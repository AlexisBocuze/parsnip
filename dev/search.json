[{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://parsnip.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://parsnip.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://parsnip.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://parsnip.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement [INSERT CONTACT METHOD]. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://parsnip.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://parsnip.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://parsnip.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://parsnip.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://parsnip.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://parsnip.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/ code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https:// www.contributor-covenant.org/translations.","code":""},{"path":"https://parsnip.tidymodels.org/dev/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to tidymodels","title":"Contributing to tidymodels","text":"detailed information contributing tidymodels packages, see development contributing guide.","code":""},{"path":"https://parsnip.tidymodels.org/dev/CONTRIBUTING.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Contributing to tidymodels","text":"Typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. YES ✅: edit roxygen comment .R file R/ directory. 🚫: edit .Rd file man/ directory. use roxygen2, Markdown syntax, documentation.","code":""},{"path":"https://parsnip.tidymodels.org/dev/CONTRIBUTING.html","id":"code","dir":"","previous_headings":"","what":"Code","title":"Contributing to tidymodels","text":"submit 🎯 pull request tidymodels package, always file issue confirm tidymodels team agrees idea happy basic proposal. tidymodels packages work together. package contains unit tests, integration tests tests using packages contained extratests. pull requests, recommend create fork repo usethis::create_from_github(), initiate new branch usethis::pr_init(). Look build status making changes. README contains badges continuous integration services used package. New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. user-facing changes, add bullet top NEWS.md current development version header describing changes made followed GitHub username, links relevant issue(s)/PR(s). use testthat. Contributions test cases included easier accept. contribution spans use one package, consider building extratests changes check breakages /adding new tests . Let us know PR ran extra tests.","code":""},{"path":"https://parsnip.tidymodels.org/dev/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"Code","what":"Code of Conduct","title":"Contributing to tidymodels","text":"project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://parsnip.tidymodels.org/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 parsnip authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"bart-models","dir":"Articles > Articles","previous_headings":"","what":"bart() models","title":"Fitting and Predicting with parsnip","text":"\"dbarts\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels) ## Registered S3 method overwritten by 'tune':   ##   method                   from      ##   required_pkgs.model_spec parsnip ## ── Attaching packages ──────────────────────────────── tidymodels 0.1.4 ── ## ✔ broom        0.7.10         ✔ rsample      0.1.0        ## ✔ dials        0.0.10         ✔ tibble       3.1.5        ## ✔ dplyr        1.0.7          ✔ tidyr        1.1.4        ## ✔ infer        1.0.0          ✔ tune         0.1.6        ## ✔ modeldata    0.1.1          ✔ workflows    0.2.4        ## ✔ parsnip      0.1.7.9001     ✔ workflowsets 0.1.0        ## ✔ purrr        0.3.4          ✔ yardstick    0.0.8        ## ✔ recipes      0.1.17 ## ── Conflicts ─────────────────────────────────── tidymodels_conflicts() ──   ## ✖ purrr::discard() masks scales::discard()   ## ✖ dplyr::filter()  masks stats::filter()   ## ✖ dplyr::lag()     masks stats::lag()   ## ✖ recipes::step()  masks stats::step()   ## • Learn how to get started at https://www.tidymodels.org/start/ tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] bt_reg_spec <-      bart(trees = 15) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"regression\") %>%      set_engine(\"dbarts\")   bt_reg_spec ## BART Model Specification (regression)   ##    ## Main Arguments:   ##   trees = 15   ##    ## Computational engine: dbarts set.seed(1)   bt_reg_fit <- bt_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   bt_reg_fit ## parsnip model object   ##    ## Fit time:  2s    ## BART Model Specification () predict(bt_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 20.1    ## 2 20.3    ## 3 21.3    ## 4 20.2    ## 5 19.4    ## 6  7.51   ## 7  6.44 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] bt_cls_spec <-      bart(trees = 15) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"classification\") %>%      set_engine(\"dbarts\")   bt_cls_spec ## BART Model Specification (classification)   ##    ## Main Arguments:   ##   trees = 15   ##    ## Computational engine: dbarts set.seed(1)   bt_cls_fit <- bt_cls_spec %>% fit(Class ~ ., data = data_train)   bt_cls_fit ## parsnip model object   ##    ## Fit time:  278ms    ## BART Model Specification () bind_cols(     predict(bt_cls_fit, data_test),     predict(bt_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class1             0.352        0.648   ##  2 Class2             0.823        0.177   ##  3 Class2             0.497        0.503   ##  4 Class1             0.509        0.491   ##  5 Class1             0.434        0.566   ##  6 Class1             0.185        0.815   ##  7 Class2             0.663        0.337   ##  8 Class1             0.392        0.608   ##  9 Class2             0.967        0.033   ## 10 Class1             0.095        0.905"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"boost_tree-models","dir":"Articles > Articles","previous_headings":"","what":"boost_tree() models","title":"Fitting and Predicting with parsnip","text":"\"xgboost\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble: \"C5.0\" engine example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] bt_reg_spec <-      boost_tree(trees = 15) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"regression\") %>%      set_engine(\"xgboost\")   bt_reg_spec ## Boosted Tree Model Specification (regression)   ##    ## Main Arguments:   ##   trees = 15   ##    ## Computational engine: xgboost set.seed(1)   bt_reg_fit <- bt_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   bt_reg_fit ## parsnip model object   ##    ## Fit time:  69ms    ## ##### xgb.Booster   ## raw: 69.2 Kb    ## call:   ##   xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0,    ##     colsample_bytree = 1, colsample_bynode = 1, min_child_weight = 1,    ##     subsample = 1, objective = \"reg:squarederror\"), data = x$data,    ##     nrounds = 15, watchlist = x$watchlist, verbose = 0, nthread = 1)   ## params (as set within xgb.train):   ##   eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"1\", min_child_weight = \"1\", subsample = \"1\", objective = \"reg:squarederror\", nthread = \"1\", validate_parameters = \"TRUE\"   ## xgb.attributes:   ##   niter   ## callbacks:   ##   cb.evaluation.log()   ## # of features: 2    ## niter: 15   ## nfeatures : 2    ## evaluation_log:   ##     iter training_rmse   ##        1     10.481480   ##        2      7.620928   ## ---                      ##       14      2.551942   ##       15      2.531085 predict(bt_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 20.6    ## 2 20.6    ## 3 20.2    ## 4 20.6    ## 5 19.3    ## 6  7.26   ## 7  5.92 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] bt_cls_spec <-      boost_tree(trees = 15) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"classification\") %>%      set_engine(\"xgboost\")   bt_cls_spec ## Boosted Tree Model Specification (classification)   ##    ## Main Arguments:   ##   trees = 15   ##    ## Computational engine: xgboost set.seed(1)   bt_cls_fit <- bt_cls_spec %>% fit(Class ~ ., data = data_train) ## [17:15:46] WARNING: amalgamation/../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior. bt_cls_fit ## parsnip model object   ##    ## Fit time:  19ms    ## ##### xgb.Booster   ## raw: 58.1 Kb    ## call:   ##   xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0,    ##     colsample_bytree = 1, colsample_bynode = 1, min_child_weight = 1,    ##     subsample = 1, objective = \"binary:logistic\"), data = x$data,    ##     nrounds = 15, watchlist = x$watchlist, verbose = 0, nthread = 1)   ## params (as set within xgb.train):   ##   eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"1\", min_child_weight = \"1\", subsample = \"1\", objective = \"binary:logistic\", nthread = \"1\", validate_parameters = \"TRUE\"   ## xgb.attributes:   ##   niter   ## callbacks:   ##   cb.evaluation.log()   ## # of features: 2    ## niter: 15   ## nfeatures : 2    ## evaluation_log:   ##     iter training_logloss   ##        1         0.552465   ##        2         0.473069   ## ---                         ##       14         0.252313   ##       15         0.249071 bind_cols(     predict(bt_cls_fit, data_test),     predict(bt_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class2            0.220        0.780    ##  2 Class1            0.931        0.0689   ##  3 Class1            0.638        0.362    ##  4 Class1            0.815        0.185    ##  5 Class2            0.292        0.708    ##  6 Class2            0.120        0.880    ##  7 Class1            0.796        0.204    ##  8 Class2            0.392        0.608    ##  9 Class1            0.879        0.121    ## 10 Class2            0.0389       0.961 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] bt_cls_spec <-      boost_tree(trees = 15) %>%      set_mode(\"classification\") %>%      set_engine(\"C5.0\")   bt_cls_spec ## Boosted Tree Model Specification (classification)   ##    ## Main Arguments:   ##   trees = 15   ##    ## Computational engine: C5.0 set.seed(1)   bt_cls_fit <- bt_cls_spec %>% fit(Class ~ ., data = data_train)   bt_cls_fit ## parsnip model object   ##    ## Fit time:  23ms    ##    ## Call:   ## C5.0.default(x = x, y = y, trials = 15, control   ##  = C50::C5.0Control(minCases = 2, sample = 0))   ##    ## Classification Tree   ## Number of samples: 781    ## Number of predictors: 2    ##    ## Number of boosting iterations: 15 requested;  6 used due to early stopping   ## Average tree size: 3.2    ##    ## Non-standard options: attempt to group attributes bind_cols(     predict(bt_cls_fit, data_test),     predict(bt_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class2             0.311        0.689   ##  2 Class1             0.863        0.137   ##  3 Class1             0.535        0.465   ##  4 Class2             0.336        0.664   ##  5 Class2             0.336        0.664   ##  6 Class2             0.137        0.863   ##  7 Class2             0.496        0.504   ##  8 Class2             0.311        0.689   ##  9 Class1             1            0       ## 10 Class2             0            1"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"decision_tree-models","dir":"Articles > Articles","previous_headings":"","what":"decision_tree() models","title":"Fitting and Predicting with parsnip","text":"\"rpart\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble: \"C5.0\" engine example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] dt_reg_spec <-      decision_tree(tree_depth = 30) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"regression\") %>%      set_engine(\"rpart\")   dt_reg_spec ## Decision Tree Model Specification (regression)   ##    ## Main Arguments:   ##   tree_depth = 30   ##    ## Computational engine: rpart set.seed(1)   dt_reg_fit <- dt_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   dt_reg_fit ## parsnip model object   ##    ## Fit time:  26ms    ## n= 5691    ##    ## node), split, n, deviance, yval   ##       * denotes terminal node   ##    ## 1) root 5691 244958.800 13.615560     ##   2) Quincy_Wells< 2.737 1721  22973.630  5.194394     ##     4) Clark_Lake< 5.07 1116  13166.830  4.260215 *   ##     5) Clark_Lake>=5.07 605   7036.349  6.917607 *   ##   3) Quincy_Wells>=2.737 3970  47031.540 17.266140     ##     6) Clark_Lake< 17.6965 1940  16042.090 15.418210 *   ##     7) Clark_Lake>=17.6965 2030  18033.560 19.032140 * predict(dt_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 19.0    ## 2 19.0    ## 3 19.0    ## 4 19.0    ## 5 19.0    ## 6  6.92   ## 7  6.92 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] dt_cls_spec <-      decision_tree(tree_depth = 30) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"classification\") %>%      set_engine(\"rpart\")   dt_cls_spec ## Decision Tree Model Specification (classification)   ##    ## Main Arguments:   ##   tree_depth = 30   ##    ## Computational engine: rpart set.seed(1)   dt_cls_fit <- dt_cls_spec %>% fit(Class ~ ., data = data_train)   dt_cls_fit ## parsnip model object   ##    ## Fit time:  11ms    ## n= 781    ##    ## node), split, n, loss, yval, (yprob)   ##       * denotes terminal node   ##    ##  1) root 781 348 Class1 (0.5544174 0.4455826)     ##    2) B< 1.495535 400  61 Class1 (0.8475000 0.1525000) *   ##    3) B>=1.495535 381  94 Class2 (0.2467192 0.7532808)     ##      6) B< 2.079458 191  70 Class2 (0.3664921 0.6335079)     ##       12) A>=2.572663 48  13 Class1 (0.7291667 0.2708333) *   ##       13) A< 2.572663 143  35 Class2 (0.2447552 0.7552448) *   ##      7) B>=2.079458 190  24 Class2 (0.1263158 0.8736842) * bind_cols(     predict(dt_cls_fit, data_test),     predict(dt_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class2             0.245        0.755   ##  2 Class1             0.848        0.152   ##  3 Class1             0.848        0.152   ##  4 Class1             0.729        0.271   ##  5 Class1             0.729        0.271   ##  6 Class2             0.126        0.874   ##  7 Class2             0.245        0.755   ##  8 Class2             0.245        0.755   ##  9 Class1             0.848        0.152   ## 10 Class2             0.126        0.874 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] dt_cls_spec <-      decision_tree(min_n = 2) %>%      set_mode(\"classification\") %>%      set_engine(\"C5.0\")   dt_cls_spec ## Decision Tree Model Specification (classification)   ##    ## Main Arguments:   ##   min_n = 2   ##    ## Computational engine: C5.0 set.seed(1)   dt_cls_fit <- dt_cls_spec %>% fit(Class ~ ., data = data_train)   dt_cls_fit ## parsnip model object   ##    ## Fit time:  14ms    ##    ## Call:   ## C5.0.default(x = x, y = y, trials = 1, control   ##  = C50::C5.0Control(minCases = 2, sample = 0))   ##    ## Classification Tree   ## Number of samples: 781    ## Number of predictors: 2    ##    ## Tree size: 4    ##    ## Non-standard options: attempt to group attributes bind_cols(     predict(dt_cls_fit, data_test),     predict(dt_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class2             0.233        0.767   ##  2 Class1             0.847        0.153   ##  3 Class1             0.847        0.153   ##  4 Class1             0.727        0.273   ##  5 Class1             0.727        0.273   ##  6 Class2             0.118        0.882   ##  7 Class2             0.233        0.767   ##  8 Class2             0.233        0.767   ##  9 Class1             0.847        0.153   ## 10 Class2             0.118        0.882"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"gen_additive_mod-models","dir":"Articles > Articles","previous_headings":"","what":"gen_additive_mod() models","title":"Fitting and Predicting with parsnip","text":"\"mgcv\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] gam_reg_spec <-      gen_additive_mod(select_features = FALSE, adjust_deg_free = 10) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"regression\") %>%      set_engine(\"mgcv\")   gam_reg_spec ## GAM Specification (regression)   ##    ## Main Arguments:   ##   select_features = FALSE   ##   adjust_deg_free = 10   ##    ## Computational engine: mgcv set.seed(1)   gam_reg_fit <- gam_reg_spec %>%      fit(ridership ~ Clark_Lake + Quincy_Wells, data = Chicago_train)   gam_reg_fit ## parsnip model object   ##    ## Fit time:  171ms    ##    ## Family: gaussian    ## Link function: identity    ##    ## Formula:   ## ridership ~ Clark_Lake + Quincy_Wells   ## Total model degrees of freedom 3    ##    ## GCV score: 9.505245 predict(gam_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 20.3    ## 2 20.5    ## 3 20.8    ## 4 20.5    ## 5 18.8    ## 6  7.45   ## 7  7.02 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] gam_cls_spec <-      gen_additive_mod(select_features = FALSE, adjust_deg_free = 10) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"classification\") %>%      set_engine(\"mgcv\")   gam_cls_spec ## GAM Specification (classification)   ##    ## Main Arguments:   ##   select_features = FALSE   ##   adjust_deg_free = 10   ##    ## Computational engine: mgcv set.seed(1)   gam_cls_fit <- gam_cls_spec %>% fit(Class ~ A + B, data = data_train)   gam_cls_fit ## parsnip model object   ##    ## Fit time:  17ms    ##    ## Family: binomial    ## Link function: logit    ##    ## Formula:   ## Class ~ A + B   ## Total model degrees of freedom 3    ##    ## UBRE score: -0.07548008 bind_cols(     predict(gam_cls_fit, data_test),     predict(gam_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class1             0.518      0.482     ##  2 Class1             0.909      0.0913    ##  3 Class1             0.648      0.352     ##  4 Class1             0.610      0.390     ##  5 Class2             0.443      0.557     ##  6 Class2             0.206      0.794     ##  7 Class1             0.708      0.292     ##  8 Class1             0.567      0.433     ##  9 Class1             0.994      0.00582   ## 10 Class2             0.108      0.892"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"linear_reg-models","dir":"Articles > Articles","previous_headings":"","what":"linear_reg() models","title":"Fitting and Predicting with parsnip","text":"\"lm\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: \"glmnet\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: \"keras\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: \"stan\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted:","code":"library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] linreg_reg_spec <-      linear_reg() %>%      set_engine(\"lm\")   linreg_reg_spec ## Linear Regression Model Specification (regression)   ##    ## Computational engine: lm set.seed(1)   linreg_reg_fit <- linreg_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   linreg_reg_fit ## parsnip model object   ##    ## Fit time:  4ms    ##    ## Call:   ## stats::lm(formula = ridership ~ ., data = data)   ##    ## Coefficients:   ##  (Intercept)    Clark_Lake  Quincy_Wells     ##       1.6624        0.7738        0.2557 predict(linreg_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 20.3    ## 2 20.5    ## 3 20.8    ## 4 20.5    ## 5 18.8    ## 6  7.45   ## 7  7.02 library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] linreg_reg_spec <-      linear_reg(penalty = 0.1) %>%      set_engine(\"glmnet\")   linreg_reg_spec ## Linear Regression Model Specification (regression)   ##    ## Main Arguments:   ##   penalty = 0.1   ##    ## Computational engine: glmnet set.seed(1)   linreg_reg_fit <- linreg_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   linreg_reg_fit ## parsnip model object   ##    ## Fit time:  11ms    ##    ## Call:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\")    ##    ##    Df  %Dev Lambda   ## 1   0  0.00 5.7970   ## 2   1 13.25 5.2820   ## 3   1 24.26 4.8130   ## 4   1 33.40 4.3850   ## 5   1 40.98 3.9960   ## 6   1 47.28 3.6410   ## 7   1 52.51 3.3170   ## 8   1 56.85 3.0220   ## 9   1 60.45 2.7540   ## 10  1 63.44 2.5090   ## 11  1 65.92 2.2860   ## 12  1 67.99 2.0830   ## 13  1 69.70 1.8980   ## 14  1 71.12 1.7300   ## 15  1 72.30 1.5760   ## 16  2 73.29 1.4360   ## 17  2 74.11 1.3080   ## 18  2 74.80 1.1920   ## 19  2 75.37 1.0860   ## 20  2 75.84 0.9897   ## 21  2 76.23 0.9018   ## 22  2 76.56 0.8217   ## 23  2 76.83 0.7487   ## 24  2 77.05 0.6822   ## 25  2 77.24 0.6216   ## 26  2 77.39 0.5664   ## 27  2 77.52 0.5160   ## 28  2 77.63 0.4702   ## 29  2 77.72 0.4284   ## 30  2 77.79 0.3904   ## 31  2 77.85 0.3557   ## 32  2 77.90 0.3241   ## 33  2 77.94 0.2953   ## 34  2 77.98 0.2691   ## 35  2 78.01 0.2452   ## 36  2 78.03 0.2234   ## 37  2 78.05 0.2035   ## 38  2 78.07 0.1855   ## 39  2 78.08 0.1690   ## 40  2 78.09 0.1540   ## 41  2 78.10 0.1403   ## 42  2 78.11 0.1278   ## 43  2 78.12 0.1165   ## 44  2 78.12 0.1061   ## 45  2 78.13 0.0967   ## 46  2 78.13 0.0881   ## 47  2 78.13 0.0803   ## 48  2 78.14 0.0732   ## 49  2 78.14 0.0666   ## 50  2 78.14 0.0607   ## 51  2 78.14 0.0553   ## 52  2 78.14 0.0504   ## 53  2 78.14 0.0459   ## 54  2 78.15 0.0419   ## 55  2 78.15 0.0381 predict(linreg_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 20.2    ## 2 20.4    ## 3 20.7    ## 4 20.4    ## 5 18.7    ## 6  7.57   ## 7  7.15 library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] linreg_reg_spec <-      linear_reg(penalty = 0.1) %>%      set_engine(\"keras\")   linreg_reg_spec ## Linear Regression Model Specification (regression)   ##    ## Main Arguments:   ##   penalty = 0.1   ##    ## Computational engine: keras set.seed(1)   linreg_reg_fit <- linreg_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   linreg_reg_fit ## parsnip model object   ##    ## Fit time:  8.2s    ## Model   ## Model: \"sequential\"   ## __________________________________________________________________________   ## Layer (type)                     Output Shape                 Param #        ## ==========================================================================   ## dense (Dense)                    (None, 1)                    3              ## __________________________________________________________________________   ## dense_1 (Dense)                  (None, 1)                    2              ## ==========================================================================   ## Total params: 5   ## Trainable params: 5   ## Non-trainable params: 0   ## __________________________________________________________________________ predict(linreg_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 20.4    ## 2 20.6    ## 3 20.9    ## 4 20.6    ## 5 19.0    ## 6  7.44   ## 7  7.08 library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] linreg_reg_spec <-      linear_reg() %>%      set_engine(\"stan\")   linreg_reg_spec ## Linear Regression Model Specification (regression)   ##    ## Computational engine: stan set.seed(1)   linreg_reg_fit <- linreg_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   linreg_reg_fit ## parsnip model object   ##    ## Fit time:  3.2s    ## stan_glm   ##  family:       gaussian [identity]   ##  formula:      ridership ~ .   ##  observations: 5691   ##  predictors:   3   ## ------   ##              Median MAD_SD   ## (Intercept)  1.7    0.1      ## Clark_Lake   0.8    0.0      ## Quincy_Wells 0.3    0.1      ##    ## Auxiliary parameter(s):   ##       Median MAD_SD   ## sigma 3.1    0.0      ##    ## ------   ## * For help interpreting the printed output see ?print.stanreg   ## * For info on the priors used see ?prior_summary.stanreg predict(linreg_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 20.3    ## 2 20.5    ## 3 20.8    ## 4 20.5    ## 5 18.8    ## 6  7.45   ## 7  7.02"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"logistic_reg-models","dir":"Articles > Articles","previous_headings":"","what":"logistic_reg() models","title":"Fitting and Predicting with parsnip","text":"\"glm\" engine example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble: \"glmnet\" engine example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble: \"keras\" engine example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble: \"LiblineaR\" engine example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble: \"stan\" engine example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] logreg_cls_spec <-      logistic_reg() %>%      set_engine(\"glm\")   logreg_cls_spec ## Logistic Regression Model Specification (classification)   ##    ## Computational engine: glm set.seed(1)   logreg_cls_fit <- logreg_cls_spec %>% fit(Class ~ ., data = data_train)   logreg_cls_fit ## parsnip model object   ##    ## Fit time:  7ms    ##    ## Call:  stats::glm(formula = Class ~ ., family = stats::binomial, data = data)   ##    ## Coefficients:   ## (Intercept)            A            B     ##      -3.755       -1.259        3.855     ##    ## Degrees of Freedom: 780 Total (i.e. Null);  778 Residual   ## Null Deviance:     1073    ## Residual Deviance: 662.1   AIC: 668.1 bind_cols(     predict(logreg_cls_fit, data_test),     predict(logreg_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class1             0.518      0.482     ##  2 Class1             0.909      0.0913    ##  3 Class1             0.648      0.352     ##  4 Class1             0.610      0.390     ##  5 Class2             0.443      0.557     ##  6 Class2             0.206      0.794     ##  7 Class1             0.708      0.292     ##  8 Class1             0.567      0.433     ##  9 Class1             0.994      0.00582   ## 10 Class2             0.108      0.892 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] logreg_cls_spec <-      logistic_reg(penalty = 0.1) %>%      set_engine(\"glmnet\")   logreg_cls_spec ## Logistic Regression Model Specification (classification)   ##    ## Main Arguments:   ##   penalty = 0.1   ##    ## Computational engine: glmnet set.seed(1)   logreg_cls_fit <- logreg_cls_spec %>% fit(Class ~ ., data = data_train)   logreg_cls_fit ## parsnip model object   ##    ## Fit time:  13ms    ##    ## Call:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"binomial\")    ##    ##    Df  %Dev   Lambda   ## 1   0  0.00 0.308500   ## 2   1  4.76 0.281100   ## 3   1  8.75 0.256100   ## 4   1 12.13 0.233300   ## 5   1 15.01 0.212600   ## 6   1 17.50 0.193700   ## 7   1 19.64 0.176500   ## 8   1 21.49 0.160800   ## 9   1 23.10 0.146500   ## 10  1 24.49 0.133500   ## 11  1 25.71 0.121700   ## 12  1 26.76 0.110900   ## 13  1 27.67 0.101000   ## 14  1 28.46 0.092030   ## 15  1 29.15 0.083860   ## 16  1 29.74 0.076410   ## 17  1 30.25 0.069620   ## 18  1 30.70 0.063430   ## 19  1 31.08 0.057800   ## 20  1 31.40 0.052660   ## 21  1 31.68 0.047990   ## 22  1 31.92 0.043720   ## 23  1 32.13 0.039840   ## 24  2 32.70 0.036300   ## 25  2 33.50 0.033070   ## 26  2 34.18 0.030140   ## 27  2 34.78 0.027460   ## 28  2 35.29 0.025020   ## 29  2 35.72 0.022800   ## 30  2 36.11 0.020770   ## 31  2 36.43 0.018930   ## 32  2 36.71 0.017250   ## 33  2 36.96 0.015710   ## 34  2 37.16 0.014320   ## 35  2 37.34 0.013050   ## 36  2 37.49 0.011890   ## 37  2 37.62 0.010830   ## 38  2 37.73 0.009868   ## 39  2 37.82 0.008992   ## 40  2 37.90 0.008193   ## 41  2 37.97 0.007465   ## 42  2 38.02 0.006802   ## 43  2 38.07 0.006198   ## 44  2 38.11 0.005647   ## 45  2 38.15 0.005145   ## 46  2 38.18 0.004688   ## 47  2 38.20 0.004272   ## 48  2 38.22 0.003892   ## 49  2 38.24 0.003547   ## 50  2 38.25 0.003231   ## 51  2 38.26 0.002944   ## 52  2 38.27 0.002683   ## 53  2 38.28 0.002444   ## 54  2 38.29 0.002227   ## 55  2 38.29 0.002029   ## 56  2 38.30 0.001849   ## 57  2 38.30 0.001685   ## 58  2 38.31 0.001535   ## 59  2 38.31 0.001399   ## 60  2 38.31 0.001275   ## 61  2 38.31 0.001161   ## 62  2 38.32 0.001058   ## 63  2 38.32 0.000964   ## 64  2 38.32 0.000879   ## 65  2 38.32 0.000800 bind_cols(     predict(logreg_cls_fit, data_test),     predict(logreg_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class1             0.530        0.470   ##  2 Class1             0.713        0.287   ##  3 Class1             0.616        0.384   ##  4 Class2             0.416        0.584   ##  5 Class2             0.417        0.583   ##  6 Class2             0.288        0.712   ##  7 Class1             0.554        0.446   ##  8 Class1             0.557        0.443   ##  9 Class1             0.820        0.180   ## 10 Class2             0.206        0.794 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] logreg_cls_spec <-      logistic_reg(penalty = 0.1) %>%      set_engine(\"keras\")   logreg_cls_spec ## Logistic Regression Model Specification (classification)   ##    ## Main Arguments:   ##   penalty = 0.1   ##    ## Computational engine: keras set.seed(1)   logreg_cls_fit <- logreg_cls_spec %>% fit(Class ~ ., data = data_train)   logreg_cls_fit ## parsnip model object   ##    ## Fit time:  1.2s    ## Model   ## Model: \"sequential_1\"   ## __________________________________________________________________________   ## Layer (type)                     Output Shape                 Param #        ## ==========================================================================   ## dense_2 (Dense)                  (None, 1)                    3              ## __________________________________________________________________________   ## dense_3 (Dense)                  (None, 2)                    4              ## ==========================================================================   ## Total params: 7   ## Trainable params: 7   ## Non-trainable params: 0   ## __________________________________________________________________________ bind_cols(     predict(logreg_cls_fit, data_test),     predict(logreg_cls_fit, data_test, type = \"prob\")   ) ## Warning in keras::predict_classes(object = object$fit, x = as.matrix(new_data)): `predict_classes()` is deprecated and and was removed from tensorflow in version 2.6.   ## Please update your code:   ##   * If your model does multi-class classification:   ##     (e.g. if it uses a `softmax` last-layer activation).   ##    ##       model %>% predict(x) %>% k_argmax()   ##    ##   * if your model does binary classification   ##     (e.g. if it uses a `sigmoid` last-layer activation).   ##    ##       model %>% predict(x) %>% `>`(0.5) %>% k_cast(\"int32\") ## Warning in keras::predict_proba(object = object$fit, x =   ## as.matrix(new_data)): `predict_proba()` is deprecated and was removed from   ## tensorflow in version 2.6, please use `predict()` instead ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class1             0.552        0.448   ##  2 Class1             0.599        0.401   ##  3 Class2             0.499        0.501   ##  4 Class1             0.770        0.230   ##  5 Class1             0.679        0.321   ##  6 Class1             0.718        0.282   ##  7 Class1             0.644        0.356   ##  8 Class1             0.541        0.459   ##  9 Class1             0.787        0.213   ## 10 Class1             0.761        0.239 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] logreg_cls_spec <-      logistic_reg(penalty = 0.1) %>%      set_engine(\"LiblineaR\")   logreg_cls_spec ## Logistic Regression Model Specification (classification)   ##    ## Main Arguments:   ##   penalty = 0.1   ##    ## Computational engine: LiblineaR set.seed(1)   logreg_cls_fit <- logreg_cls_spec %>% fit(Class ~ ., data = data_train)   logreg_cls_fit ## parsnip model object   ##    ## Fit time:  3ms    ## $TypeDetail   ## [1] \"L2-regularized logistic regression primal (L2R_LR)\"   ##    ## $Type   ## [1] 0   ##    ## $W   ##             A         B     Bias   ## [1,] 1.219818 -3.759034 3.674861   ##    ## $Bias   ## [1] 1   ##    ## $ClassNames   ## [1] Class1 Class2   ## Levels: Class1 Class2   ##    ## $NbClass   ## [1] 2   ##    ## attr(,\"class\")   ## [1] \"LiblineaR\" bind_cols(     predict(logreg_cls_fit, data_test),     predict(logreg_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class1             0.517      0.483     ##  2 Class1             0.904      0.0964    ##  3 Class1             0.645      0.355     ##  4 Class1             0.604      0.396     ##  5 Class2             0.442      0.558     ##  6 Class2             0.210      0.790     ##  7 Class1             0.702      0.298     ##  8 Class1             0.565      0.435     ##  9 Class1             0.993      0.00667   ## 10 Class2             0.112      0.888 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] logreg_cls_spec <-      logistic_reg() %>%      set_engine(\"stan\")   logreg_cls_spec ## Logistic Regression Model Specification (classification)   ##    ## Computational engine: stan set.seed(1)   logreg_cls_fit <- logreg_cls_spec %>% fit(Class ~ ., data = data_train)   logreg_cls_fit ## parsnip model object   ##    ## Fit time:  3.4s    ## stan_glm   ##  family:       binomial [logit]   ##  formula:      Class ~ .   ##  observations: 781   ##  predictors:   3   ## ------   ##             Median MAD_SD   ## (Intercept) -3.8    0.3     ## A           -1.3    0.2     ## B            3.9    0.3     ##    ## ------   ## * For help interpreting the printed output see ?print.stanreg   ## * For info on the priors used see ?prior_summary.stanreg bind_cols(     predict(logreg_cls_fit, data_test),     predict(logreg_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class1             0.518      0.482     ##  2 Class1             0.909      0.0909    ##  3 Class1             0.650      0.350     ##  4 Class1             0.609      0.391     ##  5 Class2             0.443      0.557     ##  6 Class2             0.206      0.794     ##  7 Class1             0.708      0.292     ##  8 Class1             0.568      0.432     ##  9 Class1             0.994      0.00580   ## 10 Class2             0.108      0.892"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"mars-models","dir":"Articles > Articles","previous_headings":"","what":"mars() models","title":"Fitting and Predicting with parsnip","text":"\"earth\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] mars_reg_spec <-      mars(prod_degree = 1, prune_method = \"backward\") %>%      # This model can be used for classification or regression, so set mode     set_mode(\"regression\") %>%      set_engine(\"earth\")   mars_reg_spec ## MARS Model Specification (regression)   ##    ## Main Arguments:   ##   prod_degree = 1   ##   prune_method = backward   ##    ## Computational engine: earth set.seed(1)   mars_reg_fit <- mars_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   mars_reg_fit ## parsnip model object   ##    ## Fit time:  41ms    ## Selected 5 of 6 terms, and 2 of 2 predictors   ## Termination condition: RSq changed by less than 0.001 at 6 terms   ## Importance: Clark_Lake, Quincy_Wells   ## Number of terms at each degree of interaction: 1 4 (additive model)   ## GCV 9.085818    RSS 51543.98    GRSq 0.7889881    RSq 0.789581 predict(mars_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 20.4    ## 2 20.7    ## 3 21.0    ## 4 20.7    ## 5 19.0    ## 6  7.99   ## 7  6.68 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] mars_cls_spec <-      mars(prod_degree = 1, prune_method = \"backward\") %>%      # This model can be used for classification or regression, so set mode     set_mode(\"classification\") %>%      set_engine(\"earth\")   mars_cls_spec ## MARS Model Specification (classification)   ##    ## Main Arguments:   ##   prod_degree = 1   ##   prune_method = backward   ##    ## Computational engine: earth set.seed(1)   mars_cls_fit <- mars_cls_spec %>% fit(Class ~ ., data = data_train)   mars_cls_fit ## parsnip model object   ##    ## Fit time:  16ms    ## GLM (family binomial, link logit):   ##  nulldev  df       dev  df   devratio     AIC iters converged   ##  1073.43 780   632.723 775      0.411   644.7     5         1   ##    ## Earth selected 6 of 13 terms, and 2 of 2 predictors   ## Termination condition: Reached nk 21   ## Importance: B, A   ## Number of terms at each degree of interaction: 1 5 (additive model)   ## Earth GCV 0.1334948    RSS 101.3432    GRSq 0.461003    RSq 0.4747349 bind_cols(     predict(mars_cls_fit, data_test),     predict(mars_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class2            0.332       0.668     ##  2 Class1            0.845       0.155     ##  3 Class1            0.585       0.415     ##  4 Class1            0.690       0.310     ##  5 Class2            0.483       0.517     ##  6 Class2            0.318       0.682     ##  7 Class1            0.661       0.339     ##  8 Class2            0.398       0.602     ##  9 Class1            0.990       0.00972   ## 10 Class2            0.0625      0.938"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"mlp-models","dir":"Articles > Articles","previous_headings":"","what":"mlp() models","title":"Fitting and Predicting with parsnip","text":"\"nnet\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble: \"keras\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] mlp_reg_spec <-      mlp(penalty = 0, epochs = 100) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"regression\") %>%      set_engine(\"nnet\")   mlp_reg_spec ## Single Layer Neural Network Specification (regression)   ##    ## Main Arguments:   ##   penalty = 0   ##   epochs = 100   ##    ## Computational engine: nnet set.seed(1)   mlp_reg_fit <- mlp_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   mlp_reg_fit ## parsnip model object   ##    ## Fit time:  186ms    ## a 2-5-1 network with 21 weights   ## inputs: Clark_Lake Quincy_Wells    ## output(s): ridership    ## options were - linear output units predict(mlp_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 20.5    ## 2 20.8    ## 3 21.1    ## 4 20.8    ## 5 18.8    ## 6  8.09   ## 7  6.22 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] mlp_cls_spec <-      mlp(penalty = 0, epochs = 100) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"classification\") %>%      set_engine(\"nnet\")   mlp_cls_spec ## Single Layer Neural Network Specification (classification)   ##    ## Main Arguments:   ##   penalty = 0   ##   epochs = 100   ##    ## Computational engine: nnet set.seed(1)   mlp_cls_fit <- mlp_cls_spec %>% fit(Class ~ ., data = data_train)   mlp_cls_fit ## parsnip model object   ##    ## Fit time:  40ms    ## a 2-5-1 network with 21 weights   ## inputs: A B    ## output(s): Class    ## options were - entropy fitting bind_cols(     predict(mlp_cls_fit, data_test),     predict(mlp_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class2             0.364        0.636   ##  2 Class1             0.691        0.309   ##  3 Class1             0.577        0.423   ##  4 Class1             0.686        0.314   ##  5 Class2             0.466        0.534   ##  6 Class2             0.339        0.661   ##  7 Class1             0.670        0.330   ##  8 Class2             0.384        0.616   ##  9 Class1             0.692        0.308   ## 10 Class2             0.330        0.670 library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] mlp_reg_spec <-      mlp(penalty = 0, epochs = 20) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"regression\") %>%      set_engine(\"keras\")   mlp_reg_spec ## Single Layer Neural Network Specification (regression)   ##    ## Main Arguments:   ##   penalty = 0   ##   epochs = 20   ##    ## Computational engine: keras set.seed(1)   mlp_reg_fit <- mlp_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   mlp_reg_fit ## parsnip model object   ##    ## Fit time:  4.5s    ## Model   ## Model: \"sequential_2\"   ## __________________________________________________________________________   ## Layer (type)                     Output Shape                 Param #        ## ==========================================================================   ## dense_4 (Dense)                  (None, 5)                    15             ## __________________________________________________________________________   ## dense_5 (Dense)                  (None, 1)                    6              ## ==========================================================================   ## Total params: 21   ## Trainable params: 21   ## Non-trainable params: 0   ## __________________________________________________________________________ predict(mlp_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1  7.05   ## 2  7.05   ## 3  7.05   ## 4  7.05   ## 5  7.05   ## 6  6.49   ## 7  6.26 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] mlp_cls_spec <-      mlp(penalty = 0, epochs = 20) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"classification\") %>%      set_engine(\"keras\")   mlp_cls_spec ## Single Layer Neural Network Specification (classification)   ##    ## Main Arguments:   ##   penalty = 0   ##   epochs = 20   ##    ## Computational engine: keras set.seed(1)   mlp_cls_fit <- mlp_cls_spec %>% fit(Class ~ ., data = data_train)   mlp_cls_fit ## parsnip model object   ##    ## Fit time:  1.2s    ## Model   ## Model: \"sequential_3\"   ## __________________________________________________________________________   ## Layer (type)                     Output Shape                 Param #        ## ==========================================================================   ## dense_6 (Dense)                  (None, 5)                    15             ## __________________________________________________________________________   ## dense_7 (Dense)                  (None, 2)                    12             ## ==========================================================================   ## Total params: 27   ## Trainable params: 27   ## Non-trainable params: 0   ## __________________________________________________________________________ bind_cols(     predict(mlp_cls_fit, data_test),     predict(mlp_cls_fit, data_test, type = \"prob\")   ) ## Warning in keras::predict_classes(object = object$fit, x = as.matrix(new_data)): `predict_classes()` is deprecated and and was removed from tensorflow in version 2.6.   ## Please update your code:   ##   * If your model does multi-class classification:   ##     (e.g. if it uses a `softmax` last-layer activation).   ##    ##       model %>% predict(x) %>% k_argmax()   ##    ##   * if your model does binary classification   ##     (e.g. if it uses a `sigmoid` last-layer activation).   ##    ##       model %>% predict(x) %>% `>`(0.5) %>% k_cast(\"int32\") ## Warning in keras::predict_proba(object = object$fit, x =   ## as.matrix(new_data)): `predict_proba()` is deprecated and was removed from   ## tensorflow in version 2.6, please use `predict()` instead ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class1             0.524        0.476   ##  2 Class1             0.607        0.393   ##  3 Class1             0.570        0.430   ##  4 Class2             0.448        0.552   ##  5 Class2             0.461        0.539   ##  6 Class2             0.411        0.589   ##  7 Class1             0.522        0.478   ##  8 Class1             0.537        0.463   ##  9 Class1             0.654        0.346   ## 10 Class2             0.381        0.619"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"multinom_reg-models","dir":"Articles > Articles","previous_headings":"","what":"multinom_reg() models","title":"Fitting and Predicting with parsnip","text":"\"glmnet\" engine ’ll predict island penguins observed two variables unit (mm): bill length bill depth. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble: \"keras\" engine ’ll predict island penguins observed two variables unit (mm): bill length bill depth. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble: \"nnet\" engine ’ll predict island penguins observed two variables unit (mm): bill length bill depth. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels) tidymodels_prefer() data(penguins)  penguins <- penguins %>% select(island, starts_with(\"bill_\")) penguins_train <- penguins[-c(21, 153, 31, 277, 1), ] penguins_test  <- penguins[ c(21, 153, 31, 277, 1), ] mr_cls_spec <-    multinom_reg(penalty = 0.1) %>%    set_engine(\"glmnet\") mr_cls_spec ## Multinomial Regression Model Specification (classification) ##  ## Main Arguments: ##   penalty = 0.1 ##  ## Computational engine: glmnet set.seed(1) mr_cls_fit <- mr_cls_spec %>% fit(island ~ ., data = penguins_train) mr_cls_fit ## parsnip model object ##  ## Fit time:  32ms  ##  ## Call:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"multinomial\")  ##  ##    Df  %Dev  Lambda ## 1   0  0.00 0.31730 ## 2   1  3.43 0.28910 ## 3   1  6.30 0.26340 ## 4   1  8.74 0.24000 ## 5   1 10.83 0.21870 ## 6   1 12.62 0.19930 ## 7   1 14.17 0.18160 ## 8   1 15.51 0.16540 ## 9   1 16.67 0.15070 ## 10  1 17.68 0.13740 ## 11  1 18.56 0.12520 ## 12  2 19.93 0.11400 ## 13  2 21.31 0.10390 ## 14  2 22.50 0.09467 ## 15  2 23.52 0.08626 ## 16  2 24.40 0.07860 ## 17  2 25.16 0.07162 ## 18  2 25.81 0.06526 ## 19  2 26.37 0.05946 ## 20  2 26.86 0.05418 ## 21  2 27.27 0.04936 ## 22  2 27.63 0.04498 ## 23  2 27.94 0.04098 ## 24  2 28.21 0.03734 ## 25  2 28.44 0.03402 ## 26  2 28.63 0.03100 ## 27  2 28.80 0.02825 ## 28  2 28.94 0.02574 ## 29  2 29.06 0.02345 ## 30  2 29.17 0.02137 ## 31  2 29.26 0.01947 ## 32  2 29.33 0.01774 ## 33  2 29.39 0.01616 ## 34  2 29.45 0.01473 ## 35  2 29.49 0.01342 ## 36  2 29.53 0.01223 ## 37  2 29.56 0.01114 ## 38  2 29.59 0.01015 ## 39  2 29.61 0.00925 ## 40  2 29.63 0.00843 ## 41  2 29.65 0.00768 ## 42  2 29.67 0.00700 ## 43  2 29.68 0.00638 ## 44  2 29.69 0.00581 ## 45  2 29.70 0.00529 ## 46  2 29.71 0.00482 ## 47  2 29.71 0.00439 ## 48  2 29.72 0.00400 ## 49  2 29.72 0.00365 ## 50  2 29.73 0.00332 ## 51  2 29.73 0.00303 ## 52  2 29.74 0.00276 ## 53  2 29.74 0.00251 ## 54  2 29.74 0.00229 ## 55  2 29.75 0.00209 ## 56  2 29.75 0.00190 ## 57  2 29.75 0.00173 ## 58  2 29.75 0.00158 ## 59  2 29.75 0.00144 ## 60  2 29.75 0.00131 bind_cols(   predict(mr_cls_fit, penguins_test),   predict(mr_cls_fit, penguins_test, type = \"prob\") ) ## # A tibble: 5 × 4 ##   .pred_class .pred_Biscoe .pred_Dream .pred_Torgersen ##   <fct>              <dbl>       <dbl>           <dbl> ## 1 Dream              0.339      0.448           0.214  ## 2 Biscoe             0.879      0.0882          0.0331 ## 3 Biscoe             0.539      0.317           0.144  ## 4 Dream              0.403      0.435           0.162  ## 5 Dream              0.297      0.481           0.221 library(tidymodels) tidymodels_prefer() data(penguins)  penguins <- penguins %>% select(island, starts_with(\"bill_\")) penguins_train <- penguins[-c(21, 153, 31, 277, 1), ] penguins_test  <- penguins[ c(21, 153, 31, 277, 1), ] mr_cls_spec <-    multinom_reg(penalty = 0.1) %>%    set_engine(\"keras\") mr_cls_spec ## Multinomial Regression Model Specification (classification) ##  ## Main Arguments: ##   penalty = 0.1 ##  ## Computational engine: keras set.seed(1) mr_cls_fit <- mr_cls_spec %>% fit(island ~ ., data = penguins_train) mr_cls_fit ## parsnip model object ##  ## Fit time:  935ms  ## Model ## Model: \"sequential_4\" ## __________________________________________________________________________ ## Layer (type)                     Output Shape                 Param #      ## ========================================================================== ## dense_8 (Dense)                  (None, 1)                    3            ## __________________________________________________________________________ ## dense_9 (Dense)                  (None, 3)                    6            ## ========================================================================== ## Total params: 9 ## Trainable params: 9 ## Non-trainable params: 0 ## __________________________________________________________________________ bind_cols(   predict(mr_cls_fit, penguins_test),   predict(mr_cls_fit, penguins_test, type = \"prob\") ) ## Warning in keras::predict_classes(object = object$fit, x = as.matrix(new_data)): `predict_classes()` is deprecated and and was removed from tensorflow in version 2.6. ## Please update your code: ##   * If your model does multi-class classification: ##     (e.g. if it uses a `softmax` last-layer activation). ##  ##       model %>% predict(x) %>% k_argmax() ##  ##   * if your model does binary classification ##     (e.g. if it uses a `sigmoid` last-layer activation). ##  ##       model %>% predict(x) %>% `>`(0.5) %>% k_cast(\"int32\") ## Warning in keras::predict_proba(object = object$fit, x = ## as.matrix(new_data)): `predict_proba()` is deprecated and was removed from ## tensorflow in version 2.6, please use `predict()` instead ## # A tibble: 5 × 4 ##   .pred_class .pred_Biscoe .pred_Dream .pred_Torgersen ##   <fct>              <dbl>       <dbl>           <dbl> ## 1 Biscoe             0.661    5.25e-23           0.339 ## 2 Biscoe             0.692    5.39e-28           0.308 ## 3 Biscoe             0.667    4.89e-24           0.333 ## 4 Biscoe             0.693    3.75e-28           0.307 ## 5 Biscoe             0.666    9.10e-24           0.334 library(tidymodels) tidymodels_prefer() data(penguins)  penguins <- penguins %>% select(island, starts_with(\"bill_\")) penguins_train <- penguins[-c(21, 153, 31, 277, 1), ] penguins_test  <- penguins[ c(21, 153, 31, 277, 1), ] mr_cls_spec <-    multinom_reg(penalty = 0.1) %>%    set_engine(\"nnet\") mr_cls_spec ## Multinomial Regression Model Specification (classification) ##  ## Main Arguments: ##   penalty = 0.1 ##  ## Computational engine: nnet set.seed(1) mr_cls_fit <- mr_cls_spec %>% fit(island ~ ., data = penguins_train) mr_cls_fit ## parsnip model object ##  ## Fit time:  6ms  ## Call: ## nnet::multinom(formula = island ~ ., data = data, decay = ~0.1,  ##     trace = FALSE) ##  ## Coefficients: ##           (Intercept) bill_length_mm bill_depth_mm ## Dream       -8.243575     -0.0580960     0.6168318 ## Torgersen   -1.610588     -0.2789588     0.6978480 ##  ## Residual Deviance: 502.5009  ## AIC: 514.5009 bind_cols(   predict(mr_cls_fit, penguins_test),   predict(mr_cls_fit, penguins_test, type = \"prob\") ) ## # A tibble: 5 × 4 ##   .pred_class .pred_Biscoe .pred_Dream .pred_Torgersen ##   <fct>              <dbl>       <dbl>           <dbl> ## 1 Dream              0.193      0.450          0.357   ## 2 Biscoe             0.937      0.0582         0.00487 ## 3 Biscoe             0.462      0.364          0.174   ## 4 Dream              0.450      0.495          0.0556  ## 5 Dream              0.183      0.506          0.311"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"nearest_neighbor-models","dir":"Articles > Articles","previous_headings":"","what":"nearest_neighbor() models","title":"Fitting and Predicting with parsnip","text":"\"kknn\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. Since two classes, ’ll use odd number neighbors avoid ties: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels) tidymodels_prefer() data(Chicago)  n <- nrow(Chicago) Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)  Chicago_train <- Chicago[1:(n - 7), ] Chicago_test <- Chicago[(n - 6):n, ] knn_reg_spec <-   nearest_neighbor(neighbors = 5, weight_func = \"triangular\") %>%   # This model can be used for classification or regression, so set mode   set_mode(\"regression\") %>%   set_engine(\"kknn\") knn_reg_spec ## K-Nearest Neighbor Model Specification (regression) ##  ## Main Arguments: ##   neighbors = 5 ##   weight_func = triangular ##  ## Computational engine: kknn knn_reg_fit <- knn_reg_spec %>% fit(ridership ~ ., data = Chicago_train) knn_reg_fit ## parsnip model object ##  ## Fit time:  232ms  ##  ## Call: ## kknn::train.kknn(formula = ridership ~ ., data = data, ks = min_rows(5,     data, 5), kernel = ~\"triangular\") ##  ## Type of response variable: continuous ## minimal mean absolute error: 1.79223 ## Minimal mean squared error: 11.21809 ## Best kernel: triangular ## Best k: 5 predict(knn_reg_fit, Chicago_test) ## # A tibble: 7 × 1 ##   .pred ##   <dbl> ## 1 20.5  ## 2 21.1  ## 3 21.4  ## 4 21.8  ## 5 19.5  ## 6  7.83 ## 7  5.54 library(tidymodels) tidymodels_prefer() data(two_class_dat)  data_train <- two_class_dat[-(1:10), ] data_test  <- two_class_dat[  1:10 , ] knn_cls_spec <-   nearest_neighbor(neighbors = 11, weight_func = \"triangular\") %>%   # This model can be used for classification or regression, so set mode   set_mode(\"classification\") %>%   set_engine(\"kknn\") knn_cls_spec ## K-Nearest Neighbor Model Specification (classification) ##  ## Main Arguments: ##   neighbors = 11 ##   weight_func = triangular ##  ## Computational engine: kknn knn_cls_fit <- knn_cls_spec %>% fit(Class ~ ., data = data_train) knn_cls_fit ## parsnip model object ##  ## Fit time:  38ms  ##  ## Call: ## kknn::train.kknn(formula = Class ~ ., data = data, ks = min_rows(11,     data, 5), kernel = ~\"triangular\") ##  ## Type of response variable: nominal ## Minimal misclassification: 0.1869398 ## Best kernel: triangular ## Best k: 11 bind_cols(   predict(knn_cls_fit, data_test),   predict(knn_cls_fit, data_test, type = \"prob\") ) ## # A tibble: 10 × 3 ##    .pred_class .pred_Class1 .pred_Class2 ##    <fct>              <dbl>        <dbl> ##  1 Class2            0.177       0.823   ##  2 Class1            0.995       0.00515 ##  3 Class1            0.590       0.410   ##  4 Class1            0.770       0.230   ##  5 Class2            0.333       0.667   ##  6 Class2            0.182       0.818   ##  7 Class1            0.692       0.308   ##  8 Class2            0.400       0.600   ##  9 Class1            0.814       0.186   ## 10 Class2            0.0273      0.973"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"rand_forest-models","dir":"Articles > Articles","previous_headings":"","what":"rand_forest() models","title":"Fitting and Predicting with parsnip","text":"\"ranger\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble: \"randomForest\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] rf_reg_spec <-      rand_forest(trees = 200, min_n = 5) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"regression\") %>%      set_engine(\"ranger\")   rf_reg_spec ## Random Forest Model Specification (regression)   ##    ## Main Arguments:   ##   trees = 200   ##   min_n = 5   ##    ## Computational engine: ranger set.seed(1)   rf_reg_fit <- rf_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   rf_reg_fit ## parsnip model object   ##    ## Fit time:  1.5s    ## Ranger result   ##    ## Call:   ##  ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~200,      min.node.size = min_rows(~5, x), num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1))    ##    ## Type:                             Regression    ## Number of trees:                  200    ## Sample size:                      5691    ## Number of independent variables:  2    ## Mtry:                             1    ## Target node size:                 5    ## Variable importance mode:         none    ## Splitrule:                        variance    ## OOB prediction error (MSE):       9.72953    ## R squared (OOB):                  0.7739986 predict(rf_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 20.4    ## 2 21.5    ## 3 20.8    ## 4 21.6    ## 5 19.4    ## 6  7.32   ## 7  6.03 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] rf_cls_spec <-      rand_forest(trees = 200, min_n = 5) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"classification\") %>%      set_engine(\"ranger\")   rf_cls_spec ## Random Forest Model Specification (classification)   ##    ## Main Arguments:   ##   trees = 200   ##   min_n = 5   ##    ## Computational engine: ranger set.seed(1)   rf_cls_fit <- rf_cls_spec %>% fit(Class ~ ., data = data_train)   rf_cls_fit ## parsnip model object   ##    ## Fit time:  106ms    ## Ranger result   ##    ## Call:   ##  ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~200,      min.node.size = min_rows(~5, x), num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE)    ##    ## Type:                             Probability estimation    ## Number of trees:                  200    ## Sample size:                      781    ## Number of independent variables:  2    ## Mtry:                             1    ## Target node size:                 5    ## Variable importance mode:         none    ## Splitrule:                        gini    ## OOB prediction error (Brier s.):  0.1534794 bind_cols(     predict(rf_cls_fit, data_test),     predict(rf_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class2           0.274         0.725    ##  2 Class1           0.928         0.0716   ##  3 Class2           0.497         0.503    ##  4 Class1           0.703         0.297    ##  5 Class2           0.302         0.698    ##  6 Class2           0.151         0.849    ##  7 Class1           0.701         0.299    ##  8 Class1           0.592         0.409    ##  9 Class1           0.752         0.248    ## 10 Class2           0.00225       0.998 library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] rf_reg_spec <-      rand_forest(trees = 200, min_n = 5) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"regression\") %>%      set_engine(\"randomForest\")   rf_reg_spec ## Random Forest Model Specification (regression)   ##    ## Main Arguments:   ##   trees = 200   ##   min_n = 5   ##    ## Computational engine: randomForest set.seed(1)   rf_reg_fit <- rf_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   rf_reg_fit ## parsnip model object   ##    ## Fit time:  7.8s    ##    ## Call:   ##  randomForest(x = maybe_data_frame(x), y = y, ntree = ~200, nodesize = min_rows(~5,      x))    ##                Type of random forest: regression   ##                      Number of trees: 200   ## No. of variables tried at each split: 1   ##    ##           Mean of squared residuals: 9.696736   ##                     % Var explained: 77.47 predict(rf_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 20.4    ## 2 21.6    ## 3 20.9    ## 4 21.6    ## 5 19.3    ## 6  7.33   ## 7  6.16 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] rf_cls_spec <-      rand_forest(trees = 200, min_n = 5) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"classification\") %>%      set_engine(\"randomForest\")   rf_cls_spec ## Random Forest Model Specification (classification)   ##    ## Main Arguments:   ##   trees = 200   ##   min_n = 5   ##    ## Computational engine: randomForest set.seed(1)   rf_cls_fit <- rf_cls_spec %>% fit(Class ~ ., data = data_train)   rf_cls_fit ## parsnip model object   ##    ## Fit time:  79ms    ##    ## Call:   ##  randomForest(x = maybe_data_frame(x), y = y, ntree = ~200, nodesize = min_rows(~5,      x))    ##                Type of random forest: classification   ##                      Number of trees: 200   ## No. of variables tried at each split: 1   ##    ##         OOB estimate of  error rate: 19.72%   ## Confusion matrix:   ##        Class1 Class2 class.error   ## Class1    363     70   0.1616628   ## Class2     84    264   0.2413793 bind_cols(     predict(rf_cls_fit, data_test),     predict(rf_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class2             0.23         0.77    ##  2 Class1             0.95         0.05    ##  3 Class1             0.59         0.41    ##  4 Class1             0.75         0.25    ##  5 Class2             0.305        0.695   ##  6 Class2             0.105        0.895   ##  7 Class1             0.685        0.315   ##  8 Class1             0.63         0.37    ##  9 Class1             0.79         0.21    ## 10 Class2             0.02         0.98"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"svm_linear-models","dir":"Articles > Articles","previous_headings":"","what":"svm_linear() models","title":"Fitting and Predicting with parsnip","text":"\"LiblineaR\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions. \"kernlab\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] svm_reg_spec <-      svm_linear(cost = 1, margin = 0.1) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"regression\") %>%      set_engine(\"LiblineaR\")   svm_reg_spec ## Linear Support Vector Machine Specification (regression)   ##    ## Main Arguments:   ##   cost = 1   ##   margin = 0.1   ##    ## Computational engine: LiblineaR set.seed(1)   svm_reg_fit <- svm_reg_spec %>% fit(ridership ~ ., data = Chicago_train)   svm_reg_fit ## parsnip model object   ##    ## Fit time:  3ms    ## $TypeDetail   ## [1] \"L2-regularized L2-loss support vector regression primal (L2R_L2LOSS_SVR)\"   ##    ## $Type   ## [1] 11   ##    ## $W   ##      Clark_Lake Quincy_Wells       Bias   ## [1,]  0.8277352    0.3430336 0.05042585   ##    ## $Bias   ## [1] 1   ##    ## $NbClass   ## [1] 2   ##    ## attr(,\"class\")   ## [1] \"LiblineaR\" predict(svm_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 20.6    ## 2 20.8    ## 3 21.1    ## 4 20.8    ## 5 18.9    ## 6  6.40   ## 7  5.90 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] svm_cls_spec <-      svm_linear(cost = 1) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"classification\") %>%      set_engine(\"LiblineaR\")   svm_cls_spec ## Linear Support Vector Machine Specification (classification)   ##    ## Main Arguments:   ##   cost = 1   ##    ## Computational engine: LiblineaR set.seed(1)   svm_cls_fit <- svm_cls_spec %>% fit(Class ~ ., data = data_train)   svm_cls_fit ## parsnip model object   ##    ## Fit time:  528ms    ## $TypeDetail   ## [1] \"L2-regularized L2-loss support vector classification dual (L2R_L2LOSS_SVC_DUAL)\"   ##    ## $Type   ## [1] 1   ##    ## $W   ##              A         B     Bias   ## [1,] 0.4067922 -1.314783 1.321851   ##    ## $Bias   ## [1] 1   ##    ## $ClassNames   ## [1] Class1 Class2   ## Levels: Class1 Class2   ##    ## $NbClass   ## [1] 2   ##    ## attr(,\"class\")   ## [1] \"LiblineaR\" predict(svm_cls_fit, data_test) ## # A tibble: 10 × 1   ##    .pred_class   ##    <fct>         ##  1 Class1        ##  2 Class1        ##  3 Class1        ##  4 Class1        ##  5 Class2        ##  6 Class2        ##  7 Class1        ##  8 Class1        ##  9 Class1        ## 10 Class2 library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] svm_reg_spec <-      svm_linear(cost = 1, margin = 0.1) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"regression\") %>%      set_engine(\"kernlab\")   svm_reg_spec ## Linear Support Vector Machine Specification (regression)   ##    ## Main Arguments:   ##   cost = 1   ##   margin = 0.1   ##    ## Computational engine: kernlab set.seed(1)   svm_reg_fit <- svm_reg_spec %>% fit(ridership ~ ., data = Chicago_train) ##  Setting default kernel parameters svm_reg_fit ## parsnip model object   ##    ## Fit time:  885ms    ## Support Vector Machine object of class \"ksvm\"    ##    ## SV type: eps-svr  (regression)    ##  parameter : epsilon = 0.1  cost C = 1    ##    ## Linear (vanilla) kernel function.    ##    ## Number of Support Vectors : 2283    ##    ## Objective Function Value : -825.1632    ## Training error : 0.226456 predict(svm_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 21.0    ## 2 21.2    ## 3 21.5    ## 4 21.2    ## 5 19.4    ## 6  6.87   ## 7  6.41 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] svm_cls_spec <-      svm_linear(cost = 1) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"classification\") %>%      set_engine(\"kernlab\")   svm_cls_spec ## Linear Support Vector Machine Specification (classification)   ##    ## Main Arguments:   ##   cost = 1   ##    ## Computational engine: kernlab set.seed(1)   svm_cls_fit <- svm_cls_spec %>% fit(Class ~ ., data = data_train) ##  Setting default kernel parameters svm_cls_fit ## parsnip model object   ##    ## Fit time:  922ms    ## Support Vector Machine object of class \"ksvm\"    ##    ## SV type: C-svc  (classification)    ##  parameter : cost C = 1    ##    ## Linear (vanilla) kernel function.    ##    ## Number of Support Vectors : 353    ##    ## Objective Function Value : -349.425    ## Training error : 0.174136    ## Probability model included. bind_cols(     predict(svm_cls_fit, data_test),     predict(svm_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class1             0.517      0.483     ##  2 Class1             0.904      0.0956    ##  3 Class1             0.645      0.355     ##  4 Class1             0.610      0.390     ##  5 Class2             0.445      0.555     ##  6 Class2             0.212      0.788     ##  7 Class1             0.704      0.296     ##  8 Class1             0.565      0.435     ##  9 Class1             0.994      0.00646   ## 10 Class2             0.114      0.886"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"svm_poly-models","dir":"Articles > Articles","previous_headings":"","what":"svm_poly() models","title":"Fitting and Predicting with parsnip","text":"\"kernlab\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels)   tidymodels_prefer()   data(Chicago)      n <- nrow(Chicago)   Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)      Chicago_train <- Chicago[1:(n - 7), ]   Chicago_test <- Chicago[(n - 6):n, ] svm_reg_spec <-      svm_poly(cost = 1, margin = 0.1) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"regression\") %>%      set_engine(\"kernlab\")   svm_reg_spec ## Polynomial Support Vector Machine Specification (regression)   ##    ## Main Arguments:   ##   cost = 1   ##   margin = 0.1   ##    ## Computational engine: kernlab set.seed(1)   svm_reg_fit <- svm_reg_spec %>% fit(ridership ~ ., data = Chicago_train) ##  Setting default kernel parameters svm_reg_fit ## parsnip model object   ##    ## Fit time:  1.3s    ## Support Vector Machine object of class \"ksvm\"    ##    ## SV type: eps-svr  (regression)    ##  parameter : epsilon = 0.1  cost C = 1    ##    ## Polynomial kernel function.    ##  Hyperparameters : degree =  1  scale =  1  offset =  1    ##    ## Number of Support Vectors : 2283    ##    ## Objective Function Value : -825.1628    ## Training error : 0.226471 predict(svm_reg_fit, Chicago_test) ## # A tibble: 7 × 1   ##   .pred   ##   <dbl>   ## 1 21.0    ## 2 21.2    ## 3 21.5    ## 4 21.2    ## 5 19.4    ## 6  6.87   ## 7  6.41 library(tidymodels)   tidymodels_prefer()   data(two_class_dat)      data_train <- two_class_dat[-(1:10), ]   data_test  <- two_class_dat[  1:10 , ] svm_cls_spec <-      svm_poly(cost = 1) %>%      # This model can be used for classification or regression, so set mode     set_mode(\"classification\") %>%      set_engine(\"kernlab\")   svm_cls_spec ## Polynomial Support Vector Machine Specification (classification)   ##    ## Main Arguments:   ##   cost = 1   ##    ## Computational engine: kernlab set.seed(1)   svm_cls_fit <- svm_cls_spec %>% fit(Class ~ ., data = data_train) ##  Setting default kernel parameters svm_cls_fit ## parsnip model object   ##    ## Fit time:  59ms    ## Support Vector Machine object of class \"ksvm\"    ##    ## SV type: C-svc  (classification)    ##  parameter : cost C = 1    ##    ## Polynomial kernel function.    ##  Hyperparameters : degree =  1  scale =  1  offset =  1    ##    ## Number of Support Vectors : 353    ##    ## Objective Function Value : -349.425    ## Training error : 0.174136    ## Probability model included. bind_cols(     predict(svm_cls_fit, data_test),     predict(svm_cls_fit, data_test, type = \"prob\")   ) ## # A tibble: 10 × 3   ##    .pred_class .pred_Class1 .pred_Class2   ##    <fct>              <dbl>        <dbl>   ##  1 Class1             0.517      0.483     ##  2 Class1             0.904      0.0956    ##  3 Class1             0.645      0.355     ##  4 Class1             0.610      0.390     ##  5 Class2             0.445      0.555     ##  6 Class2             0.212      0.788     ##  7 Class1             0.704      0.296     ##  8 Class1             0.565      0.435     ##  9 Class1             0.994      0.00646   ## 10 Class2             0.114      0.886"},{"path":"https://parsnip.tidymodels.org/dev/articles/articles/Examples.html","id":"svm_rbf-models","dir":"Articles > Articles","previous_headings":"","what":"svm_rbf() models","title":"Fitting and Predicting with parsnip","text":"\"kernlab\" engine ’ll model ridership Chicago elevated trains function 14 day lagged ridership two stations. two predictors units (rides per day/1000) need normalized. last week data used training. last week predicted model fit. can define model specific parameters: Now create model fit object: holdout data can predicted: example data two predictors outcome two classes. predictors units. can define model specific parameters: Now create model fit object: holdout data can predicted hard class predictions probabilities. ’ll bind together one tibble:","code":"library(tidymodels) tidymodels_prefer() data(Chicago)  n <- nrow(Chicago) Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)  Chicago_train <- Chicago[1:(n - 7), ] Chicago_test <- Chicago[(n - 6):n, ] svm_reg_spec <-    svm_rbf(cost = 1, margin = 0.1) %>%    # This model can be used for classification or regression, so set mode   set_mode(\"regression\") %>%    set_engine(\"kernlab\") svm_reg_spec ## Radial Basis Function Support Vector Machine Specification (regression) ##  ## Main Arguments: ##   cost = 1 ##   margin = 0.1 ##  ## Computational engine: kernlab set.seed(1) svm_reg_fit <- svm_reg_spec %>% fit(ridership ~ ., data = Chicago_train) svm_reg_fit ## parsnip model object ##  ## Fit time:  1.9s  ## Support Vector Machine object of class \"ksvm\"  ##  ## SV type: eps-svr  (regression)  ##  parameter : epsilon = 0.1  cost C = 1  ##  ## Gaussian Radial Basis kernel function.  ##  Hyperparameter : sigma =  10.8262370251485  ##  ## Number of Support Vectors : 2233  ##  ## Objective Function Value : -746.584  ## Training error : 0.205567 predict(svm_reg_fit, Chicago_test) ## # A tibble: 7 × 1 ##   .pred ##   <dbl> ## 1 20.7  ## 2 21.2  ## 3 21.3  ## 4 21.1  ## 5 19.4  ## 6  6.77 ## 7  6.13 library(tidymodels) tidymodels_prefer() data(two_class_dat)  data_train <- two_class_dat[-(1:10), ] data_test  <- two_class_dat[  1:10 , ] svm_cls_spec <-    svm_rbf(cost = 1) %>%    # This model can be used for classification or regression, so set mode   set_mode(\"classification\") %>%    set_engine(\"kernlab\") svm_cls_spec ## Radial Basis Function Support Vector Machine Specification (classification) ##  ## Main Arguments: ##   cost = 1 ##  ## Computational engine: kernlab set.seed(1) svm_cls_fit <- svm_cls_spec %>% fit(Class ~ ., data = data_train) svm_cls_fit ## parsnip model object ##  ## Fit time:  80ms  ## Support Vector Machine object of class \"ksvm\"  ##  ## SV type: C-svc  (classification)  ##  parameter : cost C = 1  ##  ## Gaussian Radial Basis kernel function.  ##  Hyperparameter : sigma =  1.63216688499952  ##  ## Number of Support Vectors : 327  ##  ## Objective Function Value : -294.4344  ## Training error : 0.169014  ## Probability model included. bind_cols(   predict(svm_cls_fit, data_test),   predict(svm_cls_fit, data_test, type = \"prob\") ) ## # A tibble: 10 × 3 ##    .pred_class .pred_Class1 .pred_Class2 ##    <fct>              <dbl>        <dbl> ##  1 Class2             0.238       0.762  ##  2 Class1             0.905       0.0950 ##  3 Class1             0.619       0.381  ##  4 Class1             0.879       0.121  ##  5 Class1             0.641       0.359  ##  6 Class2             0.153       0.847  ##  7 Class1             0.745       0.255  ##  8 Class2             0.313       0.687  ##  9 Class1             0.878       0.122  ## 10 Class2             0.137       0.863"},{"path":"https://parsnip.tidymodels.org/dev/articles/parsnip.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"parsnip Basics","text":"Modeling functions across different R packages can different interfaces. like try different approaches, lot syntactical minutiae remember. problem worsens move -platforms (e.g. logistic regression R’s glm versus Spark’s implementation). parsnip tries solve providing similar interfaces models. example, fitting random forest model like adjust number trees forest different argument names remember: randomForest::randomForest uses ntree, ranger::ranger uses num.trees, Spark’s sparklyr::ml_random_forest uses num_trees. Rather remembering values, common interface models can used package makes translation trees real names implementations. terminology: model type differentiates models. Example types : random forests, logistic regression, linear support vector machines, etc. mode model denotes used. Two common modes classification regression. Others include “censored regression” “risk regression” (parametric Cox PH models censored data, respectively), well unsupervised models (e.g. “clustering”). computational engine indicates actual model might fit. often R packages (randomForest ranger) might also methods outside R (e.g. Stan, Spark, others). parsnip, similar ggplot2, dplyr recipes, separates specification want actual . allows us create broader functionality modeling.","code":"library(parsnip) rf_mod <- rand_forest(trees = 2000)"},{"path":"https://parsnip.tidymodels.org/dev/articles/parsnip.html","id":"placeholders-for-parameters","dir":"Articles","previous_headings":"","what":"Placeholders for Parameters","title":"parsnip Basics","text":"times like change parameter default sure final value . basis model tuning. Since model executing created, types parameters can changed using varying() function. provides simple placeholder value. come handy later fit model different values mtry.","code":"tune_mtry <- rand_forest(trees = 2000, mtry = varying()) tune_mtry #> Random Forest Model Specification (unknown) #>  #> Main Arguments: #>   mtry = varying() #>   trees = 2000 #>  #> Computational engine: ranger"},{"path":"https://parsnip.tidymodels.org/dev/articles/parsnip.html","id":"specifying-arguments","dir":"Articles","previous_headings":"","what":"Specifying Arguments","title":"parsnip Basics","text":"Commonly used arguments modeling functions parameters exposed function. example, rand_forest arguments : mtry: number predictors randomly sampled split creating tree models. trees: number trees contained ensemble. min_n: minimum number data points node required node split . arguments default function : However, might arguments like change allow vary. accessible using set_engine. example, ranger option set internal random number seed. set specific value:","code":"args(rand_forest) #> function (mode = \"unknown\", engine = \"ranger\", mtry = NULL, trees = NULL,  #>     min_n = NULL)  #> NULL rf_with_seed <-    rand_forest(trees = 2000, mtry = varying(), mode = \"regression\") %>%   set_engine(\"ranger\", seed = 63233) rf_with_seed #> Random Forest Model Specification (regression) #>  #> Main Arguments: #>   mtry = varying() #>   trees = 2000 #>  #> Engine-Specific Arguments: #>   seed = 63233 #>  #> Computational engine: ranger"},{"path":"https://parsnip.tidymodels.org/dev/articles/parsnip.html","id":"process","dir":"Articles","previous_headings":"","what":"Process","title":"parsnip Basics","text":"fit model, must: defined model, including mode, varying() parameters, specify computational engine. example, rf_with_seed ready fitting due varying() parameter. can set parameter’s value create model fit: , using randomForest package: Note call objects show num.trees = ~2000. tilde consequence parsnip using quosures process model specification’s arguments. Normally, function executed, function’s arguments immediately evaluated. case parsnip, model specification’s arguments ; expression captured along environment evaluated. quosure . parsnip uses expressions make model fit call evaluated. tilde call reflects argument captured using quosure.","code":"rf_with_seed %>%    set_args(mtry = 4) %>%    set_engine(\"ranger\") %>%   fit(mpg ~ ., data = mtcars) #> parsnip model object #>  #> Ranger result #>  #> Call: #>  ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~4, x), num.trees = ~2000, num.threads = 1, verbose = FALSE, seed = sample.int(10^5, 1))  #>  #> Type:                             Regression  #> Number of trees:                  2000  #> Sample size:                      32  #> Number of independent variables:  10  #> Mtry:                             4  #> Target node size:                 5  #> Variable importance mode:         none  #> Splitrule:                        variance  #> OOB prediction error (MSE):       5.57  #> R squared (OOB):                  0.847 set.seed(56982) rf_with_seed %>%    set_args(mtry = 4) %>%    set_engine(\"randomForest\") %>%   fit(mpg ~ ., data = mtcars) #> parsnip model object #>  #>  #> Call: #>  randomForest(x = maybe_data_frame(x), y = y, ntree = ~2000, mtry = min_cols(~4, x))  #>                Type of random forest: regression #>                      Number of trees: 2000 #> No. of variables tried at each split: 4 #>  #>           Mean of squared residuals: 5.52 #>                     % Var explained: 84.3"},{"path":"https://parsnip.tidymodels.org/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors","text":"Max Kuhn. Author, maintainer. Davis Vaughan. Author. Emil Hvitfeldt. Contributor. . Copyright holder.","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"A Common API to Modeling and Analysis Functions","text":"goal parsnip provide tidy, unified interface models can used try range models without getting bogged syntactical minutiae underlying packages.","code":""},{"path":"https://parsnip.tidymodels.org/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Common API to Modeling and Analysis Functions","text":"","code":"# The easiest way to get parsnip is to install all of tidymodels: install.packages(\"tidymodels\")  # Alternatively, install just parsnip: install.packages(\"parsnip\")  # Or the development version from GitHub: # install.packages(\"devtools\") devtools::install_github(\"tidymodels/parsnip\")"},{"path":"https://parsnip.tidymodels.org/dev/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting started","title":"A Common API to Modeling and Analysis Functions","text":"One challenge different modeling functions available R thing can different interfaces arguments. example, fit random forest regression model, might : Note model syntax can different argument names (formats) also different. pain switch implementations. example: type model “random forest”, mode model “regression” (opposed classification, etc), computational engine name R package. goals parsnip : Separate definition model evaluation. Decouple model specification implementation (whether implementation R, spark, something else). example, user call rand_forest instead ranger::ranger specific packages. Harmonize argument names (e.g. n.trees, ntrees, trees) users need remember single name. help across model types trees argument across random forest well boosting bagging. Using example , parsnip approach : engine can easily changed. use Spark, change straightforward: Either one model specifications can fit way: list parsnip models across different CRAN packages can found tidymodels.org.","code":"# From randomForest rf_1 <- randomForest(   y ~ .,    data = .,    mtry = 10,    ntree = 2000,    importance = TRUE )  # From ranger rf_2 <- ranger(   y ~ .,    data = dat,    mtry = 10,    num.trees = 2000,    importance = \"impurity\" )  # From sparklyr rf_3 <- ml_random_forest(   dat,    intercept = FALSE,    response = \"y\",    features = names(dat)[names(dat) != \"y\"],    col.sample.rate = 10,   num.trees = 2000 ) library(parsnip)  rand_forest(mtry = 10, trees = 2000) %>%   set_engine(\"ranger\", importance = \"impurity\") %>%   set_mode(\"regression\") #> Random Forest Model Specification (regression) #>  #> Main Arguments: #>   mtry = 10 #>   trees = 2000 #>  #> Engine-Specific Arguments: #>   importance = impurity #>  #> Computational engine: ranger rand_forest(mtry = 10, trees = 2000) %>%   set_engine(\"spark\") %>%   set_mode(\"regression\") #> Random Forest Model Specification (regression) #>  #> Main Arguments: #>   mtry = 10 #>   trees = 2000 #>  #> Computational engine: spark set.seed(192) rand_forest(mtry = 10, trees = 2000) %>%   set_engine(\"ranger\", importance = \"impurity\") %>%   set_mode(\"regression\") %>%   fit(mpg ~ ., data = mtcars) #> parsnip model object #>  #> Fit time:  316ms  #> Ranger result #>  #> Call: #>  ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~10,      x), num.trees = ~2000, importance = ~\"impurity\", num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1))  #>  #> Type:                             Regression  #> Number of trees:                  2000  #> Sample size:                      32  #> Number of independent variables:  10  #> Mtry:                             10  #> Target node size:                 5  #> Variable importance mode:         impurity  #> Splitrule:                        variance  #> OOB prediction error (MSE):       5.725636  #> R squared (OOB):                  0.8423737"},{"path":"https://parsnip.tidymodels.org/dev/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"A Common API to Modeling and Analysis Functions","text":"project released Contributor Code Conduct. contributing project, agree abide terms. questions discussions tidymodels packages, modeling, machine learning, please post RStudio Community. think encountered bug, please submit issue. Either way, learn create share reprex (minimal, reproducible example), clearly communicate code. Check details contributing guidelines tidymodels packages get help.","code":""},{"path":"https://parsnip.tidymodels.org/dev/issue_template.html","id":null,"dir":"","previous_headings":"","what":"PLEASE READ: Making a new issue for parsnip","title":"PLEASE READ: Making a new issue for parsnip","text":"Please follow template . question related specific data analysis, please include minimal reprex (reproducible example). ’ve never heard reprex , start reading “reprex”, follow advice page. Tips: good example issue: #139 Issues without reprex lower priority others. don’t want use confidential data; can blind data simulate data demonstrate issue. functions caret::twoClassSim() caret::SLC14_1() might good tools simulate data . Unless problem explicitly parallel processing, please run sequentially. Even parallel processing, please make sure runs sequentially first. Please use set.seed() ensure randomness code reproducible. Please check https://stackoverflow.com/ https://community.rstudio.com/ see someone already asked question (see: Yihui’s Rule). might need install :  ready file issue, please delete parts line: < – ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ –>","code":"install.packages(c(\"reprex\", \"sessioninfo\"), repos = \"http://cran.r-project.org\")"},{"path":"https://parsnip.tidymodels.org/dev/issue_template.html","id":"the-problem","dir":"","previous_headings":"","what":"The problem","title":"PLEASE READ: Making a new issue for parsnip","text":"’m trouble … considered …","code":""},{"path":"https://parsnip.tidymodels.org/dev/issue_template.html","id":"reproducible-example","dir":"","previous_headings":"","what":"Reproducible example","title":"PLEASE READ: Making a new issue for parsnip","text":"Copy code clipboard run:","code":"reprex::reprex(si = TRUE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/C5.0_train.html","id":null,"dir":"Reference","previous_headings":"","what":"Boosted trees via C5.0 — C5.0_train","title":"Boosted trees via C5.0 — C5.0_train","text":"C5.0_train wrapper C5.0() function C50 package fits tree-based models model arguments main function.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/C5.0_train.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Boosted trees via C5.0 — C5.0_train","text":"","code":"C5.0_train(x, y, weights = NULL, trials = 15, minCases = 2, sample = 0, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/C5.0_train.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Boosted trees via C5.0 — C5.0_train","text":"x data frame matrix predictors. y factor vector 2 levels weights optional numeric vector case weights. Note data used case weights used splitting variable model (see https://www.rulequest.com/see5-info.html Quinlan's notes case weights). trials integer specifying number boosting iterations. value one indicates single model used. minCases integer smallest number samples must put least two splits. sample value (0, .999) specifies random proportion data used train model. default, samples used model training. Samples used training used evaluate accuracy model printed output. value zero means training data used. ... arguments pass.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/C5.0_train.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Boosted trees via C5.0 — C5.0_train","text":"fitted C5.0 model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/C5_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"C5.0 rule-based classification models — C5_rules","title":"C5.0 rule-based classification models — C5_rules","text":"C5_rules() defines model derives feature rules tree prediction. single tree boosted ensemble can used. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/C5_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"C5.0 rule-based classification models — C5_rules","text":"","code":"C5_rules(mode = \"classification\", trees = NULL, min_n = NULL, engine = \"C5.0\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/C5_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"C5.0 rule-based classification models — C5_rules","text":"mode single character string type model. possible value model \"classification\". trees non-negative integer (greater 100) number members ensemble. min_n integer greater zero nine minimum number data points node required node split . engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/C5_rules.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"C5.0 rule-based classification models — C5_rules","text":"C5.0 classification model extension C4.5 model Quinlan (1993). tree- rule-based versions also include boosting capabilities. C5_rules() enables version model uses series rules (see examples ). make set rules, initial C5.0 tree created flattened rules. rules pruned, simplified, ordered. Rule sets created within iteration boosting. function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/C5_rules.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"C5.0 rule-based classification models — C5_rules","text":"Quinlan R (1993). C4.5: Programs Machine Learning. Morgan Kaufmann Publishers. https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/add_on_exports.html","id":null,"dir":"Reference","previous_headings":"","what":"Functions required for parsnip-adjacent packages — null_value","title":"Functions required for parsnip-adjacent packages — null_value","text":"functions helpful creating new packages register new model specifications.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/add_on_exports.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Functions required for parsnip-adjacent packages — null_value","text":"","code":"null_value(x)  show_fit(model, eng)  update_dot_check(...)  new_model_spec(cls, args, eng_args, mode, method, engine)  check_final_param(x)  update_main_parameters(args, param)  update_engine_parameters(eng_args, ...)  is_varying(x)"},{"path":"https://parsnip.tidymodels.org/dev/reference/add_rowindex.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a column of row numbers to a data frame — add_rowindex","title":"Add a column of row numbers to a data frame — add_rowindex","text":"Add column row numbers data frame","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/add_rowindex.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Add a column of row numbers to a data frame — add_rowindex","text":"","code":"add_rowindex(x)"},{"path":"https://parsnip.tidymodels.org/dev/reference/add_rowindex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a column of row numbers to a data frame — add_rowindex","text":"x data frame","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/add_rowindex.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a column of row numbers to a data frame — add_rowindex","text":"data frame column 1-based integers named .row.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/augment.html","id":null,"dir":"Reference","previous_headings":"","what":"Augment data with predictions — augment.model_fit","title":"Augment data with predictions — augment.model_fit","text":"augment() add column(s) predictions given data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/augment.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Augment data with predictions — augment.model_fit","text":"","code":"# S3 method for model_fit augment(x, new_data, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/augment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augment data with predictions — augment.model_fit","text":"x model_fit object produced fit.model_spec() fit_xy.model_spec() . new_data data frame matrix. ... currently used.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/augment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Augment data with predictions — augment.model_fit","text":"regression models, .pred column added. x created using fit.model_spec() new_data contains outcome column, .resid column also added. classification models, results can include column called .pred_class well class probability columns named .pred_{level}. depends type prediction types available model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bag_mars.html","id":null,"dir":"Reference","previous_headings":"","what":"Ensembles of MARS models — bag_mars","title":"Ensembles of MARS models — bag_mars","text":"bag_mars() defines ensemble generalized linear models use artificial features predictors. features resemble hinge functions result model segmented regression small dimensions. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bag_mars.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Ensembles of MARS models — bag_mars","text":"","code":"bag_mars(   mode = \"unknown\",   num_terms = NULL,   prod_degree = NULL,   prune_method = NULL,   engine = \"earth\" )"},{"path":"https://parsnip.tidymodels.org/dev/reference/bag_mars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ensembles of MARS models — bag_mars","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". num_terms number features retained final model, including intercept. prod_degree highest possible interaction degree. prune_method pruning method. engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bag_mars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ensembles of MARS models — bag_mars","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bag_mars.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ensembles of MARS models — bag_mars","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/bag_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Ensembles of decision trees — bag_tree","title":"Ensembles of decision trees — bag_tree","text":"bag_tree() defines ensemble decision trees. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bag_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Ensembles of decision trees — bag_tree","text":"","code":"bag_tree(   mode = \"unknown\",   cost_complexity = 0,   tree_depth = NULL,   min_n = 2,   class_cost = NULL,   engine = \"rpart\" )"},{"path":"https://parsnip.tidymodels.org/dev/reference/bag_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ensembles of decision trees — bag_tree","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". cost_complexity positive number cost/complexity parameter (.k.. Cp) used CART models (specific engines ). tree_depth integer maximum depth tree. min_n integer minimum number data points node required node split . class_cost non-negative scalar class cost (cost 1 means extra cost). useful first level outcome factor minority class. case, values zero one can used bias second level factor. engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bag_tree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ensembles of decision trees — bag_tree","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bag_tree.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ensembles of decision trees — bag_tree","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/bart-internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Model predictions — bart-internal","title":"Model predictions — bart-internal","text":"Apply model create different types predictions. predict() can used types models uses \"type\" argument specificity.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bart-internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Model predictions — bart-internal","text":"","code":"bartMachine_interval_calc(new_data, obj, ci = TRUE, level = 0.95)  dbart_predict_calc(obj, new_data, type, level = 0.95, std_err = FALSE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/bart-internal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model predictions — bart-internal","text":"new_data rectangular data object, data frame. obj parsnip object. ci Confidence (TRUE) prediction interval (FALSE) level Confidence level. type single character value NULL. Possible values \"numeric\", \"class\", \"prob\", \"conf_int\", \"pred_int\", \"quantile\", \"time\", \"hazard\", \"survival\", \"raw\". NULL, predict() choose appropriate value based model's mode. std_err Attach column standard error prediction .","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bart-internal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model predictions — bart-internal","text":"exception type = \"raw\", results predict.model_fit() tibble many rows output rows new_data column names predictable. numeric results single outcome, tibble .pred column .pred_Yname multivariate results. hard class predictions, column named .pred_classand, type = \"prob\", columns .pred_classlevel. type = \"conf_int\" type = \"pred_int\" return tibbles columns .pred_lower .pred_upper attribute confidence level. case intervals can produces class probabilities (non-scalar outputs), columns named .pred_lower_classlevel . Quantile predictions return tibble column .pred, list-column. list element contains tibble columns .pred .quantile (perhaps columns). Using type = \"raw\" predict.model_fit() return unadulterated results prediction function. censored regression: type = \"time\" produces column .pred_time. type = \"hazard\" results column .pred_hazard. type = \"survival\" results list column containing tibbles .pred_survival column. last two types, results nested tibble overall column called .pred sub-tibbles format. case Spark-based models, since table columns contain dots, convention used except 1) dots appear names 2) vectors never returned type-specific prediction functions. model fit failed error captured, predict() function return structure filled missing values. currently work multivariate models.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bart-internal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model predictions — bart-internal","text":"\"type\" supplied predict(), choice made: type = \"numeric\" regression models, type = \"class\" classification, type = \"time\" censored regression. predict() designed provide tidy result (see \"Value\" section ) tibble output format.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bart-internal.html","id":"interval-predictions","dir":"Reference","previous_headings":"","what":"Interval predictions","title":"Model predictions — bart-internal","text":"using type = \"conf_int\" type = \"pred_int\", options level std_error can used. latter logical extra column standard error values (available).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bart-internal.html","id":"censored-regression-predictions","dir":"Reference","previous_headings":"","what":"Censored regression predictions","title":"Model predictions — bart-internal","text":"censored regression, numeric vector time required survival hazard probabilities requested. Also, type = \"linear_pred\", censored regression models default formatted linear predictor increases time. may opposite sign underlying model's predict() method produces. Set increasing = FALSE suppress behavior.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bart.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian additive regression trees (BART) — bart","title":"Bayesian additive regression trees (BART) — bart","text":"bart() defines tree ensemble model uses Bayesian analysis assemble ensemble. different ways fit model. See engine-specific pages details: engine-specific pages model listed  contain details: dbarts  (default) information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bart.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian additive regression trees (BART) — bart","text":"","code":"bart(   mode = \"unknown\",   engine = \"dbarts\",   trees = NULL,   prior_terminal_node_coef = NULL,   prior_terminal_node_expo = NULL,   prior_outcome_range = NULL )"},{"path":"https://parsnip.tidymodels.org/dev/reference/bart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian additive regression trees (BART) — bart","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". engine single character string specifying computational engine use fitting. trees integer number trees contained ensemble. prior_terminal_node_coef coefficient prior probability node terminal node. Values usually 0 one default 0.95. affects baseline probability; smaller numbers make probabilities larger overall. See Details . prior_terminal_node_expo exponent prior probability node terminal node.  Values usually non-negative default 2 affects rate prior probability decreases depth tree increases. Larger values make deeper trees less likely. prior_outcome_range positive value defines width prior predicted outcome within certain range. regression related observed range data; prior number standard deviations Gaussian distribution defined observed range data. classification, defined range +/-3 (assumed logit scale). default value 2.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bart.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian additive regression trees (BART) — bart","text":"prior terminal node probability expressed prior = * (1 + d)^(-b) d depth node, prior_terminal_node_coef b prior_terminal_node_expo. See Examples section example graph prior probability terminal node different values parameters. function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/bart.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian additive regression trees (BART) — bart","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/boost_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Boosted trees — boost_tree","title":"Boosted trees — boost_tree","text":"boost_tree() defines model creates series decision trees forming ensemble. tree depends results previous trees. trees ensemble combined produce final prediction. different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: xgboost  (default) C5.0 spark information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/boost_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Boosted trees — boost_tree","text":"","code":"boost_tree(   mode = \"unknown\",   engine = \"xgboost\",   mtry = NULL,   trees = NULL,   min_n = NULL,   tree_depth = NULL,   learn_rate = NULL,   loss_reduction = NULL,   sample_size = NULL,   stop_iter = NULL )"},{"path":"https://parsnip.tidymodels.org/dev/reference/boost_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Boosted trees — boost_tree","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". engine single character string specifying computational engine use fitting. mtry number number (proportion) predictors randomly sampled split creating tree models (specific engines ) trees integer number trees contained ensemble. min_n integer minimum number data points node required node split . tree_depth integer maximum depth tree (.e. number splits) (specific engines ). learn_rate number rate boosting algorithm adapts iteration--iteration (specific engines ). loss_reduction number reduction loss function required split (specific engines ). sample_size number number (proportion) data exposed fitting routine. xgboost, sampling done iteration C5.0 samples training. stop_iter number iterations without improvement stopping (specific engines ).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/boost_tree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Boosted trees — boost_tree","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/boost_tree.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Boosted trees — boost_tree","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/check_empty_ellipse.html","id":null,"dir":"Reference","previous_headings":"","what":"Check to ensure that ellipses are empty — check_empty_ellipse","title":"Check to ensure that ellipses are empty — check_empty_ellipse","text":"Check ensure ellipses empty","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/check_empty_ellipse.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Check to ensure that ellipses are empty — check_empty_ellipse","text":"","code":"check_empty_ellipse(...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/check_empty_ellipse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check to ensure that ellipses are empty — check_empty_ellipse","text":"... Extra arguments.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/check_empty_ellipse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check to ensure that ellipses are empty — check_empty_ellipse","text":"error thrown (non-empty ellipses), NULL list.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/contr_one_hot.html","id":null,"dir":"Reference","previous_headings":"","what":"Contrast function for one-hot encodings — contr_one_hot","title":"Contrast function for one-hot encodings — contr_one_hot","text":"contrast function produces model matrix indicator columns level factor.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/contr_one_hot.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Contrast function for one-hot encodings — contr_one_hot","text":"","code":"contr_one_hot(n, contrasts = TRUE, sparse = FALSE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/contr_one_hot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Contrast function for one-hot encodings — contr_one_hot","text":"n vector character factor levels number unique levels. contrasts argument backwards compatibility default TRUE supported. sparse argument backwards compatibility default FALSE supported.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/contr_one_hot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Contrast function for one-hot encodings — contr_one_hot","text":"diagonal matrix n--n.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/contr_one_hot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Contrast function for one-hot encodings — contr_one_hot","text":"default, model.matrix() generates binary indicator variables factor predictors. formula remove intercept, incomplete set indicators created; indicator made first level factor. example, species island three levels model.matrix() creates two indicator variables :      formula intercept, first factor expanded indicators factor levels factors expanded one ():  inference, hybrid encoding can problematic. generate indicators, use contrast:    Removing intercept affect factor encodings.","code":"library(dplyr) library(modeldata) data(penguins)  levels(penguins$species) ## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\" levels(penguins$island) ## [1] \"Biscoe\"    \"Dream\"     \"Torgersen\" model.matrix(~ species + island, data = penguins) %>%    colnames() ## [1] \"(Intercept)\"      \"speciesChinstrap\" \"speciesGentoo\"    \"islandDream\"      ## [5] \"islandTorgersen\" model.matrix(~ 0 + species + island, data = penguins) %>%    colnames() ## [1] \"speciesAdelie\"    \"speciesChinstrap\" \"speciesGentoo\"    \"islandDream\"      ## [5] \"islandTorgersen\" # Switch out the contrast method old_contr <- options(\"contrasts\")$contrasts new_contr <- old_contr new_contr[\"unordered\"] <- \"contr_one_hot\" options(contrasts = new_contr)  model.matrix(~ species + island, data = penguins) %>%    colnames() ## [1] \"(Intercept)\"      \"speciesAdelie\"    \"speciesChinstrap\" \"speciesGentoo\"    ## [5] \"islandBiscoe\"     \"islandDream\"      \"islandTorgersen\" options(contrasts = old_contr)"},{"path":"https://parsnip.tidymodels.org/dev/reference/control_parsnip.html","id":null,"dir":"Reference","previous_headings":"","what":"Control the fit function — control_parsnip","title":"Control the fit function — control_parsnip","text":"Options can passed fit.model_spec() function control output computations","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/control_parsnip.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Control the fit function — control_parsnip","text":"","code":"control_parsnip(verbosity = 1L, catch = FALSE)  fit_control(verbosity = 1L, catch = FALSE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/control_parsnip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control the fit function — control_parsnip","text":"verbosity integer value zero indicates messages output shown packages loaded model fit. value 1 means package loading quiet model fits can produce output screen (depending contain verbose-type argument). value 2 indicates output seen. catch logical value TRUE evaluate model inside try(, silent = TRUE). model fails, object still returned (without error) inherits class \"try-error\".","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/control_parsnip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control the fit function — control_parsnip","text":"S3 object class \"fit_control\" named list results function call","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/control_parsnip.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Control the fit function — control_parsnip","text":"fit_control() deprecated favor control_parsnip().","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/convert_helpers.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper functions to convert between formula and matrix interface — .convert_form_to_xy_fit","title":"Helper functions to convert between formula and matrix interface — .convert_form_to_xy_fit","text":"Functions take formula interface get resulting objects (y, x, weights, etc) back way around. functions intended developer use. part, emulates internals lm() (also see notes https://developer.r-project.org/model-fitting-functions.html). .convert_form_to_xy_fit() .convert_xy_to_form_fit() data created modeling. .convert_form_to_xy_fit() saves data objects well objects needed new data predicted (e.g. terms, etc.). .convert_form_to_xy_new() .convert_xy_to_form_new() used new samples predicted require predictors available.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/convert_helpers.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Helper functions to convert between formula and matrix interface — .convert_form_to_xy_fit","text":"","code":".convert_form_to_xy_fit(   formula,   data,   ...,   na.action = na.omit,   indicators = \"traditional\",   composition = \"data.frame\",   remove_intercept = TRUE )  .convert_form_to_xy_new(   object,   new_data,   na.action = na.pass,   composition = \"data.frame\" )  .convert_xy_to_form_fit(   x,   y,   weights = NULL,   y_name = \"..y\",   remove_intercept = TRUE )  .convert_xy_to_form_new(object, new_data)"},{"path":"https://parsnip.tidymodels.org/dev/reference/convert_helpers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper functions to convert between formula and matrix interface — .convert_form_to_xy_fit","text":"formula object class formula (one can coerced class): symbolic description model fitted. data data frame containing relevant variables (e.g. outcome(s), predictors, case weights, etc). ... Additional arguments passed stats::model.frame(). na.action function indicates happen data contain NAs. indicators string describing whether create indicator/dummy variables factor predictors. Possible options \"none\", \"traditional\", \"one_hot\". composition string describing whether resulting x y returned \"matrix\" \"data.frame\". remove_intercept logical indicating whether remove intercept column model.matrix() finished. object object class model_fit. new_data rectangular data object, data frame. x matrix, sparse matrix, data frame predictors. models support sparse matrix input. See parsnip::get_encoding() details. x column names. y vector, matrix data frame outcome data. weights numeric vector containing weights. y_name string specifying name outcome.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/convert_stan_interval.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenience function for intervals — convert_stan_interval","title":"Convenience function for intervals — convert_stan_interval","text":"Convenience function intervals","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/convert_stan_interval.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Convenience function for intervals — convert_stan_interval","text":"","code":"convert_stan_interval(x, level = 0.95, lower = TRUE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/convert_stan_interval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenience function for intervals — convert_stan_interval","text":"x fitted model object level Level uncertainty intervals lower level lower level?","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/cubist_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Cubist rule-based regression models — cubist_rules","title":"Cubist rule-based regression models — cubist_rules","text":"cubist_rules() defines model derives simple feature rules tree ensemble creates regression models within rule. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/cubist_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Cubist rule-based regression models — cubist_rules","text":"","code":"cubist_rules(   mode = \"regression\",   committees = NULL,   neighbors = NULL,   max_rules = NULL,   engine = \"Cubist\" )"},{"path":"https://parsnip.tidymodels.org/dev/reference/cubist_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cubist rule-based regression models — cubist_rules","text":"mode single character string type model. possible value model \"regression\". committees non-negative integer (greater 100) number members ensemble. neighbors integer zero nine number training set instances used adjust model-based prediction. max_rules largest number rules. engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/cubist_rules.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cubist rule-based regression models — cubist_rules","text":"Cubist rule-based ensemble regression model. basic model tree (Quinlan, 1992) created separate linear regression model corresponding terminal node. paths along model tree flattened rules rules simplified pruned. parameter min_n primary method controlling size tree max_rules controls number rules. Cubist ensembles created using committees, similar boosting. first model committee created, second model uses modified version outcome data based whether previous model - -predicted outcome. iteration m, new outcome y* computed using  sample -predicted previous iteration, outcome adjusted next time likely -predicted compensate. adjustment continues ensemble iteration. See Kuhn Johnson (2013) details. model created, also option post-hoc adjustment uses training set (Quinlan, 1993). new sample predicted model, can modified nearest neighbors original training set. K neighbors, model-based predicted value adjusted neighbor using:  t training set prediction w weight inverse distance neighbor. function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/cubist_rules.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cubist rule-based regression models — cubist_rules","text":"https://www.tidymodels.org, Tidy Modeling R Quinlan R (1992). \"Learning Continuous Classes.\" Proceedings 5th Australian Joint Conference Artificial Intelligence, pp. 343-348. Quinlan R (1993).\"Combining Instance-Based Model-Based Learning.\" Proceedings Tenth International Conference Machine Learning, pp. 236-243. Kuhn M Johnson K (2013). Applied Predictive Modeling. Springer.","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/decision_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Decision trees — decision_tree","title":"Decision trees — decision_tree","text":"decision_tree() defines model set /statements creates tree-based structure. different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: rpart  (default) C5.0 spark information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/decision_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Decision trees — decision_tree","text":"","code":"decision_tree(   mode = \"unknown\",   engine = \"rpart\",   cost_complexity = NULL,   tree_depth = NULL,   min_n = NULL )"},{"path":"https://parsnip.tidymodels.org/dev/reference/decision_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decision trees — decision_tree","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". engine single character string specifying computational engine use fitting. cost_complexity positive number cost/complexity parameter (.k.. Cp) used CART models (specific engines ). tree_depth integer maximum depth tree. min_n integer minimum number data points node required node split .","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/decision_tree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Decision trees — decision_tree","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/decision_tree.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Decision trees — decision_tree","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/descriptors.html","id":null,"dir":"Reference","previous_headings":"","what":"Data Set Characteristics Available when Fitting Models — descriptors","title":"Data Set Characteristics Available when Fitting Models — descriptors","text":"using fit() functions variables available use arguments. example, user like choose argument value based current number rows data set, .obs() function can used. See Details .","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/descriptors.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Data Set Characteristics Available when Fitting Models — descriptors","text":"","code":".cols()  .preds()  .obs()  .lvls()  .facts()  .x()  .y()  .dat()"},{"path":"https://parsnip.tidymodels.org/dev/reference/descriptors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data Set Characteristics Available when Fitting Models — descriptors","text":"Existing functions: .obs(): current number rows data set. .preds(): number columns data set associated predictors prior dummy variable creation. .cols(): number predictor columns available dummy variables created (). .facts(): number factor predictors data set. .lvls(): outcome factor, table counts level (NA otherwise). .x(): predictors returned format given. Either data frame matrix. .y(): known outcomes returned format given. Either vector, matrix, data frame. .dat(): data frame containing predictors outcomes. fit_xy() used, outcomes attached column, ..y. example, use model formula circumference ~ . built-Orange data, values formula Tree ~ . used: use model fit, pass model specification. evaluation delayed time model run via fit() (variables listed available). example: descriptors found, computation descriptor values executed.","code":".preds() =   2          (the 2 remaining columns in `Orange`)  .cols()  =   5          (1 numeric column + 4 from Tree dummy variables)  .obs()   = 35  .lvls()  =  NA          (no factor outcome)  .facts() =   1          (the Tree predictor)  .y()     = <vector>     (circumference as a vector)  .x()     = <data.frame> (The other 2 columns as a data frame)  .dat()   = <data.frame> (The full data set) .preds() =   2          (the 2 numeric columns in `Orange`)  .cols()  =   2          (same)  .obs()   = 35  .lvls()  =  c(\"1\" = 7, \"2\" = 7, \"3\" = 7, \"4\" = 7, \"5\" = 7)  .facts() =   0  .y()     = <vector>     (Tree as a vector)  .x()     = <data.frame> (The other 2 columns as a data frame)  .dat()   = <data.frame> (The full data set) library(modeldata) data(\"lending_club\")  rand_forest(mode = \"classification\", mtry = .cols() - 2)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_bart_dbarts.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian additive regression trees via dbarts — details_bart_dbarts","title":"Bayesian additive regression trees via dbarts — details_bart_dbarts","text":"dbarts::bart() creates ensemble tree-based model whose training assembly determined using Bayesian analysis.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_bart_dbarts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian additive regression trees via dbarts — details_bart_dbarts","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_bart_dbarts.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Bayesian additive regression trees via dbarts — details_bart_dbarts","text":"model 4 tuning parameters: trees: # Trees (type: integer, default: 200L) prior_terminal_node_coef: Terminal Node Prior Coefficient (type: double, default: 0.95) prior_terminal_node_expo: Terminal Node Prior Exponent (type: double, default: 2.00) prior_outcome_range: Prior Outcome Range (type: double, default: 2.00)","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_bart_dbarts.html","id":"important-engine-specific-options","dir":"Reference","previous_headings":"","what":"Important engine-specific options","title":"Bayesian additive regression trees via dbarts — details_bart_dbarts","text":"relevant arguments can passed set_engine(): keepevery, n.thin: Every keepevery draw kept returned user. Useful “thinning” samples. ntree, n.trees: number trees sum--trees formulation. ndpost, n.samples: number posterior draws burn , ndpost / keepevery actually returned. nskip, n.burn: Number MCMC iterations treated burn . nchain, n.chains: Integer specifying many independent tree sets fits calculated. nthread, n.threads: Integer specifying many threads use. Depending CPU architecture, using number chains can degrade performance small/medium data sets. calculations may executed single threaded regardless. combinechains, combineChains: Logical; TRUE, samples returned arrays dimensions equal nchain times ndpost times number observations.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_bart_dbarts.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Bayesian additive regression trees via dbarts — details_bart_dbarts","text":"","code":"bart(   trees = integer(1),   prior_terminal_node_coef = double(1),   prior_terminal_node_expo = double(1),   prior_outcome_range = double(1) ) %>%    set_engine(\"dbarts\") %>%    set_mode(\"classification\") %>%    translate() ## BART Model Specification (classification) ##  ## Main Arguments: ##   trees = integer(1) ##   prior_terminal_node_coef = double(1) ##   prior_terminal_node_expo = double(1) ##   prior_outcome_range = double(1) ##  ## Computational engine: dbarts  ##  ## Model fit template: ## dbarts::bart(x = missing_arg(), y = missing_arg(), ntree = integer(1),  ##     base = double(1), power = double(1), k = double(1), verbose = FALSE,  ##     keeptrees = TRUE, keepcall = FALSE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_bart_dbarts.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Bayesian additive regression trees via dbarts — details_bart_dbarts","text":"","code":"bart(   trees = integer(1),   prior_terminal_node_coef = double(1),   prior_terminal_node_expo = double(1),   prior_outcome_range = double(1) ) %>%    set_engine(\"dbarts\") %>%    set_mode(\"regression\") %>%    translate() ## BART Model Specification (regression) ##  ## Main Arguments: ##   trees = integer(1) ##   prior_terminal_node_coef = double(1) ##   prior_terminal_node_expo = double(1) ##   prior_outcome_range = double(1) ##  ## Computational engine: dbarts  ##  ## Model fit template: ## dbarts::bart(x = missing_arg(), y = missing_arg(), ntree = integer(1),  ##     base = double(1), power = double(1), k = double(1), verbose = FALSE,  ##     keeptrees = TRUE, keepcall = FALSE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_bart_dbarts.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Bayesian additive regression trees via dbarts — details_bart_dbarts","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. dbarts::bart() also convert factors indicators user create first.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_bart_dbarts.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian additive regression trees via dbarts — details_bart_dbarts","text":"Chipman, George, McCulloch. “BART: Bayesian additive regression trees.” Ann. Appl. Stat. 4 (1) 266 - 298, March 2010.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_C5.0.html","id":null,"dir":"Reference","previous_headings":"","what":"Boosted trees via C5.0 — details_boost_tree_C5.0","title":"Boosted trees via C5.0 — details_boost_tree_C5.0","text":"C50::C5.0() creates series classification trees forming ensemble. tree depends results previous trees. trees ensemble combined produce final prediction.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_C5.0.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Boosted trees via C5.0 — details_boost_tree_C5.0","text":"engine, single mode: classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_C5.0.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Boosted trees via C5.0 — details_boost_tree_C5.0","text":"model 3 tuning parameters: trees: # Trees (type: integer, default: 15L) min_n: Minimal Node Size (type: integer, default: 2L) sample_size: Proportion Observations Sampled (type: double, default: 1.0) implementation C5.0 limits number trees 1 100.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_C5.0.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Boosted trees via C5.0 — details_boost_tree_C5.0","text":"C5.0_train() wrapper around C50::C5.0() makes easier run model.","code":"boost_tree(trees = integer(), min_n = integer(), sample_size = numeric()) %>%    set_engine(\"C5.0\") %>%    set_mode(\"classification\") %>%    translate() ## Boosted Tree Model Specification (classification) ##  ## Main Arguments: ##   trees = integer() ##   min_n = integer() ##   sample_size = numeric() ##  ## Computational engine: C5.0  ##  ## Model fit template: ## parsnip::C5.0_train(x = missing_arg(), y = missing_arg(), weights = missing_arg(),  ##     trials = integer(), minCases = integer(), sample = numeric())"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_C5.0.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Boosted trees via C5.0 — details_boost_tree_C5.0","text":"engine require special encoding predictors. Categorical predictors can partitioned groups factor levels (e.g. {, c} vs {b, d}) splitting node. Dummy variables required model.","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_C5.0.html","id":"early-stopping","dir":"Reference","previous_headings":"","what":"Early stopping","title":"Boosted trees via C5.0 — details_boost_tree_C5.0","text":"default, early stopping used. use complete set boosting iterations, pass earlyStopping = FALSE set_engine(). Also, unlikely early stopping occur sample_size = 1.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_C5.0.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Boosted trees via C5.0 — details_boost_tree_C5.0","text":"“Fitting Predicting parsnip” article contains examples boost_tree() \"C5.0\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_C5.0.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Boosted trees via C5.0 — details_boost_tree_C5.0","text":"Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_spark.html","id":null,"dir":"Reference","previous_headings":"","what":"Boosted trees via Spark — details_boost_tree_spark","title":"Boosted trees via Spark — details_boost_tree_spark","text":"sparklyr::ml_gradient_boosted_trees() creates series decision trees forming ensemble. tree depends results previous trees. trees ensemble combined produce final prediction.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_spark.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Boosted trees via Spark — details_boost_tree_spark","text":"engine, multiple modes: classification regression. However, multiclass classification supported yet.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_spark.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Boosted trees via Spark — details_boost_tree_spark","text":"model 7 tuning parameters: tree_depth: Tree Depth (type: integer, default: 5L) trees: # Trees (type: integer, default: 20L) learn_rate: Learning Rate (type: double, default: 0.1) mtry: # Randomly Selected Predictors (type: integer, default: see ) min_n: Minimal Node Size (type: integer, default: 1L) loss_reduction: Minimum Loss Reduction (type: double, default: 0.0) sample_size: # Observations Sampled (type: integer, default: 1.0) mtry parameter related number predictors. default depends model mode. classification, square root number predictors used regression, one third predictors sampled.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_spark.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Boosted trees via Spark — details_boost_tree_spark","text":"","code":"boost_tree(   mtry = integer(), trees = integer(), min_n = integer(), tree_depth = integer(),   learn_rate = numeric(), loss_reduction = numeric(), sample_size = numeric() ) %>%   set_engine(\"spark\") %>%   set_mode(\"regression\") %>%   translate() ## Boosted Tree Model Specification (regression) ##  ## Main Arguments: ##   mtry = integer() ##   trees = integer() ##   min_n = integer() ##   tree_depth = integer() ##   learn_rate = numeric() ##   loss_reduction = numeric() ##   sample_size = numeric() ##  ## Computational engine: spark  ##  ## Model fit template: ## sparklyr::ml_gradient_boosted_trees(x = missing_arg(), formula = missing_arg(),  ##     type = \"regression\", feature_subset_strategy = integer(),  ##     max_iter = integer(), min_instances_per_node = min_rows(integer(0),  ##         x), max_depth = integer(), step_size = numeric(), min_info_gain = numeric(),  ##     subsampling_rate = numeric(), seed = sample.int(10^5, 1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_spark.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Boosted trees via Spark — details_boost_tree_spark","text":"","code":"boost_tree(   mtry = integer(), trees = integer(), min_n = integer(), tree_depth = integer(),   learn_rate = numeric(), loss_reduction = numeric(), sample_size = numeric() ) %>%    set_engine(\"spark\") %>%    set_mode(\"classification\") %>%    translate() ## Boosted Tree Model Specification (classification) ##  ## Main Arguments: ##   mtry = integer() ##   trees = integer() ##   min_n = integer() ##   tree_depth = integer() ##   learn_rate = numeric() ##   loss_reduction = numeric() ##   sample_size = numeric() ##  ## Computational engine: spark  ##  ## Model fit template: ## sparklyr::ml_gradient_boosted_trees(x = missing_arg(), formula = missing_arg(),  ##     type = \"classification\", feature_subset_strategy = integer(),  ##     max_iter = integer(), min_instances_per_node = min_rows(integer(0),  ##         x), max_depth = integer(), step_size = numeric(), min_info_gain = numeric(),  ##     subsampling_rate = numeric(), seed = sample.int(10^5, 1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_spark.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Boosted trees via Spark — details_boost_tree_spark","text":"engine require special encoding predictors. Categorical predictors can partitioned groups factor levels (e.g. {, c} vs {b, d}) splitting node. Dummy variables required model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_spark.html","id":"other-details","dir":"Reference","previous_headings":"","what":"Other details","title":"Boosted trees via Spark — details_boost_tree_spark","text":"models created using \"spark\" engine, several things consider. formula interface via fit() available; using fit_xy() generate error. predictions always Spark table format. names documented without dots. equivalent factor columns Spark tables class predictions returned character columns. retain model object new R session (via save()), model$fit element parsnip object serialized via ml_save(object$fit) separately saved disk. new session, object can reloaded reattached parsnip object.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_spark.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Boosted trees via Spark — details_boost_tree_spark","text":"Luraschi, J, K Kuo, E Ruiz. 2019. Mastering Spark R. O’Reilly Media Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_xgboost.html","id":null,"dir":"Reference","previous_headings":"","what":"Boosted trees via xgboost — details_boost_tree_xgboost","title":"Boosted trees via xgboost — details_boost_tree_xgboost","text":"xgboost::xgb.train() creates series decision trees forming ensemble. tree depends results previous trees. trees ensemble combined produce final prediction.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_xgboost.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Boosted trees via xgboost — details_boost_tree_xgboost","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_xgboost.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Boosted trees via xgboost — details_boost_tree_xgboost","text":"model 8 tuning parameters: tree_depth: Tree Depth (type: integer, default: 6L) trees: # Trees (type: integer, default: 15L) learn_rate: Learning Rate (type: double, default: 0.3) mtry: # Randomly Selected Predictors (type: integer, default: see ) min_n: Minimal Node Size (type: integer, default: 1L) loss_reduction: Minimum Loss Reduction (type: double, default: 0.0) sample_size: Proportion Observations Sampled (type: double, default: 1.0) stop_iter: # Iterations Stopping (type: integer, default: Inf) mtry parameter related number predictors. default use predictors. xgboost::xgb.train() encodes real number zero one. parsnip translates number columns type value. user give argument boost_tree() integer (real number).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_xgboost.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Boosted trees via xgboost — details_boost_tree_xgboost","text":"","code":"boost_tree(   mtry = integer(), trees = integer(), min_n = integer(), tree_depth = integer(),   learn_rate = numeric(), loss_reduction = numeric(), sample_size = numeric(),   stop_iter = integer() ) %>%   set_engine(\"xgboost\") %>%   set_mode(\"regression\") %>%   translate() ## Boosted Tree Model Specification (regression) ##  ## Main Arguments: ##   mtry = integer() ##   trees = integer() ##   min_n = integer() ##   tree_depth = integer() ##   learn_rate = numeric() ##   loss_reduction = numeric() ##   sample_size = numeric() ##   stop_iter = integer() ##  ## Computational engine: xgboost  ##  ## Model fit template: ## parsnip::xgb_train(x = missing_arg(), y = missing_arg(), colsample_bynode = integer(),  ##     nrounds = integer(), min_child_weight = integer(), max_depth = integer(),  ##     eta = numeric(), gamma = numeric(), subsample = numeric(),  ##     early_stop = integer(), nthread = 1, verbose = 0)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_xgboost.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Boosted trees via xgboost — details_boost_tree_xgboost","text":"xgb_train() wrapper around xgboost::xgb.train() (functions) makes easier run model.","code":"boost_tree(   mtry = integer(), trees = integer(), min_n = integer(), tree_depth = integer(),   learn_rate = numeric(), loss_reduction = numeric(), sample_size = numeric(),   stop_iter = integer() ) %>%    set_engine(\"xgboost\") %>%    set_mode(\"classification\") %>%    translate() ## Boosted Tree Model Specification (classification) ##  ## Main Arguments: ##   mtry = integer() ##   trees = integer() ##   min_n = integer() ##   tree_depth = integer() ##   learn_rate = numeric() ##   loss_reduction = numeric() ##   sample_size = numeric() ##   stop_iter = integer() ##  ## Computational engine: xgboost  ##  ## Model fit template: ## parsnip::xgb_train(x = missing_arg(), y = missing_arg(), colsample_bynode = integer(),  ##     nrounds = integer(), min_child_weight = integer(), max_depth = integer(),  ##     eta = numeric(), gamma = numeric(), subsample = numeric(),  ##     early_stop = integer(), nthread = 1, verbose = 0)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_xgboost.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Boosted trees via xgboost — details_boost_tree_xgboost","text":"xgboost means translate factor predictors grouped splits. Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators using one-hot encoding. classification, non-numeric outcomes (.e., factors) internally converted numeric. binary classification, event_level argument set_engine() can set either \"first\" \"second\" specify level used event. can helpful watchlist used monitor performance xgboost training process.","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_xgboost.html","id":"sparse-matrices","dir":"Reference","previous_headings":"","what":"Sparse matrices","title":"Boosted trees via xgboost — details_boost_tree_xgboost","text":"xgboost requires data sparse format. predictor data already format, use fit_xy.model_spec() pass model function. Otherwise, parsnip converts data format.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_xgboost.html","id":"parallel-processing","dir":"Reference","previous_headings":"","what":"Parallel processing","title":"Boosted trees via xgboost — details_boost_tree_xgboost","text":"default, model trained without parallel processing. can change passing nthread parameter set_engine(). However, unwise combine external parallel processing using package.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_xgboost.html","id":"early-stopping","dir":"Reference","previous_headings":"","what":"Early stopping","title":"Boosted trees via xgboost — details_boost_tree_xgboost","text":"stop_iter() argument allows model prematurely stop training objective function improve within early_stop iterations. best way use feature conjunction internal validation set. , pass validation parameter xgb_train() via parsnip set_engine() function. proportion training set reserved measuring performance (stop early). model specification early_stop >= trees, early_stop converted trees - 1 warning issued.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_xgboost.html","id":"objective-function","dir":"Reference","previous_headings":"","what":"Objective function","title":"Boosted trees via xgboost — details_boost_tree_xgboost","text":"parsnip chooses objective function based characteristics outcome. use different loss, pass objective argument set_engine().","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_xgboost.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Boosted trees via xgboost — details_boost_tree_xgboost","text":"“Fitting Predicting parsnip” article contains examples boost_tree() \"xgboost\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_boost_tree_xgboost.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Boosted trees via xgboost — details_boost_tree_xgboost","text":"XGBoost: Scalable Tree Boosting System Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_C5.0.html","id":null,"dir":"Reference","previous_headings":"","what":"Decision trees via C5.0 — details_decision_tree_C5.0","title":"Decision trees via C5.0 — details_decision_tree_C5.0","text":"C50::C5.0() fits model set /statements creates tree-based structure.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_C5.0.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Decision trees via C5.0 — details_decision_tree_C5.0","text":"engine, single mode: classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_C5.0.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Decision trees via C5.0 — details_decision_tree_C5.0","text":"model 1 tuning parameters: min_n: Minimal Node Size (type: integer, default: 2L)","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_C5.0.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Decision trees via C5.0 — details_decision_tree_C5.0","text":"C5.0_train() wrapper around C50::C5.0() makes easier run model.","code":"decision_tree(min_n = integer()) %>%    set_engine(\"C5.0\") %>%    set_mode(\"classification\") %>%    translate() ## Decision Tree Model Specification (classification) ##  ## Main Arguments: ##   min_n = integer() ##  ## Computational engine: C5.0  ##  ## Model fit template: ## parsnip::C5.0_train(x = missing_arg(), y = missing_arg(), weights = missing_arg(),  ##     minCases = integer(), trials = 1)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_C5.0.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Decision trees via C5.0 — details_decision_tree_C5.0","text":"engine require special encoding predictors. Categorical predictors can partitioned groups factor levels (e.g. {, c} vs {b, d}) splitting node. Dummy variables required model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_C5.0.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decision trees via C5.0 — details_decision_tree_C5.0","text":"“Fitting Predicting parsnip” article contains examples decision_tree() \"C5.0\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_C5.0.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Decision trees via C5.0 — details_decision_tree_C5.0","text":"Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_rpart.html","id":null,"dir":"Reference","previous_headings":"","what":"Decision trees via CART — details_decision_tree_rpart","title":"Decision trees via CART — details_decision_tree_rpart","text":"rpart::rpart() fits model set /statements creates tree-based structure.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_rpart.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Decision trees via CART — details_decision_tree_rpart","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_rpart.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Decision trees via CART — details_decision_tree_rpart","text":"model 3 tuning parameters: tree_depth: Tree Depth (type: integer, default: 30L) min_n: Minimal Node Size (type: integer, default: 2L) cost_complexity: Cost-Complexity Parameter (type: double, default: 0.01)","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_rpart.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Decision trees via CART — details_decision_tree_rpart","text":"","code":"decision_tree(tree_depth = integer(1), min_n = integer(1), cost_complexity = double(1)) %>%    set_engine(\"rpart\") %>%    set_mode(\"classification\") %>%    translate() ## Decision Tree Model Specification (classification) ##  ## Main Arguments: ##   cost_complexity = double(1) ##   tree_depth = integer(1) ##   min_n = integer(1) ##  ## Computational engine: rpart  ##  ## Model fit template: ## rpart::rpart(formula = missing_arg(), data = missing_arg(), weights = missing_arg(),  ##     cp = double(1), maxdepth = integer(1), minsplit = min_rows(0L,  ##         data))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_rpart.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Decision trees via CART — details_decision_tree_rpart","text":"","code":"decision_tree(tree_depth = integer(1), min_n = integer(1), cost_complexity = double(1)) %>%    set_engine(\"rpart\") %>%    set_mode(\"regression\") %>%    translate() ## Decision Tree Model Specification (regression) ##  ## Main Arguments: ##   cost_complexity = double(1) ##   tree_depth = integer(1) ##   min_n = integer(1) ##  ## Computational engine: rpart  ##  ## Model fit template: ## rpart::rpart(formula = missing_arg(), data = missing_arg(), weights = missing_arg(),  ##     cp = double(1), maxdepth = integer(1), minsplit = min_rows(0L,  ##         data))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_rpart.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Decision trees via CART — details_decision_tree_rpart","text":"engine require special encoding predictors. Categorical predictors can partitioned groups factor levels (e.g. {, c} vs {b, d}) splitting node. Dummy variables required model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_rpart.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decision trees via CART — details_decision_tree_rpart","text":"“Fitting Predicting parsnip” article contains examples decision_tree() \"rpart\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_rpart.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Decision trees via CART — details_decision_tree_rpart","text":"Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_spark.html","id":null,"dir":"Reference","previous_headings":"","what":"Decision trees via Spark — details_decision_tree_spark","title":"Decision trees via Spark — details_decision_tree_spark","text":"sparklyr::ml_decision_tree() fits model set /statements creates tree-based structure.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_spark.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Decision trees via Spark — details_decision_tree_spark","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_spark.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Decision trees via Spark — details_decision_tree_spark","text":"model 2 tuning parameters: tree_depth: Tree Depth (type: integer, default: 5L) min_n: Minimal Node Size (type: integer, default: 1L)","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_spark.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Decision trees via Spark — details_decision_tree_spark","text":"","code":"decision_tree(tree_depth = integer(1), min_n = integer(1)) %>%    set_engine(\"spark\") %>%    set_mode(\"classification\") %>%    translate() ## Decision Tree Model Specification (classification) ##  ## Main Arguments: ##   tree_depth = integer(1) ##   min_n = integer(1) ##  ## Computational engine: spark  ##  ## Model fit template: ## sparklyr::ml_decision_tree_classifier(x = missing_arg(), formula = missing_arg(),  ##     max_depth = integer(1), min_instances_per_node = min_rows(0L,  ##         x), seed = sample.int(10^5, 1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_spark.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Decision trees via Spark — details_decision_tree_spark","text":"","code":"decision_tree(tree_depth = integer(1), min_n = integer(1)) %>%    set_engine(\"spark\") %>%    set_mode(\"regression\") %>%    translate() ## Decision Tree Model Specification (regression) ##  ## Main Arguments: ##   tree_depth = integer(1) ##   min_n = integer(1) ##  ## Computational engine: spark  ##  ## Model fit template: ## sparklyr::ml_decision_tree_regressor(x = missing_arg(), formula = missing_arg(),  ##     max_depth = integer(1), min_instances_per_node = min_rows(0L,  ##         x), seed = sample.int(10^5, 1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_spark.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Decision trees via Spark — details_decision_tree_spark","text":"engine require special encoding predictors. Categorical predictors can partitioned groups factor levels (e.g. {, c} vs {b, d}) splitting node. Dummy variables required model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_spark.html","id":"other-details","dir":"Reference","previous_headings":"","what":"Other details","title":"Decision trees via Spark — details_decision_tree_spark","text":"models created using \"spark\" engine, several things consider. formula interface via fit() available; using fit_xy() generate error. predictions always Spark table format. names documented without dots. equivalent factor columns Spark tables class predictions returned character columns. retain model object new R session (via save()), model$fit element parsnip object serialized via ml_save(object$fit) separately saved disk. new session, object can reloaded reattached parsnip object.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_decision_tree_spark.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Decision trees via Spark — details_decision_tree_spark","text":"Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_gen_additive_mod_mgcv.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized additive models via mgcv — details_gen_additive_mod_mgcv","title":"Generalized additive models via mgcv — details_gen_additive_mod_mgcv","text":"mgcv::gam() fits generalized linear model additive smoother terms continuous predictors.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_gen_additive_mod_mgcv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized additive models via mgcv — details_gen_additive_mod_mgcv","text":"engine, multiple modes: regression classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_gen_additive_mod_mgcv.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Generalized additive models via mgcv — details_gen_additive_mod_mgcv","text":"model 2 tuning parameters: select_features: Select Features? (type: logical, default: FALSE) adjust_deg_free: Smoothness Adjustment (type: double, default: 1.0)","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_gen_additive_mod_mgcv.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Generalized additive models via mgcv — details_gen_additive_mod_mgcv","text":"","code":"gen_additive_mod(adjust_deg_free = numeric(1), select_features = logical(1)) %>%    set_engine(\"mgcv\") %>%    set_mode(\"regression\") %>%    translate() ## GAM Specification (regression) ##  ## Main Arguments: ##   select_features = logical(1) ##   adjust_deg_free = numeric(1) ##  ## Computational engine: mgcv  ##  ## Model fit template: ## mgcv::gam(formula = missing_arg(), data = missing_arg(), select = logical(1),  ##     gamma = numeric(1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_gen_additive_mod_mgcv.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Generalized additive models via mgcv — details_gen_additive_mod_mgcv","text":"","code":"gen_additive_mod(adjust_deg_free = numeric(1), select_features = logical(1)) %>%    set_engine(\"mgcv\") %>%    set_mode(\"classification\") %>%    translate() ## GAM Specification (classification) ##  ## Main Arguments: ##   select_features = logical(1) ##   adjust_deg_free = numeric(1) ##  ## Computational engine: mgcv  ##  ## Model fit template: ## mgcv::gam(formula = missing_arg(), data = missing_arg(), select = logical(1),  ##     gamma = numeric(1), family = stats::binomial(link = \"logit\"))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_gen_additive_mod_mgcv.html","id":"model-fitting","dir":"Reference","previous_headings":"","what":"Model fitting","title":"Generalized additive models via mgcv — details_gen_additive_mod_mgcv","text":"model used model formula smooth terms can specified. example:  smoothness terms need manually specified (e.g., using s(x, df = 10)) formula. Tuning can accomplished using adjust_deg_free parameter.","code":"library(mgcv) gen_additive_mod() %>%    set_engine(\"mgcv\") %>%    set_mode(\"regression\") %>%    fit(mpg ~ wt + gear + cyl + s(disp, k = 10), data = mtcars) ## parsnip model object ##  ## Fit time:  21ms  ##  ## Family: gaussian  ## Link function: identity  ##  ## Formula: ## mpg ~ wt + gear + cyl + s(disp, k = 10) ##  ## Estimated degrees of freedom: ## 7.52  total = 11.52  ##  ## GCV score: 4.225228"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_gen_additive_mod_mgcv.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Generalized additive models via mgcv — details_gen_additive_mod_mgcv","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_gen_additive_mod_mgcv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized additive models via mgcv — details_gen_additive_mod_mgcv","text":"Ross, W. 2021. Generalized Additive Models R: Free, Interactive Course using mgcv Wood, S. 2017. Generalized Additive Models: Introduction R. Chapman Hall/CRC.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_glmnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear regression via glmnet — details_linear_reg_glmnet","title":"Linear regression via glmnet — details_linear_reg_glmnet","text":"glmnet::glmnet() uses regularized least squares fit models numeric outcomes.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_glmnet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear regression via glmnet — details_linear_reg_glmnet","text":"engine, single mode: regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_glmnet.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Linear regression via glmnet — details_linear_reg_glmnet","text":"model 2 tuning parameters: penalty: Amount Regularization (type: double, default: see ) mixture: Proportion Lasso Penalty (type: double, default: 1.0) value mixture = 1 corresponds pure lasso model, mixture = 0 indicates ridge regression. penalty parameter default requires single numeric value. details , glmnet model general, see glmnet-details.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_glmnet.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Linear regression via glmnet — details_linear_reg_glmnet","text":"","code":"linear_reg(penalty = double(1), mixture = double(1)) %>%    set_engine(\"glmnet\") %>%    translate() ## Linear Regression Model Specification (regression) ##  ## Main Arguments: ##   penalty = 0 ##   mixture = double(1) ##  ## Computational engine: glmnet  ##  ## Model fit template: ## glmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(),  ##     alpha = double(1), family = \"gaussian\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_glmnet.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Linear regression via glmnet — details_linear_reg_glmnet","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one. default, glmnet::glmnet() uses argument standardize = TRUE center scale data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_glmnet.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear regression via glmnet — details_linear_reg_glmnet","text":"“Fitting Predicting parsnip” article contains examples linear_reg() \"glmnet\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_glmnet.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear regression via glmnet — details_linear_reg_glmnet","text":"Hastie, T, R Tibshirani, M Wainwright. 2015. Statistical Learning Sparsity. CRC Press. Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_keras.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear regression via keras/tensorflow — details_linear_reg_keras","title":"Linear regression via keras/tensorflow — details_linear_reg_keras","text":"model uses regularized least squares fit models numeric outcomes.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_keras.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear regression via keras/tensorflow — details_linear_reg_keras","text":"engine, single mode: regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_keras.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Linear regression via keras/tensorflow — details_linear_reg_keras","text":"model one tuning parameter: penalty: Amount Regularization (type: double, default: 0.0) penalty, amount regularization L2 penalty (.e., ridge weight decay).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_keras.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Linear regression via keras/tensorflow — details_linear_reg_keras","text":"keras_mlp() parsnip wrapper around keras code neural networks. model fits linear regression network single hidden unit.","code":"linear_reg(penalty = double(1)) %>%    set_engine(\"keras\") %>%    translate() ## Linear Regression Model Specification (regression) ##  ## Main Arguments: ##   penalty = double(1) ##  ## Computational engine: keras  ##  ## Model fit template: ## parsnip::keras_mlp(x = missing_arg(), y = missing_arg(), penalty = double(1),  ##     hidden_units = 1, act = \"linear\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_keras.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Linear regression via keras/tensorflow — details_linear_reg_keras","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_keras.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear regression via keras/tensorflow — details_linear_reg_keras","text":"“Fitting Predicting parsnip” article contains examples linear_reg() \"keras\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_keras.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear regression via keras/tensorflow — details_linear_reg_keras","text":"Hoerl, ., & Kennard, R. (2000). Ridge Regression: Biased Estimation Nonorthogonal Problems. Technometrics, 42(1), 80-86.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear regression via lm — details_linear_reg_lm","title":"Linear regression via lm — details_linear_reg_lm","text":"stats::lm() uses ordinary least squares fit models numeric outcomes.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear regression via lm — details_linear_reg_lm","text":"engine, single mode: regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_lm.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Linear regression via lm — details_linear_reg_lm","text":"engine tuning parameters.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_lm.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Linear regression via lm — details_linear_reg_lm","text":"","code":"linear_reg() %>%    set_engine(\"lm\") %>%    translate() ## Linear Regression Model Specification (regression) ##  ## Computational engine: lm  ##  ## Model fit template: ## stats::lm(formula = missing_arg(), data = missing_arg(), weights = missing_arg())"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_lm.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Linear regression via lm — details_linear_reg_lm","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_lm.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear regression via lm — details_linear_reg_lm","text":"“Fitting Predicting parsnip” article contains examples linear_reg() \"lm\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear regression via lm — details_linear_reg_lm","text":"Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_spark.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear regression via spark — details_linear_reg_spark","title":"Linear regression via spark — details_linear_reg_spark","text":"sparklyr::ml_linear_regression() uses regularized least squares fit models numeric outcomes.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_spark.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear regression via spark — details_linear_reg_spark","text":"engine, single mode: regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_spark.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Linear regression via spark — details_linear_reg_spark","text":"model 2 tuning parameters: penalty: Amount Regularization (type: double, default: 0.0) mixture: Proportion Lasso Penalty (type: double, default: 0.0) penalty, amount regularization includes L1 penalty (.e., lasso) L2 penalty (.e., ridge weight decay). value mixture = 1 corresponds pure lasso model, mixture = 0 indicates ridge regression.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_spark.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Linear regression via spark — details_linear_reg_spark","text":"","code":"linear_reg(penalty = double(1), mixture = double(1)) %>%    set_engine(\"spark\") %>%    translate() ## Linear Regression Model Specification (regression) ##  ## Main Arguments: ##   penalty = double(1) ##   mixture = double(1) ##  ## Computational engine: spark  ##  ## Model fit template: ## sparklyr::ml_linear_regression(x = missing_arg(), formula = missing_arg(),  ##     weight_col = missing_arg(), reg_param = double(1), elastic_net_param = double(1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_spark.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Linear regression via spark — details_linear_reg_spark","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one. default, ml_linear_regression() uses argument standardization = TRUE center scale data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_spark.html","id":"other-details","dir":"Reference","previous_headings":"","what":"Other details","title":"Linear regression via spark — details_linear_reg_spark","text":"models created using \"spark\" engine, several things consider. formula interface via fit() available; using fit_xy() generate error. predictions always Spark table format. names documented without dots. equivalent factor columns Spark tables class predictions returned character columns. retain model object new R session (via save()), model$fit element parsnip object serialized via ml_save(object$fit) separately saved disk. new session, object can reloaded reattached parsnip object.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_spark.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear regression via spark — details_linear_reg_spark","text":"Luraschi, J, K Kuo, E Ruiz. 2019. Mastering Spark R. O’Reilly Media Hastie, T, R Tibshirani, M Wainwright. 2015. Statistical Learning Sparsity. CRC Press. Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_stan.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear regression via Bayesian Methods — details_linear_reg_stan","title":"Linear regression via Bayesian Methods — details_linear_reg_stan","text":"\"stan\" engine estimates regression parameters using Bayesian estimation.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_stan.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear regression via Bayesian Methods — details_linear_reg_stan","text":"engine, single mode: regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_stan.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Linear regression via Bayesian Methods — details_linear_reg_stan","text":"engine tuning parameters.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_stan.html","id":"important-engine-specific-options","dir":"Reference","previous_headings":"","what":"Important engine-specific options","title":"Linear regression via Bayesian Methods — details_linear_reg_stan","text":"relevant arguments can passed set_engine(): chains: positive integer specifying number Markov chains. default 4. iter: positive integer specifying number iterations chain (including warmup). default 2000. seed: seed random number generation. cores: Number cores use executing chains parallel. prior: prior distribution (non-hierarchical) regression coefficients. \"stan\" engine fit hierarchical terms. See \"stan_glmer\" engine multilevelmod package type model. prior_intercept: prior distribution intercept (centering predictors). See rstan::sampling() rstanarm::priors() information options.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_stan.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Linear regression via Bayesian Methods — details_linear_reg_stan","text":"Note refresh default prevents logging estimation process. Change value set_engine() show MCMC logs.","code":"linear_reg() %>%    set_engine(\"stan\") %>%    translate() ## Linear Regression Model Specification (regression) ##  ## Computational engine: stan  ##  ## Model fit template: ## rstanarm::stan_glm(formula = missing_arg(), data = missing_arg(),  ##     weights = missing_arg(), family = stats::gaussian, refresh = 0)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_stan.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Linear regression via Bayesian Methods — details_linear_reg_stan","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_stan.html","id":"other-details","dir":"Reference","previous_headings":"","what":"Other details","title":"Linear regression via Bayesian Methods — details_linear_reg_stan","text":"prediction, \"stan\" engine can compute posterior intervals analogous confidence prediction intervals. instances, units original outcome std_error = TRUE, standard deviation posterior distribution (posterior predictive distribution appropriate) returned.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_stan.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear regression via Bayesian Methods — details_linear_reg_stan","text":"“Fitting Predicting parsnip” article contains examples linear_reg() \"stan\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_linear_reg_stan.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear regression via Bayesian Methods — details_linear_reg_stan","text":"McElreath, R. 2020 Statistical Rethinking. CRC Press.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_LiblineaR.html","id":null,"dir":"Reference","previous_headings":"","what":"Logistic regression via LiblineaR — details_logistic_reg_LiblineaR","title":"Logistic regression via LiblineaR — details_logistic_reg_LiblineaR","text":"LiblineaR::LiblineaR() fits generalized linear model binary outcomes. linear combination predictors used model log odds event.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_LiblineaR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Logistic regression via LiblineaR — details_logistic_reg_LiblineaR","text":"engine, single mode: classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_LiblineaR.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Logistic regression via LiblineaR — details_logistic_reg_LiblineaR","text":"model 2 tuning parameters: penalty: Amount Regularization (type: double, default: see ) mixture: Proportion Lasso Penalty (type: double, default: 0) LiblineaR models, value mixture can either 0 (ridge) 1 (lasso) intermediate values. LiblineaR::LiblineaR() documentation, correspond types 0 (L2-regularized) 6 (L1-regularized). aware LiblineaR engine regularizes intercept. regularized regression models , result different parameter estimates.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_LiblineaR.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Logistic regression via LiblineaR — details_logistic_reg_LiblineaR","text":"","code":"logistic_reg(penalty = double(1), mixture = double(1)) %>%    set_engine(\"LiblineaR\") %>%    translate() ## Logistic Regression Model Specification (classification) ##  ## Main Arguments: ##   penalty = double(1) ##   mixture = double(1) ##  ## Computational engine: LiblineaR  ##  ## Model fit template: ## LiblineaR::LiblineaR(x = missing_arg(), y = missing_arg(), wi = missing_arg(),  ##     cost = Inf, type = double(1), verbose = FALSE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_LiblineaR.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Logistic regression via LiblineaR — details_logistic_reg_LiblineaR","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_LiblineaR.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logistic regression via LiblineaR — details_logistic_reg_LiblineaR","text":"“Fitting Predicting parsnip” article contains examples logistic_reg() \"LiblineaR\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_LiblineaR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Logistic regression via LiblineaR — details_logistic_reg_LiblineaR","text":"Hastie, T, R Tibshirani, M Wainwright. 2015. Statistical Learning Sparsity. CRC Press. Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Logistic regression via glm — details_logistic_reg_glm","title":"Logistic regression via glm — details_logistic_reg_glm","text":"stats::glm() fits generalized linear model binary outcomes. linear combination predictors used model log odds event.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Logistic regression via glm — details_logistic_reg_glm","text":"engine, single mode: classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glm.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Logistic regression via glm — details_logistic_reg_glm","text":"engine tuning parameters.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glm.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Logistic regression via glm — details_logistic_reg_glm","text":"","code":"logistic_reg() %>%    set_engine(\"glm\") %>%    translate() ## Logistic Regression Model Specification (classification) ##  ## Computational engine: glm  ##  ## Model fit template: ## stats::glm(formula = missing_arg(), data = missing_arg(), weights = missing_arg(),  ##     family = stats::binomial)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glm.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Logistic regression via glm — details_logistic_reg_glm","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glm.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logistic regression via glm — details_logistic_reg_glm","text":"“Fitting Predicting parsnip” article contains examples logistic_reg() \"glm\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Logistic regression via glm — details_logistic_reg_glm","text":"Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glmnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Logistic regression via glmnet — details_logistic_reg_glmnet","title":"Logistic regression via glmnet — details_logistic_reg_glmnet","text":"glmnet::glmnet() fits generalized linear model binary outcomes. linear combination predictors used model log odds event.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glmnet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Logistic regression via glmnet — details_logistic_reg_glmnet","text":"engine, single mode: classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glmnet.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Logistic regression via glmnet — details_logistic_reg_glmnet","text":"model 2 tuning parameters: penalty: Amount Regularization (type: double, default: see ) mixture: Proportion Lasso Penalty (type: double, default: 1.0) value mixture = 1 corresponds pure lasso model, mixture = 0 indicates ridge regression. penalty parameter default requires single numeric value. details , glmnet model general, see glmnet-details.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glmnet.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Logistic regression via glmnet — details_logistic_reg_glmnet","text":"","code":"logistic_reg(penalty = double(1), mixture = double(1)) %>%    set_engine(\"glmnet\") %>%    translate() ## Logistic Regression Model Specification (classification) ##  ## Main Arguments: ##   penalty = 0 ##   mixture = double(1) ##  ## Computational engine: glmnet  ##  ## Model fit template: ## glmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(),  ##     alpha = double(1), family = \"binomial\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glmnet.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Logistic regression via glmnet — details_logistic_reg_glmnet","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one. default, glmnet::glmnet() uses argument standardize = TRUE center scale data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glmnet.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logistic regression via glmnet — details_logistic_reg_glmnet","text":"“Fitting Predicting parsnip” article contains examples logistic_reg() \"glmnet\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_glmnet.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Logistic regression via glmnet — details_logistic_reg_glmnet","text":"Hastie, T, R Tibshirani, M Wainwright. 2015. Statistical Learning Sparsity. CRC Press. Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_keras.html","id":null,"dir":"Reference","previous_headings":"","what":"Logistic regression via keras — details_logistic_reg_keras","title":"Logistic regression via keras — details_logistic_reg_keras","text":"keras_mlp() fits generalized linear model binary outcomes. linear combination predictors used model log odds event.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_keras.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Logistic regression via keras — details_logistic_reg_keras","text":"engine, single mode: classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_keras.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Logistic regression via keras — details_logistic_reg_keras","text":"model one tuning parameter: penalty: Amount Regularization (type: double, default: 0.0) penalty, amount regularization L2 penalty (.e., ridge weight decay).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_keras.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Logistic regression via keras — details_logistic_reg_keras","text":"keras_mlp() parsnip wrapper around keras code neural networks. model fits linear regression network single hidden unit.","code":"logistic_reg(penalty = double(1)) %>%    set_engine(\"keras\") %>%    translate() ## Logistic Regression Model Specification (classification) ##  ## Main Arguments: ##   penalty = double(1) ##  ## Computational engine: keras  ##  ## Model fit template: ## parsnip::keras_mlp(x = missing_arg(), y = missing_arg(), penalty = double(1),  ##     hidden_units = 1, act = \"linear\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_keras.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Logistic regression via keras — details_logistic_reg_keras","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_keras.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logistic regression via keras — details_logistic_reg_keras","text":"“Fitting Predicting parsnip” article contains examples logistic_reg() \"keras\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_keras.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Logistic regression via keras — details_logistic_reg_keras","text":"Hoerl, ., & Kennard, R. (2000). Ridge Regression: Biased Estimation Nonorthogonal Problems. Technometrics, 42(1), 80-86.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_spark.html","id":null,"dir":"Reference","previous_headings":"","what":"Logistic regression via spark — details_logistic_reg_spark","title":"Logistic regression via spark — details_logistic_reg_spark","text":"sparklyr::ml_logistic_regression() fits generalized linear model binary outcomes. linear combination predictors used model log odds event.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_spark.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Logistic regression via spark — details_logistic_reg_spark","text":"engine, single mode: classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_spark.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Logistic regression via spark — details_logistic_reg_spark","text":"model 2 tuning parameters: penalty: Amount Regularization (type: double, default: 0.0) mixture: Proportion Lasso Penalty (type: double, default: 0.0) penalty, amount regularization includes L1 penalty (.e., lasso) L2 penalty (.e., ridge weight decay). value mixture = 1 corresponds pure lasso model, mixture = 0 indicates ridge regression.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_spark.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Logistic regression via spark — details_logistic_reg_spark","text":"","code":"logistic_reg(penalty = double(1), mixture = double(1)) %>%    set_engine(\"spark\") %>%    translate() ## Logistic Regression Model Specification (classification) ##  ## Main Arguments: ##   penalty = double(1) ##   mixture = double(1) ##  ## Computational engine: spark  ##  ## Model fit template: ## sparklyr::ml_logistic_regression(x = missing_arg(), formula = missing_arg(),  ##     weight_col = missing_arg(), reg_param = double(1), elastic_net_param = double(1),  ##     family = \"binomial\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_spark.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Logistic regression via spark — details_logistic_reg_spark","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one. default, ml_logistic_regression() uses argument standardization = TRUE center scale data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_spark.html","id":"other-details","dir":"Reference","previous_headings":"","what":"Other details","title":"Logistic regression via spark — details_logistic_reg_spark","text":"models created using \"spark\" engine, several things consider. formula interface via fit() available; using fit_xy() generate error. predictions always Spark table format. names documented without dots. equivalent factor columns Spark tables class predictions returned character columns. retain model object new R session (via save()), model$fit element parsnip object serialized via ml_save(object$fit) separately saved disk. new session, object can reloaded reattached parsnip object.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_spark.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Logistic regression via spark — details_logistic_reg_spark","text":"Luraschi, J, K Kuo, E Ruiz. 2019. Mastering Spark R. O’Reilly Media Hastie, T, R Tibshirani, M Wainwright. 2015. Statistical Learning Sparsity. CRC Press. Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_stan.html","id":null,"dir":"Reference","previous_headings":"","what":"Logistic regression via stan — details_logistic_reg_stan","title":"Logistic regression via stan — details_logistic_reg_stan","text":"rstanarm::stan_glm() fits generalized linear model binary outcomes. linear combination predictors used model log odds event.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_stan.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Logistic regression via stan — details_logistic_reg_stan","text":"engine, single mode: classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_stan.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Logistic regression via stan — details_logistic_reg_stan","text":"engine tuning parameters.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_stan.html","id":"important-engine-specific-options","dir":"Reference","previous_headings":"","what":"Important engine-specific options","title":"Logistic regression via stan — details_logistic_reg_stan","text":"relevant arguments can passed set_engine(): chains: positive integer specifying number Markov chains. default 4. iter: positive integer specifying number iterations chain (including warmup). default 2000. seed: seed random number generation. cores: Number cores use executing chains parallel. prior: prior distribution (non-hierarchical) regression coefficients. \"stan\" engine fit hierarchical terms. prior_intercept: prior distribution intercept (centering predictors). See rstan::sampling() rstanarm::priors() information options.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_stan.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Logistic regression via stan — details_logistic_reg_stan","text":"Note refresh default prevents logging estimation process. Change value set_engine() show MCMC logs.","code":"logistic_reg() %>%    set_engine(\"stan\") %>%    translate() ## Logistic Regression Model Specification (classification) ##  ## Computational engine: stan  ##  ## Model fit template: ## rstanarm::stan_glm(formula = missing_arg(), data = missing_arg(),  ##     weights = missing_arg(), family = stats::binomial, refresh = 0)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_stan.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Logistic regression via stan — details_logistic_reg_stan","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_stan.html","id":"other-details","dir":"Reference","previous_headings":"","what":"Other details","title":"Logistic regression via stan — details_logistic_reg_stan","text":"prediction, \"stan\" engine can compute posterior intervals analogous confidence prediction intervals. instances, units original outcome std_error = TRUE, standard deviation posterior distribution (posterior predictive distribution appropriate) returned.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_stan.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logistic regression via stan — details_logistic_reg_stan","text":"“Fitting Predicting parsnip” article contains examples logistic_reg() \"stan\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_logistic_reg_stan.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Logistic regression via stan — details_logistic_reg_stan","text":"McElreath, R. 2020 Statistical Rethinking. CRC Press.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mars_earth.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate adaptive regression splines (MARS) via earth — details_mars_earth","title":"Multivariate adaptive regression splines (MARS) via earth — details_mars_earth","text":"earth::earth() fits generalized linear model uses artificial features predictors. features resemble hinge functions result model segmented regression small dimensions.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mars_earth.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multivariate adaptive regression splines (MARS) via earth — details_mars_earth","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mars_earth.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Multivariate adaptive regression splines (MARS) via earth — details_mars_earth","text":"model 3 tuning parameters: num_terms: # Model Terms (type: integer, default: see ) prod_degree: Degree Interaction (type: integer, default: 1L) prune_method: Pruning Method (type: character, default: ‘backward’) default value num_terms depends number predictor columns. data frame x, default min(200, max(20, 2 * ncol(x))) + 1 (see earth::earth() reference ).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mars_earth.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Multivariate adaptive regression splines (MARS) via earth — details_mars_earth","text":"","code":"mars(num_terms = integer(1), prod_degree = integer(1), prune_method = character(1)) %>%    set_engine(\"earth\") %>%    set_mode(\"regression\") %>%    translate() ## MARS Model Specification (regression) ##  ## Main Arguments: ##   num_terms = integer(1) ##   prod_degree = integer(1) ##   prune_method = character(1) ##  ## Computational engine: earth  ##  ## Model fit template: ## earth::earth(formula = missing_arg(), data = missing_arg(), weights = missing_arg(),  ##     nprune = integer(1), degree = integer(1), pmethod = character(1),  ##     keepxy = TRUE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mars_earth.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Multivariate adaptive regression splines (MARS) via earth — details_mars_earth","text":"alternate method using MARs categorical outcomes can found discrim_flexible().","code":"mars(num_terms = integer(1), prod_degree = integer(1), prune_method = character(1)) %>%    set_engine(\"earth\") %>%    set_mode(\"classification\") %>%    translate() ## MARS Model Specification (classification) ##  ## Main Arguments: ##   num_terms = integer(1) ##   prod_degree = integer(1) ##   prune_method = character(1) ##  ## Engine-Specific Arguments: ##   glm = list(family = stats::binomial) ##  ## Computational engine: earth  ##  ## Model fit template: ## earth::earth(formula = missing_arg(), data = missing_arg(), weights = missing_arg(),  ##     nprune = integer(1), degree = integer(1), pmethod = character(1),  ##     glm = list(family = stats::binomial), keepxy = TRUE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mars_earth.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Multivariate adaptive regression splines (MARS) via earth — details_mars_earth","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mars_earth.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multivariate adaptive regression splines (MARS) via earth — details_mars_earth","text":"“Fitting Predicting parsnip” article contains examples mars() \"earth\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mars_earth.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multivariate adaptive regression splines (MARS) via earth — details_mars_earth","text":"Friedman, J. 1991. “Multivariate Adaptive Regression Splines.” Annals Statistics, vol. 19, . 1, pp. 1-67. Milborrow, S. “Notes earth package.” Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_keras.html","id":null,"dir":"Reference","previous_headings":"","what":"Multilayer perceptron via keras — details_mlp_keras","title":"Multilayer perceptron via keras — details_mlp_keras","text":"keras_mlp() fits single layer, feed-forward neural network.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_keras.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multilayer perceptron via keras — details_mlp_keras","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_keras.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Multilayer perceptron via keras — details_mlp_keras","text":"model 5 tuning parameters: hidden_units: # Hidden Units (type: integer, default: 5L) penalty: Amount Regularization (type: double, default: 0.0) dropout: Dropout Rate (type: double, default: 0.0) epochs: # Epochs (type: integer, default: 20L) activation: Activation Function (type: character, default: ‘softmax’)","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_keras.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Multilayer perceptron via keras — details_mlp_keras","text":"","code":"mlp(   hidden_units = integer(1),   penalty = double(1),   dropout = double(1),   epochs = integer(1),   activation = character(1) ) %>%     set_engine(\"keras\") %>%    set_mode(\"regression\") %>%    translate() ## Single Layer Neural Network Specification (regression) ##  ## Main Arguments: ##   hidden_units = integer(1) ##   penalty = double(1) ##   dropout = double(1) ##   epochs = integer(1) ##   activation = character(1) ##  ## Computational engine: keras  ##  ## Model fit template: ## parsnip::keras_mlp(x = missing_arg(), y = missing_arg(), hidden_units = integer(1),  ##     penalty = double(1), dropout = double(1), epochs = integer(1),  ##     activation = character(1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_keras.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Multilayer perceptron via keras — details_mlp_keras","text":"","code":"mlp(   hidden_units = integer(1),   penalty = double(1),   dropout = double(1),   epochs = integer(1),   activation = character(1) ) %>%    set_engine(\"keras\") %>%    set_mode(\"classification\") %>%    translate() ## Single Layer Neural Network Specification (classification) ##  ## Main Arguments: ##   hidden_units = integer(1) ##   penalty = double(1) ##   dropout = double(1) ##   epochs = integer(1) ##   activation = character(1) ##  ## Computational engine: keras  ##  ## Model fit template: ## parsnip::keras_mlp(x = missing_arg(), y = missing_arg(), hidden_units = integer(1),  ##     penalty = double(1), dropout = double(1), epochs = integer(1),  ##     activation = character(1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_keras.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Multilayer perceptron via keras — details_mlp_keras","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_keras.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multilayer perceptron via keras — details_mlp_keras","text":"“Fitting Predicting parsnip” article contains examples mlp() \"keras\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_keras.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multilayer perceptron via keras — details_mlp_keras","text":"Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_nnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Multilayer perceptron via nnet — details_mlp_nnet","title":"Multilayer perceptron via nnet — details_mlp_nnet","text":"nnet::nnet() fits single layer, feed-forward neural network.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_nnet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multilayer perceptron via nnet — details_mlp_nnet","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_nnet.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Multilayer perceptron via nnet — details_mlp_nnet","text":"model 3 tuning parameters: hidden_units: # Hidden Units (type: integer, default: none) penalty: Amount Regularization (type: double, default: 0.0) epochs: # Epochs (type: integer, default: 100L) Note , nnet::nnet(), maximum number parameters argument fairly low value maxit = 1000. models, may need pass value via set_engine() model fail.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_nnet.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Multilayer perceptron via nnet — details_mlp_nnet","text":"Note parsnip automatically sets linear activation last layer.","code":"mlp(   hidden_units = integer(1),   penalty = double(1),   epochs = integer(1) ) %>%     set_engine(\"nnet\") %>%    set_mode(\"regression\") %>%    translate() ## Single Layer Neural Network Specification (regression) ##  ## Main Arguments: ##   hidden_units = integer(1) ##   penalty = double(1) ##   epochs = integer(1) ##  ## Computational engine: nnet  ##  ## Model fit template: ## nnet::nnet(formula = missing_arg(), data = missing_arg(), weights = missing_arg(),  ##     size = integer(1), decay = double(1), maxit = integer(1),  ##     trace = FALSE, linout = TRUE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_nnet.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Multilayer perceptron via nnet — details_mlp_nnet","text":"","code":"mlp(   hidden_units = integer(1),   penalty = double(1),   epochs = integer(1) ) %>%    set_engine(\"nnet\") %>%    set_mode(\"classification\") %>%    translate() ## Single Layer Neural Network Specification (classification) ##  ## Main Arguments: ##   hidden_units = integer(1) ##   penalty = double(1) ##   epochs = integer(1) ##  ## Computational engine: nnet  ##  ## Model fit template: ## nnet::nnet(formula = missing_arg(), data = missing_arg(), weights = missing_arg(),  ##     size = integer(1), decay = double(1), maxit = integer(1),  ##     trace = FALSE, linout = FALSE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_nnet.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Multilayer perceptron via nnet — details_mlp_nnet","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_nnet.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multilayer perceptron via nnet — details_mlp_nnet","text":"“Fitting Predicting parsnip” article contains examples mlp() \"nnet\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_mlp_nnet.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multilayer perceptron via nnet — details_mlp_nnet","text":"Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_glmnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial regression via glmnet — details_multinom_reg_glmnet","title":"Multinomial regression via glmnet — details_multinom_reg_glmnet","text":"glmnet::glmnet() fits model uses linear predictors predict multiclass data using multinomial distribution.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_glmnet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinomial regression via glmnet — details_multinom_reg_glmnet","text":"engine, single mode: classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_glmnet.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Multinomial regression via glmnet — details_multinom_reg_glmnet","text":"model 2 tuning parameters: penalty: Amount Regularization (type: double, default: see ) mixture: Proportion Lasso Penalty (type: double, default: 1.0) value mixture = 1 corresponds pure lasso model, mixture = 0 indicates ridge regression. penalty parameter default requires single numeric value. details , glmnet model general, see glmnet-details.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_glmnet.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Multinomial regression via glmnet — details_multinom_reg_glmnet","text":"","code":"multinom_reg(penalty = double(1), mixture = double(1)) %>%    set_engine(\"glmnet\") %>%    translate() ## Multinomial Regression Model Specification (classification) ##  ## Main Arguments: ##   penalty = 0 ##   mixture = double(1) ##  ## Computational engine: glmnet  ##  ## Model fit template: ## glmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(),  ##     alpha = double(1), family = \"multinomial\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_glmnet.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Multinomial regression via glmnet — details_multinom_reg_glmnet","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one. default, glmnet::glmnet() uses argument standardize = TRUE center scale data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_glmnet.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinomial regression via glmnet — details_multinom_reg_glmnet","text":"“Fitting Predicting parsnip” article contains examples multinom_reg() \"glmnet\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_glmnet.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multinomial regression via glmnet — details_multinom_reg_glmnet","text":"Hastie, T, R Tibshirani, M Wainwright. 2015. Statistical Learning Sparsity. CRC Press. Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_keras.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial regression via keras — details_multinom_reg_keras","title":"Multinomial regression via keras — details_multinom_reg_keras","text":"keras_mlp() fits model uses linear predictors predict multiclass data using multinomial distribution.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_keras.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinomial regression via keras — details_multinom_reg_keras","text":"engine, single mode: classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_keras.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Multinomial regression via keras — details_multinom_reg_keras","text":"model one tuning parameter: penalty: Amount Regularization (type: double, default: 0.0) penalty, amount regularization L2 penalty (.e., ridge weight decay).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_keras.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Multinomial regression via keras — details_multinom_reg_keras","text":"keras_mlp() parsnip wrapper around keras code neural networks. model fits linear regression network single hidden unit.","code":"multinom_reg(penalty = double(1)) %>%    set_engine(\"keras\") %>%    translate() ## Multinomial Regression Model Specification (classification) ##  ## Main Arguments: ##   penalty = double(1) ##  ## Computational engine: keras  ##  ## Model fit template: ## parsnip::keras_mlp(x = missing_arg(), y = missing_arg(), penalty = double(1),  ##     hidden_units = 1, act = \"linear\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_keras.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Multinomial regression via keras — details_multinom_reg_keras","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_keras.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinomial regression via keras — details_multinom_reg_keras","text":"“Fitting Predicting parsnip” article contains examples multinom_reg() \"keras\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_keras.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multinomial regression via keras — details_multinom_reg_keras","text":"Hoerl, ., & Kennard, R. (2000). Ridge Regression: Biased Estimation Nonorthogonal Problems. Technometrics, 42(1), 80-86.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_nnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial regression via nnet — details_multinom_reg_nnet","title":"Multinomial regression via nnet — details_multinom_reg_nnet","text":"nnet::multinom() fits model uses linear predictors predict multiclass data using multinomial distribution.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_nnet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinomial regression via nnet — details_multinom_reg_nnet","text":"engine, single mode: classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_nnet.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Multinomial regression via nnet — details_multinom_reg_nnet","text":"model 1 tuning parameters: penalty: Amount Regularization (type: double, default: 0.0) penalty, amount regularization includes L2 penalty (.e., ridge weight decay).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_nnet.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Multinomial regression via nnet — details_multinom_reg_nnet","text":"","code":"multinom_reg(penalty = double(1)) %>%    set_engine(\"nnet\") %>%    translate() ## Multinomial Regression Model Specification (classification) ##  ## Main Arguments: ##   penalty = double(1) ##  ## Computational engine: nnet  ##  ## Model fit template: ## nnet::multinom(formula = missing_arg(), data = missing_arg(),  ##     weights = missing_arg(), decay = double(1), trace = FALSE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_nnet.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Multinomial regression via nnet — details_multinom_reg_nnet","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_nnet.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinomial regression via nnet — details_multinom_reg_nnet","text":"“Fitting Predicting parsnip” article contains examples multinom_reg() \"nnet\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_nnet.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multinomial regression via nnet — details_multinom_reg_nnet","text":"Luraschi, J, K Kuo, E Ruiz. 2019. Mastering nnet R. O’Reilly Media Hastie, T, R Tibshirani, M Wainwright. 2015. Statistical Learning Sparsity. CRC Press. Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_spark.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial regression via spark — details_multinom_reg_spark","title":"Multinomial regression via spark — details_multinom_reg_spark","text":"sparklyr::ml_logistic_regression() fits model uses linear predictors predict multiclass data using multinomial distribution.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_spark.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinomial regression via spark — details_multinom_reg_spark","text":"engine, single mode: classification","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_spark.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Multinomial regression via spark — details_multinom_reg_spark","text":"model 2 tuning parameters: penalty: Amount Regularization (type: double, default: 0.0) mixture: Proportion Lasso Penalty (type: double, default: 0.0) penalty, amount regularization includes L1 penalty (.e., lasso) L2 penalty (.e., ridge weight decay). value mixture = 1 corresponds pure lasso model, mixture = 0 indicates ridge regression.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_spark.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Multinomial regression via spark — details_multinom_reg_spark","text":"","code":"multinom_reg(penalty = double(1), mixture = double(1)) %>%    set_engine(\"spark\") %>%    translate() ## Multinomial Regression Model Specification (classification) ##  ## Main Arguments: ##   penalty = double(1) ##   mixture = double(1) ##  ## Computational engine: spark  ##  ## Model fit template: ## sparklyr::ml_logistic_regression(x = missing_arg(), formula = missing_arg(),  ##     weight_col = missing_arg(), reg_param = double(1), elastic_net_param = double(1),  ##     family = \"multinomial\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_spark.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Multinomial regression via spark — details_multinom_reg_spark","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one. default, ml_multinom_regression() uses argument standardization = TRUE center scale data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_spark.html","id":"other-details","dir":"Reference","previous_headings":"","what":"Other details","title":"Multinomial regression via spark — details_multinom_reg_spark","text":"models created using \"spark\" engine, several things consider. formula interface via fit() available; using fit_xy() generate error. predictions always Spark table format. names documented without dots. equivalent factor columns Spark tables class predictions returned character columns. retain model object new R session (via save()), model$fit element parsnip object serialized via ml_save(object$fit) separately saved disk. new session, object can reloaded reattached parsnip object.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_multinom_reg_spark.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multinomial regression via spark — details_multinom_reg_spark","text":"Luraschi, J, K Kuo, E Ruiz. 2019. Mastering Spark R. O’Reilly Media Hastie, T, R Tibshirani, M Wainwright. 2015. Statistical Learning Sparsity. CRC Press. Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_nearest_neighbor_kknn.html","id":null,"dir":"Reference","previous_headings":"","what":"K-nearest neighbors via kknn — details_nearest_neighbor_kknn","title":"K-nearest neighbors via kknn — details_nearest_neighbor_kknn","text":"kknn::train.kknn() fits model uses K similar data points training set predict new samples.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_nearest_neighbor_kknn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"K-nearest neighbors via kknn — details_nearest_neighbor_kknn","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_nearest_neighbor_kknn.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"K-nearest neighbors via kknn — details_nearest_neighbor_kknn","text":"model 3 tuning parameters: neighbors: # Nearest Neighbors (type: integer, default: 5L) weight_func: Distance Weighting Function (type: character, default: ‘optimal’) dist_power: Minkowski Distance Order (type: double, default: 2.0)","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_nearest_neighbor_kknn.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"K-nearest neighbors via kknn — details_nearest_neighbor_kknn","text":"min_rows() adjust number neighbors chosen value consistent actual data dimensions.","code":"nearest_neighbor(   neighbors = integer(1),   weight_func = character(1),   dist_power = double(1) ) %>%     set_engine(\"kknn\") %>%    set_mode(\"regression\") %>%    translate() ## K-Nearest Neighbor Model Specification (regression) ##  ## Main Arguments: ##   neighbors = integer(1) ##   weight_func = character(1) ##   dist_power = double(1) ##  ## Computational engine: kknn  ##  ## Model fit template: ## kknn::train.kknn(formula = missing_arg(), data = missing_arg(),  ##     ks = min_rows(0L, data, 5), kernel = character(1), distance = double(1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_nearest_neighbor_kknn.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"K-nearest neighbors via kknn — details_nearest_neighbor_kknn","text":"","code":"nearest_neighbor(   neighbors = integer(1),   weight_func = character(1),   dist_power = double(1) ) %>%    set_engine(\"kknn\") %>%    set_mode(\"classification\") %>%    translate() ## K-Nearest Neighbor Model Specification (classification) ##  ## Main Arguments: ##   neighbors = integer(1) ##   weight_func = character(1) ##   dist_power = double(1) ##  ## Computational engine: kknn  ##  ## Model fit template: ## kknn::train.kknn(formula = missing_arg(), data = missing_arg(),  ##     ks = min_rows(0L, data, 5), kernel = character(1), distance = double(1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_nearest_neighbor_kknn.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"K-nearest neighbors via kknn — details_nearest_neighbor_kknn","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_nearest_neighbor_kknn.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"K-nearest neighbors via kknn — details_nearest_neighbor_kknn","text":"“Fitting Predicting parsnip” article contains examples nearest_neighbor() \"kknn\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_nearest_neighbor_kknn.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"K-nearest neighbors via kknn — details_nearest_neighbor_kknn","text":"Hechenbichler K. Schliep K.P. (2004) Weighted k-Nearest-Neighbor Techniques Ordinal Classification, Discussion Paper 399, SFB 386, Ludwig-Maximilians University Munich Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_randomForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Random forests via randomForest — details_rand_forest_randomForest","title":"Random forests via randomForest — details_rand_forest_randomForest","text":"randomForest::randomForest() fits model creates large number decision trees, independent others. final prediction uses predictions individual trees combines .","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_randomForest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random forests via randomForest — details_rand_forest_randomForest","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_randomForest.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Random forests via randomForest — details_rand_forest_randomForest","text":"model 3 tuning parameters: mtry: # Randomly Selected Predictors (type: integer, default: see ) trees: # Trees (type: integer, default: 500L) min_n: Minimal Node Size (type: integer, default: see ) mtry depends number columns model mode. default randomForest::randomForest() floor(sqrt(ncol(x))) classification floor(ncol(x)/3) regression. min_n depends mode. regression, value 5 default. classification, value 10 used.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_randomForest.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Random forests via randomForest — details_rand_forest_randomForest","text":"min_rows() min_cols() adjust number neighbors chosen value consistent actual data dimensions.","code":"rand_forest(   mtry = integer(1),   trees = integer(1),   min_n = integer(1) ) %>%     set_engine(\"randomForest\") %>%    set_mode(\"regression\") %>%    translate() ## Random Forest Model Specification (regression) ##  ## Main Arguments: ##   mtry = integer(1) ##   trees = integer(1) ##   min_n = integer(1) ##  ## Computational engine: randomForest  ##  ## Model fit template: ## randomForest::randomForest(x = missing_arg(), y = missing_arg(),  ##     mtry = min_cols(~integer(1), x), ntree = integer(1), nodesize = min_rows(~integer(1),  ##         x))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_randomForest.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Random forests via randomForest — details_rand_forest_randomForest","text":"","code":"rand_forest(   mtry = integer(1),   trees = integer(1),   min_n = integer(1) ) %>%    set_engine(\"randomForest\") %>%    set_mode(\"classification\") %>%    translate() ## Random Forest Model Specification (classification) ##  ## Main Arguments: ##   mtry = integer(1) ##   trees = integer(1) ##   min_n = integer(1) ##  ## Computational engine: randomForest  ##  ## Model fit template: ## randomForest::randomForest(x = missing_arg(), y = missing_arg(),  ##     mtry = min_cols(~integer(1), x), ntree = integer(1), nodesize = min_rows(~integer(1),  ##         x))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_randomForest.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Random forests via randomForest — details_rand_forest_randomForest","text":"engine require special encoding predictors. Categorical predictors can partitioned groups factor levels (e.g. {, c} vs {b, d}) splitting node. Dummy variables required model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_randomForest.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random forests via randomForest — details_rand_forest_randomForest","text":"“Fitting Predicting parsnip” article contains examples rand_forest() \"randomForest\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_randomForest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random forests via randomForest — details_rand_forest_randomForest","text":"Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_ranger.html","id":null,"dir":"Reference","previous_headings":"","what":"Random forests via ranger — details_rand_forest_ranger","title":"Random forests via ranger — details_rand_forest_ranger","text":"ranger::ranger() fits model creates large number decision trees, independent others. final prediction uses predictions individual trees combines .","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_ranger.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random forests via ranger — details_rand_forest_ranger","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_ranger.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Random forests via ranger — details_rand_forest_ranger","text":"model 3 tuning parameters: mtry: # Randomly Selected Predictors (type: integer, default: see ) trees: # Trees (type: integer, default: 500L) min_n: Minimal Node Size (type: integer, default: see ) mtry depends number columns. default ranger::ranger() floor(sqrt(ncol(x))). min_n depends mode. regression, value 5 default. classification, value 10 used.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_ranger.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Random forests via ranger — details_rand_forest_ranger","text":"min_rows() min_cols() adjust number neighbors chosen value consistent actual data dimensions.","code":"rand_forest(   mtry = integer(1),   trees = integer(1),   min_n = integer(1) ) %>%     set_engine(\"ranger\") %>%    set_mode(\"regression\") %>%    translate() ## Random Forest Model Specification (regression) ##  ## Main Arguments: ##   mtry = integer(1) ##   trees = integer(1) ##   min_n = integer(1) ##  ## Computational engine: ranger  ##  ## Model fit template: ## ranger::ranger(x = missing_arg(), y = missing_arg(), case.weights = missing_arg(),  ##     mtry = min_cols(~integer(1), x), num.trees = integer(1),  ##     min.node.size = min_rows(~integer(1), x), num.threads = 1,  ##     verbose = FALSE, seed = sample.int(10^5, 1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_ranger.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Random forests via ranger — details_rand_forest_ranger","text":"Note ranger probability forest always fit (unless probability argument changed user via set_engine()).","code":"rand_forest(   mtry = integer(1),   trees = integer(1),   min_n = integer(1) ) %>%    set_engine(\"ranger\") %>%    set_mode(\"classification\") %>%    translate() ## Random Forest Model Specification (classification) ##  ## Main Arguments: ##   mtry = integer(1) ##   trees = integer(1) ##   min_n = integer(1) ##  ## Computational engine: ranger  ##  ## Model fit template: ## ranger::ranger(x = missing_arg(), y = missing_arg(), case.weights = missing_arg(),  ##     mtry = min_cols(~integer(1), x), num.trees = integer(1),  ##     min.node.size = min_rows(~integer(1), x), num.threads = 1,  ##     verbose = FALSE, seed = sample.int(10^5, 1), probability = TRUE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_ranger.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Random forests via ranger — details_rand_forest_ranger","text":"engine require special encoding predictors. Categorical predictors can partitioned groups factor levels (e.g. {, c} vs {b, d}) splitting node. Dummy variables required model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_ranger.html","id":"other-notes","dir":"Reference","previous_headings":"","what":"Other notes","title":"Random forests via ranger — details_rand_forest_ranger","text":"default, parallel processing turned . tuning, efficient parallelize resamples tuning parameters. parallelize construction trees within ranger model, change num.threads argument via set_engine(). ranger confidence intervals, intervals constructed using form estimate +/- z * std_error. classification probabilities, values can fall outside [0, 1] coerced range.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_ranger.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random forests via ranger — details_rand_forest_ranger","text":"“Fitting Predicting parsnip” article contains examples rand_forest() \"ranger\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_ranger.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random forests via ranger — details_rand_forest_ranger","text":"Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_spark.html","id":null,"dir":"Reference","previous_headings":"","what":"Random forests via spark — details_rand_forest_spark","title":"Random forests via spark — details_rand_forest_spark","text":"sparklyr::ml_random_forest() fits model creates large number decision trees, independent others. final prediction uses predictions individual trees combines .","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_spark.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random forests via spark — details_rand_forest_spark","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_spark.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Random forests via spark — details_rand_forest_spark","text":"model 3 tuning parameters: mtry: # Randomly Selected Predictors (type: integer, default: see ) trees: # Trees (type: integer, default: 20L) min_n: Minimal Node Size (type: integer, default: 1L) mtry depends number columns model mode. default sparklyr::ml_random_forest() floor(sqrt(ncol(x))) classification floor(ncol(x)/3) regression.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_spark.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Random forests via spark — details_rand_forest_spark","text":"min_rows() min_cols() adjust number neighbors chosen value consistent actual data dimensions.","code":"rand_forest(   mtry = integer(1),   trees = integer(1),   min_n = integer(1) ) %>%     set_engine(\"spark\") %>%    set_mode(\"regression\") %>%    translate() ## Random Forest Model Specification (regression) ##  ## Main Arguments: ##   mtry = integer(1) ##   trees = integer(1) ##   min_n = integer(1) ##  ## Computational engine: spark  ##  ## Model fit template: ## sparklyr::ml_random_forest(x = missing_arg(), formula = missing_arg(),  ##     type = \"regression\", feature_subset_strategy = integer(1),  ##     num_trees = integer(1), min_instances_per_node = min_rows(~integer(1),  ##         x), seed = sample.int(10^5, 1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_spark.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Random forests via spark — details_rand_forest_spark","text":"","code":"rand_forest(   mtry = integer(1),   trees = integer(1),   min_n = integer(1) ) %>%    set_engine(\"spark\") %>%    set_mode(\"classification\") %>%    translate() ## Random Forest Model Specification (classification) ##  ## Main Arguments: ##   mtry = integer(1) ##   trees = integer(1) ##   min_n = integer(1) ##  ## Computational engine: spark  ##  ## Model fit template: ## sparklyr::ml_random_forest(x = missing_arg(), formula = missing_arg(),  ##     type = \"classification\", feature_subset_strategy = integer(1),  ##     num_trees = integer(1), min_instances_per_node = min_rows(~integer(1),  ##         x), seed = sample.int(10^5, 1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_spark.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Random forests via spark — details_rand_forest_spark","text":"engine require special encoding predictors. Categorical predictors can partitioned groups factor levels (e.g. {, c} vs {b, d}) splitting node. Dummy variables required model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_spark.html","id":"other-details","dir":"Reference","previous_headings":"","what":"Other details","title":"Random forests via spark — details_rand_forest_spark","text":"models created using \"spark\" engine, several things consider. formula interface via fit() available; using fit_xy() generate error. predictions always Spark table format. names documented without dots. equivalent factor columns Spark tables class predictions returned character columns. retain model object new R session (via save()), model$fit element parsnip object serialized via ml_save(object$fit) separately saved disk. new session, object can reloaded reattached parsnip object.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_rand_forest_spark.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random forests via spark — details_rand_forest_spark","text":"Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_surv_reg_flexsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric survival regression — details_surv_reg_flexsurv","title":"Parametric survival regression — details_surv_reg_flexsurv","text":"flexsurv::flexsurvreg() fits parametric survival model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_surv_reg_flexsurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parametric survival regression — details_surv_reg_flexsurv","text":"engine, single mode: regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_surv_reg_flexsurv.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Parametric survival regression — details_surv_reg_flexsurv","text":"model 1 tuning parameters: dist: Distribution (type: character, default: ‘weibull’)","code":"## Warning: `surv_reg()` was deprecated in parsnip 0.1.6. ## Please use `survival_reg()` instead."},{"path":"https://parsnip.tidymodels.org/dev/reference/details_surv_reg_flexsurv.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Parametric survival regression — details_surv_reg_flexsurv","text":"","code":"surv_reg(dist = character(1)) %>%    set_engine(\"flexsurv\") %>%    set_mode(\"regression\") %>%    translate() ## Warning: `surv_reg()` was deprecated in parsnip 0.1.6. ## Please use `survival_reg()` instead.  ## Parametric Survival Regression Model Specification (regression) ##  ## Main Arguments: ##   dist = character(1) ##  ## Computational engine: flexsurv  ##  ## Model fit template: ## flexsurv::flexsurvreg(formula = missing_arg(), data = missing_arg(),  ##     weights = missing_arg(), dist = character(1))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_surv_reg_flexsurv.html","id":"other-details","dir":"Reference","previous_headings":"","what":"Other details","title":"Parametric survival regression — details_surv_reg_flexsurv","text":"main interface model uses formula method since model specification typically involved use survival::Surv(). engine, stratification specified via strata(), please see documentation flexsurv::flexsurv-package package alternative specifications.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_surv_reg_flexsurv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parametric survival regression — details_surv_reg_flexsurv","text":"Jackson, C. 2016. flexsurv: Platform Parametric Survival Modeling R. Journal Statistical Software, 70(8), 1 - 33.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_surv_reg_survival.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric survival regression — details_surv_reg_survival","title":"Parametric survival regression — details_surv_reg_survival","text":"survival::survreg() fits parametric survival model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_surv_reg_survival.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parametric survival regression — details_surv_reg_survival","text":"engine, single mode: regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_surv_reg_survival.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Parametric survival regression — details_surv_reg_survival","text":"model 1 tuning parameters: dist: Distribution (type: character, default: ‘weibull’)","code":"## Warning: `surv_reg()` was deprecated in parsnip 0.1.6. ## Please use `survival_reg()` instead."},{"path":"https://parsnip.tidymodels.org/dev/reference/details_surv_reg_survival.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Parametric survival regression — details_surv_reg_survival","text":"","code":"surv_reg(dist = character(1)) %>%    set_engine(\"survival\") %>%    set_mode(\"regression\") %>%    translate() ## Warning: `surv_reg()` was deprecated in parsnip 0.1.6. ## Please use `survival_reg()` instead.  ## Parametric Survival Regression Model Specification (regression) ##  ## Main Arguments: ##   dist = character(1) ##  ## Computational engine: survival  ##  ## Model fit template: ## survival::survreg(formula = missing_arg(), data = missing_arg(),  ##     weights = missing_arg(), dist = character(1), model = TRUE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_surv_reg_survival.html","id":"other-details","dir":"Reference","previous_headings":"","what":"Other details","title":"Parametric survival regression — details_surv_reg_survival","text":"Note model = TRUE needed produce quantile predictions stratification variable can overridden cases. main interface model uses formula method since model specification typically involved use survival::Surv(). model formula can include special terms, survival::strata(). allows model scale parameter differ groups contained function. column used inside strata() treated qualitative matter type. example, model, numeric column rx used estimate two different scale parameters value column:","code":"library(survival)  surv_reg() %>%    fit(Surv(futime, fustat) ~ age + strata(rx), data = ovarian) %>%    extract_fit_engine() ## Warning: `surv_reg()` was deprecated in parsnip 0.1.6. ## Please use `survival_reg()` instead.  ## Call: ## survival::survreg(formula = Surv(futime, fustat) ~ age + strata(rx),  ##     data = data, model = TRUE) ##  ## Coefficients: ## (Intercept)         age  ##  12.8734120  -0.1033569  ##  ## Scale: ##      rx=1      rx=2  ## 0.7695509 0.4703602  ##  ## Loglik(model)= -89.4   Loglik(intercept only)= -97.1 ##  Chisq= 15.36 on 1 degrees of freedom, p= 8.88e-05  ## n= 26"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_surv_reg_survival.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parametric survival regression — details_surv_reg_survival","text":"Kalbfleisch, J. D. Prentice, R. L. 2002 statistical analysis failure time data, Wiley.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_LiblineaR.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear support vector machines (SVMs) via LiblineaR — details_svm_linear_LiblineaR","title":"Linear support vector machines (SVMs) via LiblineaR — details_svm_linear_LiblineaR","text":"LiblineaR::LiblineaR() fits support vector machine model. classification, model tries maximize width margin classes. regression, model optimizes robust loss function affected large model residuals.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_LiblineaR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear support vector machines (SVMs) via LiblineaR — details_svm_linear_LiblineaR","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_LiblineaR.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Linear support vector machines (SVMs) via LiblineaR — details_svm_linear_LiblineaR","text":"model 2 tuning parameters: cost: Cost (type: double, default: 1.0) margin: Insensitivity Margin (type: double, default: default) engine fits models L2-regularized L2-loss. LiblineaR::LiblineaR() documentation, types 1 (classification) 11 (regression).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_LiblineaR.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Linear support vector machines (SVMs) via LiblineaR — details_svm_linear_LiblineaR","text":"","code":"svm_linear(   cost = double(1),   margin = double(1) ) %>%     set_engine(\"LiblineaR\") %>%    set_mode(\"regression\") %>%    translate() ## Linear Support Vector Machine Specification (regression) ##  ## Main Arguments: ##   cost = double(1) ##   margin = double(1) ##  ## Computational engine: LiblineaR  ##  ## Model fit template: ## LiblineaR::LiblineaR(x = missing_arg(), y = missing_arg(), wi = missing_arg(),  ##     C = double(1), svr_eps = double(1), type = 11)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_LiblineaR.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Linear support vector machines (SVMs) via LiblineaR — details_svm_linear_LiblineaR","text":"margin parameter apply classification models. Note LiblineaR engine produce class probabilities. optimizing model using tune package, default metrics require class probabilities. use tune_*() functions, metric set must passed argument contains metrics hard class predictions (e.g., accuracy).","code":"svm_linear(   cost = double(1) ) %>%    set_engine(\"LiblineaR\") %>%    set_mode(\"classification\") %>%    translate() ## Linear Support Vector Machine Specification (classification) ##  ## Main Arguments: ##   cost = double(1) ##  ## Computational engine: LiblineaR  ##  ## Model fit template: ## LiblineaR::LiblineaR(x = missing_arg(), y = missing_arg(), wi = missing_arg(),  ##     C = double(1), type = 1)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_LiblineaR.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Linear support vector machines (SVMs) via LiblineaR — details_svm_linear_LiblineaR","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_LiblineaR.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear support vector machines (SVMs) via LiblineaR — details_svm_linear_LiblineaR","text":"“Fitting Predicting parsnip” article contains examples svm_linear() \"LiblineaR\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_LiblineaR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear support vector machines (SVMs) via LiblineaR — details_svm_linear_LiblineaR","text":"Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_kernlab.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear support vector machines (SVMs) via kernlab — details_svm_linear_kernlab","title":"Linear support vector machines (SVMs) via kernlab — details_svm_linear_kernlab","text":"kernlab::ksvm() fits support vector machine model. classification, model tries maximize width margin classes. regression, model optimizes robust loss function affected large model residuals.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_kernlab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear support vector machines (SVMs) via kernlab — details_svm_linear_kernlab","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_kernlab.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Linear support vector machines (SVMs) via kernlab — details_svm_linear_kernlab","text":"model 2 tuning parameters: cost: Cost (type: double, default: 1.0) margin: Insensitivity Margin (type: double, default: 0.1)","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_kernlab.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Linear support vector machines (SVMs) via kernlab — details_svm_linear_kernlab","text":"","code":"svm_linear(   cost = double(1),   margin = double(1) ) %>%     set_engine(\"kernlab\") %>%    set_mode(\"regression\") %>%    translate() ## Linear Support Vector Machine Specification (regression) ##  ## Main Arguments: ##   cost = double(1) ##   margin = double(1) ##  ## Computational engine: kernlab  ##  ## Model fit template: ## kernlab::ksvm(x = missing_arg(), data = missing_arg(), C = double(1),  ##     epsilon = double(1), kernel = \"vanilladot\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_kernlab.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Linear support vector machines (SVMs) via kernlab — details_svm_linear_kernlab","text":"margin parameter apply classification models. Note \"kernlab\" engine naturally estimate class probabilities. produce , decision values model converted probabilities using Platt scaling. method fits additional model top SVM model. fitting Platt scaling model, random numbers used reproducible controlled R’s random number stream.","code":"svm_linear(   cost = double(1) ) %>%    set_engine(\"kernlab\") %>%    set_mode(\"classification\") %>%    translate() ## Linear Support Vector Machine Specification (classification) ##  ## Main Arguments: ##   cost = double(1) ##  ## Computational engine: kernlab  ##  ## Model fit template: ## kernlab::ksvm(x = missing_arg(), data = missing_arg(), C = double(1),  ##     kernel = \"vanilladot\", prob.model = TRUE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_kernlab.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Linear support vector machines (SVMs) via kernlab — details_svm_linear_kernlab","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_kernlab.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear support vector machines (SVMs) via kernlab — details_svm_linear_kernlab","text":"“Fitting Predicting parsnip” article contains examples svm_linear() \"kernlab\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_linear_kernlab.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear support vector machines (SVMs) via kernlab — details_svm_linear_kernlab","text":"Lin, HT, R Weng. “Note Platt’s Probabilistic Outputs Support Vector Machines” Karatzoglou, , Smola, , Hornik, K, Zeileis. 2004. “kernlab - S4 Package Kernel Methods R.”, Journal Statistical Software. Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_poly_kernlab.html","id":null,"dir":"Reference","previous_headings":"","what":"Polynomial support vector machines (SVMs) via kernlab — details_svm_poly_kernlab","title":"Polynomial support vector machines (SVMs) via kernlab — details_svm_poly_kernlab","text":"kernlab::ksvm() fits support vector machine model. classification, model tries maximize width margin classes. regression, model optimizes robust loss function affected large model residuals.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_poly_kernlab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Polynomial support vector machines (SVMs) via kernlab — details_svm_poly_kernlab","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_poly_kernlab.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Polynomial support vector machines (SVMs) via kernlab — details_svm_poly_kernlab","text":"model 4 tuning parameters: cost: Cost (type: double, default: 1.0) degree: Degree Interaction (type: integer, default: 1L1) scale_factor: Scale Factor (type: double, default: 1.0) margin: Insensitivity Margin (type: double, default: 0.1)","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_poly_kernlab.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Polynomial support vector machines (SVMs) via kernlab — details_svm_poly_kernlab","text":"","code":"svm_poly(   cost = double(1),   degree = integer(1),   scale_factor = double(1),    margin = double(1) ) %>%     set_engine(\"kernlab\") %>%    set_mode(\"regression\") %>%    translate() ## Polynomial Support Vector Machine Specification (regression) ##  ## Main Arguments: ##   cost = double(1) ##   degree = integer(1) ##   scale_factor = double(1) ##   margin = double(1) ##  ## Computational engine: kernlab  ##  ## Model fit template: ## kernlab::ksvm(x = missing_arg(), data = missing_arg(), C = double(1),  ##     epsilon = double(1), kernel = \"polydot\", kpar = list(degree = ~integer(1),  ##         scale = ~double(1)))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_poly_kernlab.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Polynomial support vector machines (SVMs) via kernlab — details_svm_poly_kernlab","text":"margin parameter apply classification models. Note \"kernlab\" engine naturally estimate class probabilities. produce , decision values model converted probabilities using Platt scaling. method fits additional model top SVM model. fitting Platt scaling model, random numbers used reproducible controlled R’s random number stream.","code":"svm_poly(   cost = double(1),   degree = integer(1),   scale_factor = double(1) ) %>%    set_engine(\"kernlab\") %>%    set_mode(\"classification\") %>%    translate() ## Polynomial Support Vector Machine Specification (classification) ##  ## Main Arguments: ##   cost = double(1) ##   degree = integer(1) ##   scale_factor = double(1) ##  ## Computational engine: kernlab  ##  ## Model fit template: ## kernlab::ksvm(x = missing_arg(), data = missing_arg(), C = double(1),  ##     kernel = \"polydot\", prob.model = TRUE, kpar = list(degree = ~integer(1),  ##         scale = ~double(1)))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_poly_kernlab.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Polynomial support vector machines (SVMs) via kernlab — details_svm_poly_kernlab","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_poly_kernlab.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Polynomial support vector machines (SVMs) via kernlab — details_svm_poly_kernlab","text":"“Fitting Predicting parsnip” article contains examples svm_poly() \"kernlab\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_poly_kernlab.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Polynomial support vector machines (SVMs) via kernlab — details_svm_poly_kernlab","text":"Lin, HT, R Weng. “Note Platt’s Probabilistic Outputs Support Vector Machines” Karatzoglou, , Smola, , Hornik, K, Zeileis. 2004. “kernlab - S4 Package Kernel Methods R.”, Journal Statistical Software. Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_rbf_kernlab.html","id":null,"dir":"Reference","previous_headings":"","what":"Radial basis function support vector machines (SVMs) via kernlab — details_svm_rbf_kernlab","title":"Radial basis function support vector machines (SVMs) via kernlab — details_svm_rbf_kernlab","text":"kernlab::ksvm() fits support vector machine model. classification, model tries maximize width margin classes. regression, model optimizes robust loss function affected large model residuals.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_rbf_kernlab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Radial basis function support vector machines (SVMs) via kernlab — details_svm_rbf_kernlab","text":"engine, multiple modes: classification regression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_rbf_kernlab.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Radial basis function support vector machines (SVMs) via kernlab — details_svm_rbf_kernlab","text":"model 3 tuning parameters: cost: Cost (type: double, default: 1.0) rbf_sigma: Radial Basis Function sigma (type: double, default: see ) margin: Insensitivity Margin (type: double, default: 0.1) default radial basis function kernel parameter. kernlab estimates data using heuristic method. See kernlab::sigest(). method uses random numbers , without setting seed fitting, model reproducible.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_rbf_kernlab.html","id":"translation-from-parsnip-to-the-original-package-regression-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (regression)","title":"Radial basis function support vector machines (SVMs) via kernlab — details_svm_rbf_kernlab","text":"","code":"svm_rbf(   cost = double(1),   rbf_sigma = double(1),    margin = double(1) ) %>%     set_engine(\"kernlab\") %>%    set_mode(\"regression\") %>%    translate() ## Radial Basis Function Support Vector Machine Specification (regression) ##  ## Main Arguments: ##   cost = double(1) ##   rbf_sigma = double(1) ##   margin = double(1) ##  ## Computational engine: kernlab  ##  ## Model fit template: ## kernlab::ksvm(x = missing_arg(), data = missing_arg(), C = double(1),  ##     epsilon = double(1), kernel = \"rbfdot\", kpar = list(sigma = ~double(1)))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_rbf_kernlab.html","id":"translation-from-parsnip-to-the-original-package-classification-","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package (classification)","title":"Radial basis function support vector machines (SVMs) via kernlab — details_svm_rbf_kernlab","text":"margin parameter apply classification models. Note \"kernlab\" engine naturally estimate class probabilities. produce , decision values model converted probabilities using Platt scaling. method fits additional model top SVM model. fitting Platt scaling model, random numbers used reproducible controlled R’s random number stream.","code":"svm_rbf(   cost = double(1),   rbf_sigma = double(1) ) %>%    set_engine(\"kernlab\") %>%    set_mode(\"classification\") %>%    translate() ## Radial Basis Function Support Vector Machine Specification (classification) ##  ## Main Arguments: ##   cost = double(1) ##   rbf_sigma = double(1) ##  ## Computational engine: kernlab  ##  ## Model fit template: ## kernlab::ksvm(x = missing_arg(), data = missing_arg(), C = double(1),  ##     kernel = \"rbfdot\", prob.model = TRUE, kpar = list(sigma = ~double(1)))"},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_rbf_kernlab.html","id":"preprocessing-requirements","dir":"Reference","previous_headings":"","what":"Preprocessing requirements","title":"Radial basis function support vector machines (SVMs) via kernlab — details_svm_rbf_kernlab","text":"Factor/categorical predictors need converted numeric values (e.g., dummy indicator variables) engine. using formula method via fit.model_spec(), parsnip convert factor columns indicators. Predictors scale. One way achieve center scale predictor mean zero variance one.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_rbf_kernlab.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Radial basis function support vector machines (SVMs) via kernlab — details_svm_rbf_kernlab","text":"“Fitting Predicting parsnip” article contains examples svm_rbf() \"kernlab\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/details_svm_rbf_kernlab.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Radial basis function support vector machines (SVMs) via kernlab — details_svm_rbf_kernlab","text":"Lin, HT, R Weng. “Note Platt’s Probabilistic Outputs Support Vector Machines” Karatzoglou, , Smola, , Hornik, K, Zeileis. 2004. “kernlab - S4 Package Kernel Methods R.”, Journal Statistical Software. Kuhn, M, K Johnson. 2013. Applied Predictive Modeling. Springer.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_flexible.html","id":null,"dir":"Reference","previous_headings":"","what":"Flexible discriminant analysis — discrim_flexible","title":"Flexible discriminant analysis — discrim_flexible","text":"discrim_flexible() defines model fits discriminant analysis model can use nonlinear features created using multivariate adaptive regression splines (MARS). different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_flexible.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Flexible discriminant analysis — discrim_flexible","text":"","code":"discrim_flexible(   mode = \"classification\",   num_terms = NULL,   prod_degree = NULL,   prune_method = NULL,   engine = \"earth\" )"},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_flexible.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flexible discriminant analysis — discrim_flexible","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". num_terms number features retained final model, including intercept. prod_degree highest possible interaction degree. prune_method pruning method. engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_flexible.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Flexible discriminant analysis — discrim_flexible","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_flexible.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Flexible discriminant analysis — discrim_flexible","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear discriminant analysis — discrim_linear","title":"Linear discriminant analysis — discrim_linear","text":"discrim_linear() defines model estimates multivariate distribution predictors separately data class (usually Gaussian common covariance matrix). Bayes' theorem used compute probability class, given predictor values. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Linear discriminant analysis — discrim_linear","text":"","code":"discrim_linear(   mode = \"classification\",   penalty = NULL,   regularization_method = NULL,   engine = \"MASS\" )"},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear discriminant analysis — discrim_linear","text":"mode single character string type model. possible value model \"classification\". penalty non-negative number representing amount regularization used engines. regularization_method character string type regularized estimation. Possible values : \"diagonal\", \"min_distance\", \"shrink_cov\", \"shrink_mean\" (sparsediscrim engine ). engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_linear.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear discriminant analysis — discrim_linear","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_linear.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear discriminant analysis — discrim_linear","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_quad.html","id":null,"dir":"Reference","previous_headings":"","what":"Quadratic discriminant analysis — discrim_quad","title":"Quadratic discriminant analysis — discrim_quad","text":"discrim_quad() defines model estimates multivariate distribution predictors separately data class (usually Gaussian separate covariance matrices). Bayes' theorem used compute probability class, given predictor values. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_quad.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Quadratic discriminant analysis — discrim_quad","text":"","code":"discrim_quad(   mode = \"classification\",   regularization_method = NULL,   engine = \"MASS\" )"},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_quad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quadratic discriminant analysis — discrim_quad","text":"mode single character string type model. possible value model \"classification\". regularization_method character string type regularized estimation. Possible values : \"diagonal\", \"shrink_cov\", \"shrink_mean\" (sparsediscrim engine ). engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_quad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quadratic discriminant analysis — discrim_quad","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_quad.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quadratic discriminant analysis — discrim_quad","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_regularized.html","id":null,"dir":"Reference","previous_headings":"","what":"Regularized discriminant analysis — discrim_regularized","title":"Regularized discriminant analysis — discrim_regularized","text":"discrim_regularized() defines model estimates multivariate distribution predictors separately data class. structure model can LDA, QDA, amalgam two. Bayes' theorem used compute probability class, given predictor values. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_regularized.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Regularized discriminant analysis — discrim_regularized","text":"","code":"discrim_regularized(   mode = \"classification\",   frac_common_cov = NULL,   frac_identity = NULL,   engine = \"klaR\" )"},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_regularized.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regularized discriminant analysis — discrim_regularized","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". frac_common_cov, frac_identity Numeric values zero one. engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_regularized.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regularized discriminant analysis — discrim_regularized","text":"many ways regularizing models. example, one form regularization penalize model parameters. Similarly, classic James–Stein regularization approach shrinks model structure less complex form. model fits specific type regularized model Friedman (1989) uses two types regularization. One modulates class-specific covariance matrix . allows model balance LDA QDA. second regularization component shrinks covariance matrix towards identity matrix. penalization approach, discrim_linear() mda engine can used. regularization methods can used discrim_linear() discrim_quad() can used via sparsediscrim engine functions. function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/discrim_regularized.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regularized discriminant analysis — discrim_regularized","text":"https://www.tidymodels.org, Tidy Modeling R Friedman, J (1989). Regularized Discriminant Analysis. Journal American Statistical Association, 84, 165-175.","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/doc-tools.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools for dynamically documenting packages — doc-tools","title":"Tools for dynamically documenting packages — doc-tools","text":"functions used create dynamic documentation Rd files based parsnip-related packages loaded user. functions can used make dynamic lists documentation help files. parsnip uses along files man/rmd contain expanded documentation specific model/engine combinations. find_engine_files() looks files pattern details_{model}_{engine}.Rd link . files generated files named man/rmd/{model}_{engine}.Rmd. make_engine_list() creates list seen top model Rd files make_seealso_list() populates list seen \"See Also\" . See details section.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/doc-tools.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Tools for dynamically documenting packages — doc-tools","text":"","code":"find_engine_files(mod, pkg = \"parsnip\")  make_engine_list(mod, pkg = \"parsnip\")  make_seealso_list(mod, pkg = \"parsnip\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/doc-tools.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools for dynamically documenting packages — doc-tools","text":"mod character string model file (e.g. \"linear_reg\") pkg character string package function invoked.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/doc-tools.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tools for dynamically documenting packages — doc-tools","text":"make_engine_list() returns character string creates bulleted list links specific help files. make_seealso_list() returns formatted character string links. find_engine_files() returns tibble.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/doc-tools.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tools for dynamically documenting packages — doc-tools","text":"parsnip documentation generated dynamically. Part Rd file populates list engines depends packages loaded time man file loaded. example, another package new engine linear_reg(), parsnip::linear_reg() help can show link detailed help page package. enable , process package developer : Create engine-specific R file R directory name {model}_{engine}.R (e.g. boost_tree_C5.0.R). small amount documentation, well directives \"@name details_{model}_{engine}\" \"@includeRmd man/rmd/{model}_{engine}.Rmd details\". Copy file parsnip man/rmd/setup.Rmd put place package. Write man/rmd/{model}_{engine}.Rmd file. can include packages listed DESCRIPTION file. required documentation file created locally (probably using devtools::document()). Run devtools::document() Rmd content included Rd file. examples parsnip can provide guidance organize technical information models.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/eval_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate parsnip model arguments — eval_args","title":"Evaluate parsnip model arguments — eval_args","text":"Evaluate parsnip model arguments","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/eval_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate parsnip model arguments — eval_args","text":"","code":"eval_args(spec, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/eval_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate parsnip model arguments — eval_args","text":"spec model specification ... used.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/extract-parsnip.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract elements of a parsnip model object — extract-parsnip","title":"Extract elements of a parsnip model object — extract-parsnip","text":"functions extract various elements parsnip object. exist yet, error thrown. extract_spec_parsnip() returns parsnip model specification. extract_fit_engine() returns engine specific fit embedded within parsnip model fit. example, using linear_reg() \"lm\" engine, returns underlying lm object.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/extract-parsnip.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Extract elements of a parsnip model object — extract-parsnip","text":"","code":"# S3 method for model_fit extract_spec_parsnip(x, ...)  # S3 method for model_fit extract_fit_engine(x, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/extract-parsnip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract elements of a parsnip model object — extract-parsnip","text":"x parsnip model_fit object. ... currently used.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/extract-parsnip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract elements of a parsnip model object — extract-parsnip","text":"extracted value parsnip object, x, described description section.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/extract-parsnip.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract elements of a parsnip model object — extract-parsnip","text":"Extracting underlying engine fit can helpful describing model (via print(), summary(), plot(), etc.) variable importance/explainers. However, users invoke predict() method extracted model. may preprocessing operations parsnip executed data prior giving model. Bypassing can lead errors silently generating incorrect predictions. Good:  Bad:","code":"parsnip_fit %>% predict(new_data) parsnip_fit %>% extract_fit_engine() %>% predict(new_data)"},{"path":"https://parsnip.tidymodels.org/dev/reference/fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Model Specification to a Dataset — fit.model_spec","title":"Fit a Model Specification to a Dataset — fit.model_spec","text":"fit() fit_xy() take model specification, translate required code substituting arguments, execute model fit routine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a Model Specification to a Dataset — fit.model_spec","text":"","code":"# S3 method for model_spec fit(object, formula, data, control = control_parsnip(), ...)  # S3 method for model_spec fit_xy(object, x, y, control = control_parsnip(), ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a Model Specification to a Dataset — fit.model_spec","text":"object object class model_spec chosen engine (via set_engine()). formula object class formula (one can coerced class): symbolic description model fitted. data Optional, depending interface (see Details ). data frame containing relevant variables (e.g. outcome(s), predictors, case weights, etc). Note: needed, named argument used. control named list elements verbosity catch. See control_parsnip(). ... currently used; values passed ignored. options required fit model passed using set_engine(). x matrix, sparse matrix, data frame predictors. models support sparse matrix input. See parsnip::get_encoding() details. x column names. y vector, matrix data frame outcome data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a Model Specification to a Dataset — fit.model_spec","text":"model_fit object contains several elements: lvl: outcome factor, contains factor levels time model fitting. spec: model specification object (object call fit) fit: model executed without error, model object. Otherwise, try-error object error message. preproc: objects needed convert formula non-formula interface (terms object) return value also class related fitted model (e.g. \"_glm\") base class \"model_fit\".","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a Model Specification to a Dataset — fit.model_spec","text":"fit() fit_xy() substitute current arguments model specification computational engine's code, check validity, fit model using data engine-specific code. Different model functions different interfaces (e.g. formula x/y) functions translate interface used fit() fit_xy() invoked one required underlying model. possible, functions attempt avoid making copies data. example, underlying model uses formula fit() invoked, original data references model fit. However, underlying model uses something else, x/y, formula evaluated data converted required format. case, calls resulting model objects reference temporary objects used fit model. model engine set, model's default engine used (discussed model page). verbosity option control_parsnip() greater zero, warning produced. like use alternative method generating contrasts supplying formula fit(), set global option contrasts preferred method. example, might set : options(contrasts = c(unordered = \"contr.helmert\", ordered = \"contr.poly\")). See help page stats::contr.treatment() possible contrast types.","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/gen_additive_mod.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized additive models (GAMs) — gen_additive_mod","title":"Generalized additive models (GAMs) — gen_additive_mod","text":"gen_additive_mod() defines model can use smoothed functions numeric predictors generalized linear model. different ways fit model. See engine-specific pages details engine-specific pages model listed  contain details: mgcv  (default) information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/gen_additive_mod.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized additive models (GAMs) — gen_additive_mod","text":"","code":"gen_additive_mod(   mode = \"unknown\",   select_features = NULL,   adjust_deg_free = NULL,   engine = \"mgcv\" )"},{"path":"https://parsnip.tidymodels.org/dev/reference/gen_additive_mod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized additive models (GAMs) — gen_additive_mod","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". select_features TRUE FALSE. TRUE, model ability eliminate predictor (via penalization). Increasing adjust_deg_free increase likelihood removing predictors. adjust_deg_free select_features = TRUE, acts multiplier smoothness. Increase beyond 1 produce smoother models. engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/gen_additive_mod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized additive models (GAMs) — gen_additive_mod","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/gen_additive_mod.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized additive models (GAMs) — gen_additive_mod","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/get_model_env.html","id":null,"dir":"Reference","previous_headings":"","what":"Working with the parsnip model environment — get_model_env","title":"Working with the parsnip model environment — get_model_env","text":"functions read write environment package stores information model specifications.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/get_model_env.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Working with the parsnip model environment — get_model_env","text":"","code":"get_model_env()  get_from_env(items)  set_in_env(...)  set_env_val(name, value)"},{"path":"https://parsnip.tidymodels.org/dev/reference/get_model_env.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Working with the parsnip model environment — get_model_env","text":"items character string objects model environment. ... Named values assigned model environment. name single character value new symbol model environment. value single value new value model environment.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/get_model_env.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Working with the parsnip model environment — get_model_env","text":"\"build parsnip model\" https://www.tidymodels.org/learn/develop/models/","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/glance.model_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a single row summary ","title":"Construct a single row summary ","text":"method glances model parsnip model object, exists.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/glance.model_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a single row summary ","text":"","code":"# S3 method for model_fit glance(x, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/glance.model_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a single row summary ","text":"x model R object convert single-row data frame ... arguments passed methods","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/glance.model_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a single row summary ","text":"tibble","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/glmnet-details.html","id":null,"dir":"Reference","previous_headings":"","what":"Technical aspects of the glmnet model — glmnet-details","title":"Technical aspects of the glmnet model — glmnet-details","text":"glmnet popular statistical model regularized generalized linear models. notes reflect common questions particular model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/glmnet-details.html","id":"tidymodels-and-glmnet","dir":"Reference","previous_headings":"","what":"tidymodels and glmnet","title":"Technical aspects of the glmnet model — glmnet-details","text":"implementation glmnet package nice features. example, one main tuning parameters, regularization penalty, need specified fitting model. package fits compendium values, called regularization path. values depend data set value alpha, mixture parameter pure ridge model (alpha = 0) pure lasso model (alpha = 1). predicting, penalty values can simultaneously predicted, even exactly regularization path. , model approximates closest path values produce prediction. argument called lambda glmnet() function used specify path. discussion , linear_reg() used. information true parsnip models \"glmnet\" engine.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/glmnet-details.html","id":"fitting-and-predicting-using-parsnip","dir":"Reference","previous_headings":"","what":"Fitting and predicting using parsnip","title":"Technical aspects of the glmnet model — glmnet-details","text":"Recall tidymodels uses standardized parameter names across models chosen low jargon. argument penalty equivalent glmnet calls lambda value mixture alpha value. tidymodels, predict() methods defined make one prediction time. model, means predictions single penalty value. reason, models glmnet engines require user always specify single penalty value model defined. example, linear regression:  predict() method called, automatically uses penalty given model defined. example:  However, penalty values can predicted simultaneously using multi_predict() method:","code":"linear_reg(penalty = 1) %>% set_engine(\"glmnet\") library(tidymodels)  fit <-    linear_reg(penalty = 1) %>%    set_engine(\"glmnet\") %>%    fit(mpg ~ ., data = mtcars)  # predict at penalty = 1 predict(fit, mtcars[1:3,]) ## # A tibble: 3 × 1 ##   .pred ##   <dbl> ## 1  22.2 ## 2  21.5 ## 3  24.9 # predict at c(0.00, 0.01) multi_predict(fit, mtcars[1:3,], penalty = c(0.00, 0.01)) ## # A tibble: 3 × 1 ##   .pred            ##   <list>           ## 1 <tibble [2 × 2]> ## 2 <tibble [2 × 2]> ## 3 <tibble [2 × 2]> # unnested: multi_predict(fit, mtcars[1:3,], penalty = c(0.00, 0.01)) %>%    add_rowindex() %>%    unnest(cols = \".pred\") ## # A tibble: 6 × 3 ##   penalty .pred  .row ##     <dbl> <dbl> <int> ## 1    0     22.6     1 ## 2    0.01  22.5     1 ## 3    0     22.1     2 ## 4    0.01  22.1     2 ## 5    0     26.3     3 ## 6    0.01  26.3     3"},{"path":"https://parsnip.tidymodels.org/dev/reference/glmnet-details.html","id":"where-did-lambda-go-","dir":"Reference","previous_headings":"","what":"Where did lambda go?","title":"Technical aspects of the glmnet model — glmnet-details","text":"may appear odd lambda value get used fit:  Internally, value penalty = 1 saved parsnip object value set lambda. enables full path fit glmnet(). See section setting path.","code":"linear_reg(penalty = 1) %>%    set_engine(\"glmnet\") %>%    translate() ## Linear Regression Model Specification (regression) ##  ## Main Arguments: ##   penalty = 1 ##  ## Computational engine: glmnet  ##  ## Model fit template: ## glmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(),  ##     family = \"gaussian\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/glmnet-details.html","id":"how-do-i-set-the-regularization-path-","dir":"Reference","previous_headings":"","what":"How do I set the regularization path?","title":"Technical aspects of the glmnet model — glmnet-details","text":"Regardless value use penalty, full coefficient path used glmnet::glmnet() called. want manually set path? Normally, pass vector lambda glmnet::glmnet(). parsnip models use glmnet engine can use special optional argument called path_values. argument glmnet::glmnet(); used parsnip independently set path. example, found want fully ridge regression model (.e., mixture = 0), can get wrong coefficients path contain zero (see issue #431). want use path, argument passed engine-specific option:","code":"coef_path_values <- c(0, 10^seq(-5, 1, length.out = 7))  fit_ridge <-    linear_reg(penalty = 1, mixture = 0) %>%    set_engine(\"glmnet\", path_values = coef_path_values) %>%    fit(mpg ~ ., data = mtcars)  all.equal(sort(fit_ridge$fit$lambda), coef_path_values) ## [1] TRUE # predict at penalty = 1 predict(fit_ridge, mtcars[1:3,]) ## # A tibble: 3 × 1 ##   .pred ##   <dbl> ## 1  22.1 ## 2  21.8 ## 3  26.6"},{"path":"https://parsnip.tidymodels.org/dev/reference/glmnet-details.html","id":"tidying-the-model-object","dir":"Reference","previous_headings":"","what":"Tidying the model object","title":"Technical aspects of the glmnet model — glmnet-details","text":"broom::tidy() function gives summary object tibble. tl;dr tidy() glmnet model produced parsnip gives coefficients value given penalty. parsnip makes model, gives extra class. Use tidy() method object, produces coefficients penalty originally requested:  Note tidy() method glmnet objects broom package. used directly underlying glmnet object, returns coefficients path:    can nice plots might contain penalty value interested .","code":"tidy(fit) ## # A tibble: 11 × 3 ##    term        estimate penalty ##    <chr>          <dbl>   <dbl> ##  1 (Intercept)  35.3          1 ##  2 cyl          -0.872        1 ##  3 disp          0            1 ##  4 hp           -0.0101       1 ##  5 drat          0            1 ##  6 wt           -2.59         1 ##  7 qsec          0            1 ##  8 vs            0            1 ##  9 am            0            1 ## 10 gear          0            1 ## 11 carb          0            1 # Use the basic tidy() method for glmnet all_tidy_coefs <- broom:::tidy.glmnet(fit$fit) all_tidy_coefs ## # A tibble: 640 × 5 ##    term         step estimate lambda dev.ratio ##    <chr>       <dbl>    <dbl>  <dbl>     <dbl> ##  1 (Intercept)     1     20.1   5.15     0     ##  2 (Intercept)     2     21.6   4.69     0.129 ##  3 (Intercept)     3     23.2   4.27     0.248 ##  4 (Intercept)     4     24.7   3.89     0.347 ##  5 (Intercept)     5     26.0   3.55     0.429 ##  6 (Intercept)     6     27.2   3.23     0.497 ##  7 (Intercept)     7     28.4   2.95     0.554 ##  8 (Intercept)     8     29.4   2.68     0.601 ##  9 (Intercept)     9     30.3   2.45     0.640 ## 10 (Intercept)    10     31.1   2.23     0.673 ## # … with 630 more rows length(unique(all_tidy_coefs$lambda)) ## [1] 79"},{"path":"https://parsnip.tidymodels.org/dev/reference/glmnet_helpers.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper functions for checking the penalty of glmnet models — .check_glmnet_penalty_fit","title":"Helper functions for checking the penalty of glmnet models — .check_glmnet_penalty_fit","text":"functions developer use. .check_glmnet_penalty_fit() checks model specification fitting glmnet model contains single value. .check_glmnet_penalty_predict() checks penalty value used prediction valid. called predict(), needs single value. Multiple values allowed multi_predict().","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/glmnet_helpers.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Helper functions for checking the penalty of glmnet models — .check_glmnet_penalty_fit","text":"","code":".check_glmnet_penalty_fit(x)  .check_glmnet_penalty_predict(penalty = NULL, object, multi = FALSE)"},{"path":"https://parsnip.tidymodels.org/dev/reference/glmnet_helpers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper functions for checking the penalty of glmnet models — .check_glmnet_penalty_fit","text":"x object class model_spec. penalty penalty value check. object object class model_fit. multi logical indicating multiple values allowed.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/glmnet_helpers_prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Organize glmnet predictions — .organize_glmnet_pred","title":"Organize glmnet predictions — .organize_glmnet_pred","text":"function developer use organizes predictions glmnet models.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/glmnet_helpers_prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Organize glmnet predictions — .organize_glmnet_pred","text":"","code":".organize_glmnet_pred(x, object)"},{"path":"https://parsnip.tidymodels.org/dev/reference/glmnet_helpers_prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Organize glmnet predictions — .organize_glmnet_pred","text":"x Predictions returned predict() method glmnet models. object object class model_fit.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/has_multi_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools for models that predict on sub-models — has_multi_predict","title":"Tools for models that predict on sub-models — has_multi_predict","text":"has_multi_predict() tests see object can make multiple predictions submodels object. multi_predict_args() returns names arguments multi_predict() model ().","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/has_multi_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Tools for models that predict on sub-models — has_multi_predict","text":"","code":"has_multi_predict(object, ...)  # S3 method for default has_multi_predict(object, ...)  # S3 method for model_fit has_multi_predict(object, ...)  # S3 method for workflow has_multi_predict(object, ...)  multi_predict_args(object, ...)  # S3 method for default multi_predict_args(object, ...)  # S3 method for model_fit multi_predict_args(object, ...)  # S3 method for workflow multi_predict_args(object, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/has_multi_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools for models that predict on sub-models — has_multi_predict","text":"object object test. ... currently used.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/has_multi_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tools for models that predict on sub-models — has_multi_predict","text":"has_multi_predict() returns single logical value multi_predict_args() returns character vector argument names (NAif none exist).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/keras_mlp.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple interface to MLP models via keras — keras_mlp","title":"Simple interface to MLP models via keras — keras_mlp","text":"Instead building keras model sequentially, keras_mlp can used create feedforward network single hidden layer. Regularization via either weight decay dropout.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/keras_mlp.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Simple interface to MLP models via keras — keras_mlp","text":"","code":"keras_mlp(   x,   y,   hidden_units = 5,   penalty = 0,   dropout = 0,   epochs = 20,   activation = \"softmax\",   seeds = sample.int(10^5, size = 3),   ... )"},{"path":"https://parsnip.tidymodels.org/dev/reference/keras_mlp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple interface to MLP models via keras — keras_mlp","text":"x data frame matrix predictors y vector (factor numeric) matrix (numeric) outcome data. hidden_units integer number hidden units. penalty non-negative real number amount weight decay. Either parameter dropout can specified. dropout proportion parameters set zero. Either parameter penalty can specified. epochs integer number passes data. activation character string type activation function layers. seeds vector three positive integers control randomness calculations. ... Currently ignored.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/keras_mlp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple interface to MLP models via keras — keras_mlp","text":"keras model object.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/linear_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear regression — linear_reg","title":"Linear regression — linear_reg","text":"linear_reg() defines model can predict numeric values predictors using linear function. different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: lm  (default) glmnet stan spark keras information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/linear_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Linear regression — linear_reg","text":"","code":"linear_reg(mode = \"regression\", engine = \"lm\", penalty = NULL, mixture = NULL)"},{"path":"https://parsnip.tidymodels.org/dev/reference/linear_reg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear regression — linear_reg","text":"mode single character string type model. possible value model \"regression\". engine single character string specifying computational engine use fitting. Possible engines listed . default model \"lm\". penalty non-negative number representing total amount regularization (specific engines ). mixture number zero one (inclusive) proportion L1 regularization (.e. lasso) model. mixture = 1, pure lasso model mixture = 0 indicates ridge regression used (specific engines ).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/linear_reg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear regression — linear_reg","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/linear_reg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear regression — linear_reg","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/logistic_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Logistic regression — logistic_reg","title":"Logistic regression — logistic_reg","text":"logistic_reg() defines generalized linear model binary outcomes. linear combination predictors used model log odds event. different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: glm  (default) glmnet LiblineaR spark keras stan information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/logistic_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Logistic regression — logistic_reg","text":"","code":"logistic_reg(   mode = \"classification\",   engine = \"glm\",   penalty = NULL,   mixture = NULL )"},{"path":"https://parsnip.tidymodels.org/dev/reference/logistic_reg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logistic regression — logistic_reg","text":"mode single character string type model. possible value model \"classification\". engine single character string specifying computational engine use fitting. Possible engines listed . default model \"glm\". penalty non-negative number representing total amount regularization (specific engines ). keras models, corresponds purely L2 regularization (aka weight decay) models can either combination L1 L2 (depending value mixture). mixture number zero one (inclusive) proportion L1 regularization (.e. lasso) model. mixture = 1, pure lasso model mixture = 0 indicates ridge regression used. (specific engines ). LiblineaR models, mixture must exactly 0 1 .","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/logistic_reg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Logistic regression — logistic_reg","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/logistic_reg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Logistic regression — logistic_reg","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/make_call.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a parsnip call expression — make_call","title":"Make a parsnip call expression — make_call","text":"Make parsnip call expression","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/make_call.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Make a parsnip call expression — make_call","text":"","code":"make_call(fun, ns, args, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/make_call.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a parsnip call expression — make_call","text":"fun character string function name. ns character string package name. args named list argument values.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/make_call.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a parsnip call expression — make_call","text":"call.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/make_call.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make a parsnip call expression — make_call","text":"arguments spliced ns::fun() call. missing, null, single logical, spliced.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/make_classes.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepend a new class — make_classes","title":"Prepend a new class — make_classes","text":"adds extra class base class \"model_spec\".","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/make_classes.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Prepend a new class — make_classes","text":"","code":"make_classes(prefix)"},{"path":"https://parsnip.tidymodels.org/dev/reference/make_classes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepend a new class — make_classes","text":"prefix character string class.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/make_classes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepend a new class — make_classes","text":"character vector.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/mars.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate adaptive regression splines (MARS) — mars","title":"Multivariate adaptive regression splines (MARS) — mars","text":"mars() defines generalized linear model uses artificial features predictors. features resemble hinge functions result model segmented regression small dimensions. different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: earth  (default) information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/mars.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate adaptive regression splines (MARS) — mars","text":"","code":"mars(   mode = \"unknown\",   engine = \"earth\",   num_terms = NULL,   prod_degree = NULL,   prune_method = NULL )"},{"path":"https://parsnip.tidymodels.org/dev/reference/mars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multivariate adaptive regression splines (MARS) — mars","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". engine single character string specifying computational engine use fitting. num_terms number features retained final model, including intercept. prod_degree highest possible interaction degree. prune_method pruning method.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/mars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multivariate adaptive regression splines (MARS) — mars","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/mars.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multivariate adaptive regression splines (MARS) — mars","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/maybe_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Fuzzy conversions — maybe_matrix","title":"Fuzzy conversions — maybe_matrix","text":"substitutes .matrix() .data.frame() leave sparse matrix -.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/maybe_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Fuzzy conversions — maybe_matrix","text":"","code":"maybe_matrix(x)  maybe_data_frame(x)"},{"path":"https://parsnip.tidymodels.org/dev/reference/maybe_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fuzzy conversions — maybe_matrix","text":"x data frame, matrix, sparse matrix.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/maybe_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fuzzy conversions — maybe_matrix","text":"data frame, matrix, sparse matrix.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/min_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Execution-time data dimension checks — min_cols","title":"Execution-time data dimension checks — min_cols","text":"tuning parameters, range values depend data dimensions (e.g. mtry). packages fail parameter values outside ranges. Since model might receive resampled versions data, ranges set prior point model fit.  functions check possible range data adjust needed (warning).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/min_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Execution-time data dimension checks — min_cols","text":"","code":"min_cols(num_cols, source)  min_rows(num_rows, source, offset = 0)"},{"path":"https://parsnip.tidymodels.org/dev/reference/min_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execution-time data dimension checks — min_cols","text":"num_cols, num_rows parameter value requested user. source data frame data used fit. source named \"data\", assumed one column data corresponds outcome (subtracted ). offset number subtracted number rows available data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/min_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Execution-time data dimension checks — min_cols","text":"integer (perhaps warning).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/mlp.html","id":null,"dir":"Reference","previous_headings":"","what":"Single layer neural network — mlp","title":"Single layer neural network — mlp","text":"mlp() defines multilayer perceptron model (.k.. single layer, feed-forward neural network). different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: keras nnet  (default) information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/mlp.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Single layer neural network — mlp","text":"","code":"mlp(   mode = \"unknown\",   engine = \"nnet\",   hidden_units = NULL,   penalty = NULL,   dropout = NULL,   epochs = NULL,   activation = NULL )"},{"path":"https://parsnip.tidymodels.org/dev/reference/mlp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Single layer neural network — mlp","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". engine single character string specifying computational engine use fitting. hidden_units integer number units hidden model. penalty non-negative numeric value amount weight decay. dropout number 0 (inclusive) 1 denoting proportion model parameters randomly set zero model training. epochs integer number training iterations. activation single character string denoting type relationship original predictors hidden unit layer. activation function hidden output layers automatically set either \"linear\" \"softmax\" depending type outcome. Possible values : \"linear\", \"softmax\", \"relu\", \"elu\"","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/mlp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Single layer neural network — mlp","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/mlp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Single layer neural network — mlp","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/model_db.html","id":null,"dir":"Reference","previous_headings":"","what":"parsnip model specification database — model_db","title":"parsnip model specification database — model_db","text":"used RStudio add-captures information mode specifications various R packages.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/model_db.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"parsnip model specification database — model_db","text":"model_db data frame","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/model_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Fit Object Information — model_fit","title":"Model Fit Object Information — model_fit","text":"object class \"model_fit\" container information model fit data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/model_fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model Fit Object Information — model_fit","text":"main elements object : lvl: vector factor levels outcome factor. NULL outcome factor vector. spec: model_spec object. fit: object produced fitting function. preproc: contains data-specific information required process new sample point prediction. example, underlying model function requires arguments x y user passed formula fit, preproc object contain items terms object . information required, NA. discussed documentation model_spec, original arguments specification saved quosures. evaluated model_fit object prior fitting. resulting model object prints call, user-defined options shown call preceded tilde (see example ). result use quosures specification. class structure basis parsnip stores model objects seeing data applying model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/model_printer.html","id":null,"dir":"Reference","previous_headings":"","what":"Print helper for model objects — model_printer","title":"Print helper for model objects — model_printer","text":"common format function prints information model object (e.g. arguments, calls, packages, etc).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/model_printer.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Print helper for model objects — model_printer","text":"","code":"model_printer(x, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/model_printer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print helper for model objects — model_printer","text":"x model object. ... currently used.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/model_spec.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Specification Information — model_spec","title":"Model Specification Information — model_spec","text":"object class \"model_spec\" container information model fit.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/model_spec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model Specification Information — model_spec","text":"main elements object : args: vector main arguments model. names arguments may different counterparts n underlying model function. example, glmnet model, argument name amount penalty called \"penalty\" instead \"lambda\" make general usable across different types models (specific particular model function). elements args can varying(). left defaults (NULL), arguments use underlying model functions default value. discussed , arguments args captured quosures immediately executed. ...: Optional model-function-specific parameters. args, quosures can varying(). mode: type model, \"regression\" \"classification\". modes added package adds functionality. method: slot filled later model's constructor function. generally contains lists information used create fit prediction code well required packages similar data. engine: character string declares exactly software used. can package name technology type. class structure basis parsnip stores model objects prior seeing data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/model_spec.html","id":"argument-details","dir":"Reference","previous_headings":"","what":"Argument Details","title":"Model Specification Information — model_spec","text":"important detail understand creating model specifications intended functionally independent data. true tuning parameters data dependent, model specification interact data . example, R functions immediately evaluate arguments. example, calling mean(dat_vec), object dat_vec immediately evaluated inside function. parsnip model functions . example, using execute ncol(mtcars) - 1 creating specification. can seen output: model functions save argument expressions associated environments (.k.. quosure) evaluated later either fit.model_spec() fit_xy.model_spec()  called actual data. consequence strategy data required get parameter values must available model fit. two main ways can fail : data modified creation model specification model fit function invoked. model specification saved loaded new session data objects exist. best way avoid issues reference data objects global environment use data descriptors .cols(). Another way writing previous specification dependent specific data object evaluated immediately model fitting process begins. One less advantageous approach solving issue use quasiquotation. insert actual R object model specification might best idea data object small. example, using work (reproducible sessions) embeds entire mtcars data set mtry expression: However, object number columns , bad: information quosures quasiquotation can found https://tidyeval.tidyverse.org.","code":"rand_forest(mtry = ncol(mtcars) - 1) > rand_forest(mtry = ncol(mtcars) - 1)  Random Forest Model Specification (unknown)   Main Arguments:    mtry = ncol(mtcars) - 1 rand_forest(mtry = .cols() - 1) rand_forest(mtry = ncol(!!mtcars) - 1) > rand_forest(mtry = ncol(!!mtcars) - 1)  Random Forest Model Specification (unknown)   Main Arguments:    mtry = ncol(structure(list(Sepal.Length = c(5.1, 4.9, 4.7, 4.6, 5, <snip> > mtry_val <- ncol(mtcars) - 1  > mtry_val  [1] 10  > rand_forest(mtry = !!mtry_val)  Random Forest Model Specification (unknown)   Main Arguments:    mtry = 10"},{"path":"https://parsnip.tidymodels.org/dev/reference/multi_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Model predictions across many sub-models — multi_predict","title":"Model predictions across many sub-models — multi_predict","text":"models, predictions can made sub-models model object.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/multi_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Model predictions across many sub-models — multi_predict","text":"","code":"multi_predict(object, ...)  # S3 method for default multi_predict(object, ...)  # S3 method for `_xgb.Booster` multi_predict(object, new_data, type = NULL, trees = NULL, ...)  # S3 method for `_C5.0` multi_predict(object, new_data, type = NULL, trees = NULL, ...)  # S3 method for `_elnet` multi_predict(object, new_data, type = NULL, penalty = NULL, ...)  # S3 method for `_lognet` multi_predict(object, new_data, type = NULL, penalty = NULL, ...)  # S3 method for `_earth` multi_predict(object, new_data, type = NULL, num_terms = NULL, ...)  # S3 method for `_multnet` multi_predict(object, new_data, type = NULL, penalty = NULL, ...)  # S3 method for `_train.kknn` multi_predict(object, new_data, type = NULL, neighbors = NULL, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/multi_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model predictions across many sub-models — multi_predict","text":"object model_fit object. ... Optional arguments pass predict.model_fit(type = \"raw\") type. new_data rectangular data object, data frame. type single character value NULL. Possible values \"numeric\", \"class\", \"prob\", \"conf_int\", \"pred_int\", \"quantile\", \"raw\". NULL, predict() choose appropriate value based model's mode. trees integer vector number trees ensemble. penalty numeric vector penalty values. num_terms integer vector number MARS terms retain. neighbors integer vector number nearest neighbors.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/multi_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model predictions across many sub-models — multi_predict","text":"tibble number rows data predicted. list-column named .pred contains tibbles multiple rows per sub-model. Note , within tibbles, column names follow usual standard based prediction type (.e. .pred_class type = \"class\" ).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/multinom_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial regression — multinom_reg","title":"Multinomial regression — multinom_reg","text":"multinom_reg() defines model uses linear predictors predict multiclass data using multinomial distribution. different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: glmnet spark keras nnet  (default) information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/multinom_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Multinomial regression — multinom_reg","text":"","code":"multinom_reg(   mode = \"classification\",   engine = \"nnet\",   penalty = NULL,   mixture = NULL )"},{"path":"https://parsnip.tidymodels.org/dev/reference/multinom_reg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinomial regression — multinom_reg","text":"mode single character string type model. possible value model \"classification\". engine single character string specifying computational engine use fitting. Possible engines listed . default model \"nnet\". penalty non-negative number representing total amount regularization (specific engines ). keras models, corresponds purely L2 regularization (aka weight decay) models can combination L1 L2 (depending value mixture). mixture number zero one (inclusive) proportion L1 regularization (.e. lasso) model. mixture = 1, pure lasso model mixture = 0 indicates ridge regression used. (specific engines ).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/multinom_reg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinomial regression — multinom_reg","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/multinom_reg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multinomial regression — multinom_reg","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/naive_Bayes.html","id":null,"dir":"Reference","previous_headings":"","what":"Naive Bayes models — naive_Bayes","title":"Naive Bayes models — naive_Bayes","text":"naive_Bayes() defines model uses Bayes' theorem compute probability class, given predictor values. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/naive_Bayes.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Naive Bayes models — naive_Bayes","text":"","code":"naive_Bayes(   mode = \"classification\",   smoothness = NULL,   Laplace = NULL,   engine = \"klaR\" )"},{"path":"https://parsnip.tidymodels.org/dev/reference/naive_Bayes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Naive Bayes models — naive_Bayes","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". smoothness non-negative number representing relative smoothness class boundary. Smaller examples result model flexible boundaries larger values generate class boundaries less adaptable Laplace non-negative value Laplace correction smoothing low-frequency counts. engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/naive_Bayes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Naive Bayes models — naive_Bayes","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/naive_Bayes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Naive Bayes models — naive_Bayes","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/nearest_neighbor.html","id":null,"dir":"Reference","previous_headings":"","what":"K-nearest neighbors — nearest_neighbor","title":"K-nearest neighbors — nearest_neighbor","text":"nearest_neighbor() defines model uses K similar data points training set predict new samples. different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: kknn  (default) information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/nearest_neighbor.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"K-nearest neighbors — nearest_neighbor","text":"","code":"nearest_neighbor(   mode = \"unknown\",   engine = \"kknn\",   neighbors = NULL,   weight_func = NULL,   dist_power = NULL )"},{"path":"https://parsnip.tidymodels.org/dev/reference/nearest_neighbor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"K-nearest neighbors — nearest_neighbor","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". engine single character string specifying computational engine use fitting. neighbors single integer number neighbors consider (often called k). kknn, value 5 used neighbors specified. weight_func single character type kernel function used weight distances samples. Valid choices : \"rectangular\", \"triangular\", \"epanechnikov\", \"biweight\", \"triweight\", \"cos\", \"inv\", \"gaussian\", \"rank\", \"optimal\". dist_power single number parameter used calculating Minkowski distance.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/nearest_neighbor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"K-nearest neighbors — nearest_neighbor","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/nearest_neighbor.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"K-nearest neighbors — nearest_neighbor","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/null_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Null model — null_model","title":"Null model — null_model","text":"null_model() defines simple, non-informative model. main arguments.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/null_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Null model — null_model","text":"","code":"null_model(mode = \"classification\")"},{"path":"https://parsnip.tidymodels.org/dev/reference/null_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Null model — null_model","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\".","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/null_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Null model — null_model","text":"model can created using fit() function using following engines: R:  \"parsnip\"","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/null_model.html","id":"engine-details","dir":"Reference","previous_headings":"","what":"Engine Details","title":"Null model — null_model","text":"Engines may pre-set default arguments executing model fit call. type model, template fit calls :","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/null_model.html","id":"parsnip","dir":"Reference","previous_headings":"","what":"parsnip","title":"Null model — null_model","text":"","code":"null_model() %>%    set_engine(\"parsnip\") %>%    set_mode(\"regression\") %>%    translate() ## Model Specification (regression) ##  ## Computational engine: parsnip  ##  ## Model fit template: ## nullmodel(x = missing_arg(), y = missing_arg()) null_model() %>%    set_engine(\"parsnip\") %>%    set_mode(\"classification\") %>%    translate() ## Model Specification (classification) ##  ## Computational engine: parsnip  ##  ## Model fit template: ## nullmodel(x = missing_arg(), y = missing_arg())"},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/nullmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a simple, non-informative model — nullmodel","title":"Fit a simple, non-informative model — nullmodel","text":"Fit single mean largest class model. nullmodel() underlying computational function null_model() specification.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/nullmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a simple, non-informative model — nullmodel","text":"","code":"nullmodel(x, ...)  # S3 method for default nullmodel(x = NULL, y, ...)  # S3 method for nullmodel print(x, ...)  # S3 method for nullmodel predict(object, new_data = NULL, type = NULL, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/nullmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a simple, non-informative model — nullmodel","text":"x optional matrix data frame predictors. values used model fit ... Optional arguments (yet used) y numeric vector (regression) factor (classification) outcomes object object class nullmodel new_data matrix data frame predictors (used determine number predictions return) type Either \"raw\" (regression), \"class\" \"prob\" (classification)","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/nullmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a simple, non-informative model — nullmodel","text":"output nullmodel() list class nullmodelwith elements call function call value mean y prevalent class levels y factor, vector levels. NULL otherwise pct y factor, data frame column class (NULL otherwise). column prevalent class proportion training samples class (columns zero). n number elements y predict.nullmodel() returns either factor numeric vector depending class y. predictions always .","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/nullmodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a simple, non-informative model — nullmodel","text":"nullmodel() emulates model building functions, returns simplest model possible given training set: single mean numeric outcomes prevalent class factor outcomes. class probabilities requested, percentage training set samples prevalent class returned.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/other_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Other predict methods. — predict_class.model_fit","title":"Other predict methods. — predict_class.model_fit","text":"internal functions meant directly called user.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/other_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Other predict methods. — predict_class.model_fit","text":"","code":"# S3 method for model_fit predict_class(object, new_data, ...)  # S3 method for model_fit predict_classprob(object, new_data, ...)  # S3 method for model_fit predict_hazard(object, new_data, time, ...)  # S3 method for model_fit predict_confint(object, new_data, level = 0.95, std_error = FALSE, ...)  # S3 method for model_fit predict_linear_pred(object, new_data, ...)  predict_linear_pred(object, ...)  # S3 method for model_fit predict_numeric(object, new_data, ...)  predict_numeric(object, ...)  # S3 method for model_fit predict_quantile(object, new_data, quantile = (1:9)/10, ...)  # S3 method for model_fit predict_survival(object, new_data, time, ...)  predict_survival(object, ...)  # S3 method for model_fit predict_time(object, new_data, ...)  predict_time(object, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/other_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Other predict methods. — predict_class.model_fit","text":"object object class model_fit new_data rectangular data object, data frame. ... Arguments underlying model's prediction function passed (see opts). parsnip related options can passed, depending value type. Possible arguments : level: types \"conf_int\" \"pred_int\" parameter tail area intervals (e.g. confidence level confidence intervals). Default value 0.95. std_error: add standard error fit prediction (scale linear predictors) types \"conf_int\" \"pred_int\". Default value FALSE. quantile: quantile(s) quantile regression (implemented yet) time: time(s) hazard survival probability estimates. level single numeric value zero one interval estimates. std_error single logical whether standard error returned (assuming model can compute ). quant vector numbers 0 1 quantile predicted.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/parsnip_addin.html","id":null,"dir":"Reference","previous_headings":"","what":"Start an RStudio Addin that can write model specifications — parsnip_addin","title":"Start an RStudio Addin that can write model specifications — parsnip_addin","text":"parsnip_addin() starts process RStudio IDE Viewer window allows users write code parsnip model specifications various R packages. new code written current document location cursor.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/parsnip_addin.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Start an RStudio Addin that can write model specifications — parsnip_addin","text":"","code":"parsnip_addin()"},{"path":"https://parsnip.tidymodels.org/dev/reference/parsnip_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Updating a model specification — update.bag_mars","title":"Updating a model specification — update.bag_mars","text":"parameters model specification need modified, update() can used lieu recreating object scratch.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/parsnip_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Updating a model specification — update.bag_mars","text":"","code":"# S3 method for bag_mars update(   object,   parameters = NULL,   num_terms = NULL,   prod_degree = NULL,   prune_method = NULL,   fresh = FALSE,   ... )  # S3 method for bag_tree update(   object,   parameters = NULL,   cost_complexity = NULL,   tree_depth = NULL,   min_n = NULL,   class_cost = NULL,   fresh = FALSE,   ... )  # S3 method for bart update(   object,   parameters = NULL,   trees = NULL,   prior_terminal_node_coef = NULL,   prior_terminal_node_expo = NULL,   prior_outcome_range = NULL,   fresh = FALSE,   ... )  # S3 method for boost_tree update(   object,   parameters = NULL,   mtry = NULL,   trees = NULL,   min_n = NULL,   tree_depth = NULL,   learn_rate = NULL,   loss_reduction = NULL,   sample_size = NULL,   stop_iter = NULL,   fresh = FALSE,   ... )  # S3 method for C5_rules update(   object,   parameters = NULL,   trees = NULL,   min_n = NULL,   fresh = FALSE,   ... )  # S3 method for cubist_rules update(   object,   parameters = NULL,   committees = NULL,   neighbors = NULL,   max_rules = NULL,   fresh = FALSE,   ... )  # S3 method for decision_tree update(   object,   parameters = NULL,   cost_complexity = NULL,   tree_depth = NULL,   min_n = NULL,   fresh = FALSE,   ... )  # S3 method for discrim_flexible update(   object,   num_terms = NULL,   prod_degree = NULL,   prune_method = NULL,   fresh = FALSE,   ... )  # S3 method for discrim_linear update(   object,   penalty = NULL,   regularization_method = NULL,   fresh = FALSE,   ... )  # S3 method for discrim_quad update(object, regularization_method = NULL, fresh = FALSE, ...)  # S3 method for discrim_regularized update(   object,   frac_common_cov = NULL,   frac_identity = NULL,   fresh = FALSE,   ... )  # S3 method for gen_additive_mod update(   object,   select_features = NULL,   adjust_deg_free = NULL,   parameters = NULL,   fresh = FALSE,   ... )  # S3 method for linear_reg update(   object,   parameters = NULL,   penalty = NULL,   mixture = NULL,   fresh = FALSE,   ... )  # S3 method for logistic_reg update(   object,   parameters = NULL,   penalty = NULL,   mixture = NULL,   fresh = FALSE,   ... )  # S3 method for mars update(   object,   parameters = NULL,   num_terms = NULL,   prod_degree = NULL,   prune_method = NULL,   fresh = FALSE,   ... )  # S3 method for mlp update(   object,   parameters = NULL,   hidden_units = NULL,   penalty = NULL,   dropout = NULL,   epochs = NULL,   activation = NULL,   fresh = FALSE,   ... )  # S3 method for multinom_reg update(   object,   parameters = NULL,   penalty = NULL,   mixture = NULL,   fresh = FALSE,   ... )  # S3 method for naive_Bayes update(object, smoothness = NULL, Laplace = NULL, fresh = FALSE, ...)  # S3 method for nearest_neighbor update(   object,   parameters = NULL,   neighbors = NULL,   weight_func = NULL,   dist_power = NULL,   fresh = FALSE,   ... )  # S3 method for pls update(   object,   parameters = NULL,   predictor_prop = NULL,   num_comp = NULL,   fresh = FALSE,   ... )  # S3 method for poisson_reg update(   object,   parameters = NULL,   penalty = NULL,   mixture = NULL,   fresh = FALSE,   ... )  # S3 method for proportional_hazards update(   object,   parameters = NULL,   penalty = NULL,   mixture = NULL,   fresh = FALSE,   ... )  # S3 method for rand_forest update(   object,   parameters = NULL,   mtry = NULL,   trees = NULL,   min_n = NULL,   fresh = FALSE,   ... )  # S3 method for rule_fit update(   object,   parameters = NULL,   mtry = NULL,   trees = NULL,   min_n = NULL,   tree_depth = NULL,   learn_rate = NULL,   loss_reduction = NULL,   sample_size = NULL,   penalty = NULL,   fresh = FALSE,   ... )  # S3 method for surv_reg update(object, parameters = NULL, dist = NULL, fresh = FALSE, ...)  # S3 method for survival_reg update(object, parameters = NULL, dist = NULL, fresh = FALSE, ...)  # S3 method for svm_linear update(   object,   parameters = NULL,   cost = NULL,   margin = NULL,   fresh = FALSE,   ... )  # S3 method for svm_poly update(   object,   parameters = NULL,   cost = NULL,   degree = NULL,   scale_factor = NULL,   margin = NULL,   fresh = FALSE,   ... )  # S3 method for svm_rbf update(   object,   parameters = NULL,   cost = NULL,   rbf_sigma = NULL,   margin = NULL,   fresh = FALSE,   ... )"},{"path":"https://parsnip.tidymodels.org/dev/reference/parsnip_update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Updating a model specification — update.bag_mars","text":"object model specification. parameters 1-row tibble named list main parameters update. Use either parameters main arguments directly updating. main arguments used, supersede values parameters. Also, using engine arguments object result error. num_terms number features retained final model, including intercept. prod_degree highest possible interaction degree. prune_method pruning method. fresh logical whether arguments modified -place replaced wholesale. ... used update(). cost_complexity positive number cost/complexity parameter (.k.. Cp) used CART models (specific engines ). tree_depth integer maximum depth tree. min_n integer minimum number data points node required node split . class_cost non-negative scalar class cost (cost 1 means extra cost). useful first level outcome factor minority class. case, values zero one can used bias second level factor. trees integer number trees contained ensemble. prior_terminal_node_coef coefficient prior probability node terminal node. prior_terminal_node_expo exponent prior probability node terminal node. prior_outcome_range positive value defines width prior predicted outcome within certain range. regression related observed range data; prior number standard deviations Gaussian distribution defined observed range data. classification, defined range +/-3 (assumed logit scale). default value 2. mtry number number (proportion) predictors randomly sampled split creating tree models (specific engines ) learn_rate number rate boosting algorithm adapts iteration--iteration (specific engines ). loss_reduction number reduction loss function required split (specific engines ). sample_size number number (proportion) data exposed fitting routine. xgboost, sampling done iteration C5.0 samples training. stop_iter number iterations without improvement stopping (specific engines ). committees non-negative integer (greater 100) number members ensemble. neighbors integer zero nine number training set instances used adjust model-based prediction. max_rules largest number rules. penalty non-negative number representing amount regularization used engines. regularization_method character string type regularized estimation. Possible values : \"diagonal\", \"min_distance\", \"shrink_cov\", \"shrink_mean\" (sparsediscrim engine ). frac_common_cov Numeric values zero one. frac_identity Numeric values zero one. select_features TRUE FALSE. TRUE, model ability eliminate predictor (via penalization). Increasing adjust_deg_free increase likelihood removing predictors. adjust_deg_free select_features = TRUE, acts multiplier smoothness. Increase beyond 1 produce smoother models. mixture number zero one (inclusive) proportion L1 regularization (.e. lasso) model. mixture = 1, pure lasso model mixture = 0 indicates ridge regression used (specific engines ). hidden_units integer number units hidden model. dropout number 0 (inclusive) 1 denoting proportion model parameters randomly set zero model training. epochs integer number training iterations. activation single character string denoting type relationship original predictors hidden unit layer. activation function hidden output layers automatically set either \"linear\" \"softmax\" depending type outcome. Possible values : \"linear\", \"softmax\", \"relu\", \"elu\" smoothness non-negative number representing relative smoothness class boundary. Smaller examples result model flexible boundaries larger values generate class boundaries less adaptable Laplace non-negative value Laplace correction smoothing low-frequency counts. weight_func single character type kernel function used weight distances samples. Valid choices : \"rectangular\", \"triangular\", \"epanechnikov\", \"biweight\", \"triweight\", \"cos\", \"inv\", \"gaussian\", \"rank\", \"optimal\". dist_power single number parameter used calculating Minkowski distance. predictor_prop maximum proportion original predictors can non-zero coefficients PLS component (via regularization). value used PLS components X. num_comp number PLS components retain. dist character string probability distribution outcome. default \"weibull\". cost positive number cost predicting sample within wrong side margin margin positive number epsilon SVM insensitive loss function (regression ) degree positive number polynomial degree. scale_factor positive number polynomial scaling factor. rbf_sigma positive number radial basis function.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/parsnip_update.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Updating a model specification — update.bag_mars","text":"updated model specification.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/pls.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial least squares (PLS) — pls","title":"Partial least squares (PLS) — pls","text":"pls() defines partial least squares model uses latent variables model data. similar supervised version principal component. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/pls.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Partial least squares (PLS) — pls","text":"","code":"pls(   mode = \"unknown\",   predictor_prop = NULL,   num_comp = NULL,   engine = \"mixOmics\" )"},{"path":"https://parsnip.tidymodels.org/dev/reference/pls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial least squares (PLS) — pls","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". predictor_prop maximum proportion original predictors can non-zero coefficients PLS component (via regularization). value used PLS components X. num_comp number PLS components retain. engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/pls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial least squares (PLS) — pls","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/pls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial least squares (PLS) — pls","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/poisson_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson regression models — poisson_reg","title":"Poisson regression models — poisson_reg","text":"poisson_reg() defines generalized linear model count data follow Poisson distribution. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/poisson_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson regression models — poisson_reg","text":"","code":"poisson_reg(   mode = \"regression\",   penalty = NULL,   mixture = NULL,   engine = \"glm\" )"},{"path":"https://parsnip.tidymodels.org/dev/reference/poisson_reg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson regression models — poisson_reg","text":"mode single character string type model. possible value model \"regression\". penalty non-negative number representing total amount regularization (glmnet ). mixture number zero one (inclusive) proportion L1 regularization (.e. lasso) model. mixture = 1, pure lasso model mixture = 0 indicates ridge regression used. (glmnet spark ). engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/poisson_reg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Poisson regression models — poisson_reg","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/poisson_reg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Poisson regression models — poisson_reg","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/predict.model_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Model predictions — predict.model_fit","title":"Model predictions — predict.model_fit","text":"Apply model create different types predictions. predict() can used types models uses \"type\" argument specificity.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/predict.model_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Model predictions — predict.model_fit","text":"","code":"# S3 method for model_fit predict(object, new_data, type = NULL, opts = list(), ...)  # S3 method for model_fit predict_raw(object, new_data, opts = list(), ...)  predict_raw(object, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/predict.model_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model predictions — predict.model_fit","text":"object object class model_fit new_data rectangular data object, data frame. type single character value NULL. Possible values \"numeric\", \"class\", \"prob\", \"conf_int\", \"pred_int\", \"quantile\", \"time\", \"hazard\", \"survival\", \"raw\". NULL, predict() choose appropriate value based model's mode. opts list optional arguments underlying predict function used type = \"raw\". list include options model object new data predicted. ... Arguments underlying model's prediction function passed (see opts). parsnip related options can passed, depending value type. Possible arguments : level: types \"conf_int\" \"pred_int\" parameter tail area intervals (e.g. confidence level confidence intervals). Default value 0.95. std_error: add standard error fit prediction (scale linear predictors) types \"conf_int\" \"pred_int\". Default value FALSE. quantile: quantile(s) quantile regression (implemented yet) time: time(s) hazard survival probability estimates.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/predict.model_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model predictions — predict.model_fit","text":"exception type = \"raw\", results predict.model_fit() tibble many rows output rows new_data column names predictable. numeric results single outcome, tibble .pred column .pred_Yname multivariate results. hard class predictions, column named .pred_classand, type = \"prob\", columns .pred_classlevel. type = \"conf_int\" type = \"pred_int\" return tibbles columns .pred_lower .pred_upper attribute confidence level. case intervals can produces class probabilities (non-scalar outputs), columns named .pred_lower_classlevel . Quantile predictions return tibble column .pred, list-column. list element contains tibble columns .pred .quantile (perhaps columns). Using type = \"raw\" predict.model_fit() return unadulterated results prediction function. censored regression: type = \"time\" produces column .pred_time. type = \"hazard\" results column .pred_hazard. type = \"survival\" results list column containing tibbles .pred_survival column. last two types, results nested tibble overall column called .pred sub-tibbles format. case Spark-based models, since table columns contain dots, convention used except 1) dots appear names 2) vectors never returned type-specific prediction functions. model fit failed error captured, predict() function return structure filled missing values. currently work multivariate models.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/predict.model_fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model predictions — predict.model_fit","text":"\"type\" supplied predict(), choice made: type = \"numeric\" regression models, type = \"class\" classification, type = \"time\" censored regression. predict() designed provide tidy result (see \"Value\" section ) tibble output format.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/predict.model_fit.html","id":"interval-predictions","dir":"Reference","previous_headings":"","what":"Interval predictions","title":"Model predictions — predict.model_fit","text":"using type = \"conf_int\" type = \"pred_int\", options level std_error can used. latter logical extra column standard error values (available).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/predict.model_fit.html","id":"censored-regression-predictions","dir":"Reference","previous_headings":"","what":"Censored regression predictions","title":"Model predictions — predict.model_fit","text":"censored regression, numeric vector time required survival hazard probabilities requested. Also, type = \"linear_pred\", censored regression models default formatted linear predictor increases time. may opposite sign underlying model's predict() method produces. Set increasing = FALSE suppress behavior.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/prepare_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data based on parsnip encoding information — prepare_data","title":"Prepare data based on parsnip encoding information — prepare_data","text":"Prepare data based parsnip encoding information","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/prepare_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data based on parsnip encoding information — prepare_data","text":"","code":"prepare_data(object, new_data)"},{"path":"https://parsnip.tidymodels.org/dev/reference/prepare_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data based on parsnip encoding information — prepare_data","text":"object parsnip model object new_data data frame","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/prepare_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data based on parsnip encoding information — prepare_data","text":"data frame matrix","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/proportional_hazards.html","id":null,"dir":"Reference","previous_headings":"","what":"Proportional hazards regression — proportional_hazards","title":"Proportional hazards regression — proportional_hazards","text":"proportional_hazards() defines proportional hazards model. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/proportional_hazards.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Proportional hazards regression — proportional_hazards","text":"","code":"proportional_hazards(   mode = \"censored regression\",   engine = \"survival\",   penalty = NULL,   mixture = NULL )"},{"path":"https://parsnip.tidymodels.org/dev/reference/proportional_hazards.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proportional hazards regression — proportional_hazards","text":"mode single character string prediction outcome mode. possible value model \"censored regression\". engine single character string specifying computational engine use fitting. penalty non-negative number representing total amount regularization (specific engines ). mixture number zero one (inclusive) proportion L1 regularization (.e. lasso) model. mixture = 1, pure lasso model mixture = 0 indicates ridge regression used (specific engines ).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/proportional_hazards.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Proportional hazards regression — proportional_hazards","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data. Since survival models typically involve censoring (require use survival::Surv() objects), fit.model_spec() function require survival model specified via formula interface. Proportional hazards models include Cox model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/proportional_hazards.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Proportional hazards regression — proportional_hazards","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/rand_forest.html","id":null,"dir":"Reference","previous_headings":"","what":"Random forest — rand_forest","title":"Random forest — rand_forest","text":"rand_forest() defines model creates large number decision trees, independent others. final prediction uses predictions individual trees combines . different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: ranger  (default) randomForest spark information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/rand_forest.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Random forest — rand_forest","text":"","code":"rand_forest(   mode = \"unknown\",   engine = \"ranger\",   mtry = NULL,   trees = NULL,   min_n = NULL )"},{"path":"https://parsnip.tidymodels.org/dev/reference/rand_forest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random forest — rand_forest","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". engine single character string specifying computational engine use fitting. mtry integer number predictors randomly sampled split creating tree models. trees integer number trees contained ensemble. min_n integer minimum number data points node required node split .","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/rand_forest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random forest — rand_forest","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/rand_forest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random forest — rand_forest","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics augment, fit, fit_xy, glance, required_pkgs, tidy, varying_args hardhat extract_fit_engine, extract_spec_parsnip magrittr %>%","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/repair_call.html","id":null,"dir":"Reference","previous_headings":"","what":"Repair a model call object — repair_call","title":"Repair a model call object — repair_call","text":"user passes formula fit() underlying model function uses formula, call object produced fit() may usable functions. example, arguments may still quosures data portion call correspond original data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/repair_call.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Repair a model call object — repair_call","text":"","code":"repair_call(x, data)"},{"path":"https://parsnip.tidymodels.org/dev/reference/repair_call.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repair a model call object — repair_call","text":"x fitted parsnip model. error occur underlying model call element. data data object relevant call. cases, data frame given parsnip model fit (.e., training set data). name data object inserted call.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/repair_call.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Repair a model call object — repair_call","text":"modified parsnip fitted model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/repair_call.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Repair a model call object — repair_call","text":"repair_call() call can adjust model objects call usable functions methods.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/req_pkgs.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine required packages for a model — req_pkgs","title":"Determine required packages for a model — req_pkgs","text":"Determine required packages model","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/req_pkgs.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Determine required packages for a model — req_pkgs","text":"","code":"req_pkgs(x, ...)  # S3 method for model_spec req_pkgs(x, ...)  # S3 method for model_fit req_pkgs(x, ...)  # S3 method for model_spec required_pkgs(x, ...)  # S3 method for model_fit required_pkgs(x, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/req_pkgs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine required packages for a model — req_pkgs","text":"x model specification fit. ... used.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/req_pkgs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine required packages for a model — req_pkgs","text":"character string package names ().","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/req_pkgs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Determine required packages for a model — req_pkgs","text":"model specification, engine must set. list produced req_pkgs()include parsnip package required_pkgs() .","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/rpart_train.html","id":null,"dir":"Reference","previous_headings":"","what":"Decision trees via rpart — rpart_train","title":"Decision trees via rpart — rpart_train","text":"rpart_train wrapper rpart() tree-based models model arguments main function.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/rpart_train.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Decision trees via rpart — rpart_train","text":"","code":"rpart_train(   formula,   data,   weights = NULL,   cp = 0.01,   minsplit = 20,   maxdepth = 30,   ... )"},{"path":"https://parsnip.tidymodels.org/dev/reference/rpart_train.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decision trees via rpart — rpart_train","text":"formula model formula. data data frame. weights Optional case weights. cp non-negative number complexity parameter. split decrease overall lack fit factor cp attempted. instance, anova splitting, means overall R-squared must increase cp step. main role parameter save computing time pruning splits obviously worthwhile. Essentially, user informs program split improve fit cp likely pruned cross-validation, hence program need pursue . minsplit integer minimum number observations must exist node order split attempted. maxdepth integer maximum depth node final tree, root node counted depth 0. Values greater 30 rpart give nonsense results 32-bit machines. function truncate maxdepth 30 cases. ... arguments pass either rpart rpart.control.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/rpart_train.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Decision trees via rpart — rpart_train","text":"fitted rpart model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/rule_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"RuleFit models — rule_fit","title":"RuleFit models — rule_fit","text":"rule_fit() defines model derives simple feature rules tree ensemble uses features regularized model. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/rule_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"RuleFit models — rule_fit","text":"","code":"rule_fit(   mode = \"unknown\",   mtry = NULL,   trees = NULL,   min_n = NULL,   tree_depth = NULL,   learn_rate = NULL,   loss_reduction = NULL,   sample_size = NULL,   penalty = NULL,   engine = \"xrf\" )"},{"path":"https://parsnip.tidymodels.org/dev/reference/rule_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RuleFit models — rule_fit","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". mtry number number (proportion) predictors randomly sampled split creating tree models (specific engines ) trees integer number trees contained ensemble. min_n integer minimum number data points node required node split . tree_depth integer maximum depth tree (.e. number splits) (specific engines ). learn_rate number rate boosting algorithm adapts iteration--iteration (specific engines ). loss_reduction number reduction loss function required split (specific engines ). sample_size number number (proportion) data exposed fitting routine. xgboost, sampling done iteration C5.0 samples training. penalty L1 regularization parameter. engine single character string specifying computational engine use fitting.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/rule_fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"RuleFit models — rule_fit","text":"RuleFit model creates regression model rules two stages. first stage uses tree-based model used generate set rules can filtered, modified, simplified. rules added predictors regularized generalized linear model can also conduct feature selection model training. function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/rule_fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"RuleFit models — rule_fit","text":"Friedman, J. H., Popescu, B. E. (2008). \"Predictive learning via rule ensembles.\" Annals Applied Statistics, 2(3), 916-954. https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/set_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Change elements of a model specification — set_args","title":"Change elements of a model specification — set_args","text":"set_args() can used modify arguments model specification set_mode() used change model's mode.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/set_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Change elements of a model specification — set_args","text":"","code":"set_args(object, ...)  set_mode(object, mode)"},{"path":"https://parsnip.tidymodels.org/dev/reference/set_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change elements of a model specification — set_args","text":"object model specification. ... One named model arguments. mode character string model type (e.g. \"classification\" \"regression\")","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/set_args.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change elements of a model specification — set_args","text":"updated model object.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/set_args.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Change elements of a model specification — set_args","text":"set_args() replace existing values arguments.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/set_engine.html","id":null,"dir":"Reference","previous_headings":"","what":"Declare a computational engine and specific arguments — set_engine","title":"Declare a computational engine and specific arguments — set_engine","text":"set_engine() used specify package system used fit model, along arguments specific software.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/set_engine.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Declare a computational engine and specific arguments — set_engine","text":"","code":"set_engine(object, engine, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/set_engine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Declare a computational engine and specific arguments — set_engine","text":"object model specification. engine character string software used fit model. highly dependent type model (e.g. linear regression, random forest, etc.). ... optional arguments associated chosen computational engine. captured quosures can varying().","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/set_engine.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Declare a computational engine and specific arguments — set_engine","text":"updated model specification.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/set_engine.html","id":"engines","dir":"Reference","previous_headings":"","what":"Engines","title":"Declare a computational engine and specific arguments — set_engine","text":"Based currently loaded packages, following lists set engines available model specification.  bag_mars(): engines currently available bag_tree(): engines currently available bart(): dbarts boost_tree(): C5.0, spark, xgboost C5_rules(): engines currently available cubist_rules(): engines currently available decision_tree(): C5.0, rpart, spark discrim_flexible(): engines currently available discrim_linear(): engines currently available discrim_quad(): engines currently available discrim_regularized(): engines currently available gen_additive_mod(): mgcv linear_reg(): glmnet, keras, lm, spark, stan logistic_reg(): LiblineaR, glm, glmnet, keras, spark, stan mars(): earth mlp(): keras, nnet multinom_reg(): glmnet, keras, nnet, spark naive_Bayes(): engines currently available nearest_neighbor(): kknn null_model(): parsnip pls(): engines currently available poisson_reg(): engines currently available proportional_hazards(): engines currently available rand_forest(): randomForest, ranger, spark rule_fit(): engines currently available surv_reg(): flexsurv, survival survival_reg(): engines currently available svm_linear(): LiblineaR, kernlab svm_poly(): kernlab svm_rbf(): kernlab, liquidSVM","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/set_new_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools to Register Models — check_model_exists","title":"Tools to Register Models — check_model_exists","text":"functions similar constructors can used validate conflicts underlying model structures used package.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/set_new_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Tools to Register Models — check_model_exists","text":"","code":"check_model_exists(model)  check_model_doesnt_exist(model)  set_new_model(model)  set_model_mode(model, mode)  set_model_engine(model, mode, eng)  set_model_arg(model, eng, parsnip, original, func, has_submodel)  set_dependency(model, eng, pkg = \"parsnip\")  get_dependency(model)  set_fit(model, mode, eng, value)  get_fit(model)  set_pred(model, mode, eng, type, value)  get_pred_type(model, type)  show_model_info(model)  pred_value_template(pre = NULL, post = NULL, func, ...)  set_encoding(model, mode, eng, options)  get_encoding(model)"},{"path":"https://parsnip.tidymodels.org/dev/reference/set_new_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools to Register Models — check_model_exists","text":"model single character string model type (e.g. \"rand_forest\", etc). mode single character string model mode (e.g. \"regression\"). eng single character string model engine. parsnip single character string \"harmonized\" argument name parsnip exposes. original single character string argument name underlying model function uses. func named character vector describes call function. func elements pkg fun. former optional recommended latter required. example, c(pkg = \"stats\", fun = \"lm\") used invoke usual linear regression function. cases, helpful use c(fun = \"predict\") using package's predict method. has_submodel single logical whether argument can make predictions multiple submodels . pkg options character string package name. value list conforms fit_obj pred_obj description , depending context. type single character value type prediction. Possible values : class, conf_int, numeric, pred_int, prob, quantile, raw. pre, post Optional functions pre- post-processing prediction results. ... Optional arguments passed args slot prediction objects. options list options engine-specific preprocessing encodings. See Details . arg single character string model argument name. fit_obj list elements interface, protect, func defaults. See package vignette \"Making parsnip model scratch\". pred_obj list elements pre, post, func, args.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/set_new_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tools to Register Models — check_model_exists","text":"functions available users add models engines (package otherwise) can accessed using parsnip. thoroughly documented package web site (see references ). short, parsnip stores environment object contains information code models used (e.g. fitting, predicting, etc). functions can used add models environment well helper functions can used makes sure model data right format. check_model_exists() checks model value ensures model already registered. check_model_doesnt_exist() checks model value also checks see novel environment. options engine-specific encodings dictate predictors handled. options ensure data parsnip gives underlying model allows model fit similar possible produced directly. example, fit() used fit model formula interface, typically predictor preprocessing must conducted. glmnet good example . four options can used encodings: predictor_indicators describes whether create indicator/dummy variables factor predictors. three options: \"none\" (expand factor predictors), \"traditional\" (apply standard model.matrix() encodings), \"one_hot\" (create complete set including baseline level factors). encoding affects cases fit.model_spec() used underlying model x/y interface. Another option compute_intercept; controls whether model.matrix() include intercept formula. affects inclusion intercept column. intercept, model.matrix() computes dummy variables one factor levels. Without intercept, model.matrix() computes full set indicators first factor variable, incomplete set remainder. Next, option remove_intercept remove intercept column model.matrix() finished. can useful model function (e.g. lm()) automatically generates intercept. Finally, allow_sparse_x specifies whether model function can natively accommodate sparse matrix representation predictors fitting tuning.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/set_new_model.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tools to Register Models — check_model_exists","text":"\"build parsnip model\" https://www.tidymodels.org/learn/develop/models/","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/show_call.html","id":null,"dir":"Reference","previous_headings":"","what":"Print the model call — show_call","title":"Print the model call — show_call","text":"Print model call","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/show_call.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Print the model call — show_call","text":"","code":"show_call(object)"},{"path":"https://parsnip.tidymodels.org/dev/reference/show_call.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print the model call — show_call","text":"x \"model_spec\" object.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/show_call.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print the model call — show_call","text":"character string.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/show_engines.html","id":null,"dir":"Reference","previous_headings":"","what":"Display currently available engines for a model — show_engines","title":"Display currently available engines for a model — show_engines","text":"possible engines model can depend packages loaded. parsnip-adjacent packages add engines existing models. example, multilevelmod package adds additional engines linear_reg() model available unless multilevelmod loaded.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/show_engines.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Display currently available engines for a model — show_engines","text":"","code":"show_engines(x)"},{"path":"https://parsnip.tidymodels.org/dev/reference/show_engines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display currently available engines for a model — show_engines","text":"x name parsnip model (e.g., \"linear_reg\", \"mars\", etc.)","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/show_engines.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Display currently available engines for a model — show_engines","text":"tibble.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/stan_conf_int.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper for stan confidence intervals — stan_conf_int","title":"Wrapper for stan confidence intervals — stan_conf_int","text":"Wrapper stan confidence intervals","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/stan_conf_int.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper for stan confidence intervals — stan_conf_int","text":"","code":"stan_conf_int(object, newdata)"},{"path":"https://parsnip.tidymodels.org/dev/reference/stan_conf_int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper for stan confidence intervals — stan_conf_int","text":"object stan model fit newdata data set.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/surv_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric survival regression — surv_reg","title":"Parametric survival regression — surv_reg","text":"function soft-deprecated favor survival_reg() uses \"censored regression\" mode. surv_reg() defines parametric survival model. different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: flexsurv survival  (default) information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/surv_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric survival regression — surv_reg","text":"","code":"surv_reg(mode = \"regression\", engine = \"survival\", dist = NULL)"},{"path":"https://parsnip.tidymodels.org/dev/reference/surv_reg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric survival regression — surv_reg","text":"mode single character string prediction outcome mode. possible value model \"regression\". engine single character string specifying computational engine use fitting. dist character string probability distribution outcome. default \"weibull\".","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/surv_reg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parametric survival regression — surv_reg","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data. Since survival models typically involve censoring (require use survival::Surv() objects), fit.model_spec() function require survival model specified via formula interface.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/surv_reg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parametric survival regression — surv_reg","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/survival_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric survival regression — survival_reg","title":"Parametric survival regression — survival_reg","text":"survival_reg() defines parametric survival model. different ways fit model. method estimation chosen setting model engine. engines found within currently loaded packages. information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/survival_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric survival regression — survival_reg","text":"","code":"survival_reg(mode = \"censored regression\", engine = \"survival\", dist = NULL)"},{"path":"https://parsnip.tidymodels.org/dev/reference/survival_reg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric survival regression — survival_reg","text":"mode single character string prediction outcome mode. possible value model \"censored regression\". engine single character string specifying computational engine use fitting. dist character string probability distribution outcome. default \"weibull\".","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/survival_reg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parametric survival regression — survival_reg","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data. Since survival models typically involve censoring (require use survival::Surv() objects), fit.model_spec() function require survival model specified via formula interface.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/survival_reg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parametric survival regression — survival_reg","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear support vector machines — svm_linear","title":"Linear support vector machines — svm_linear","text":"svm_linear() defines support vector machine model. classification, model tries maximize width margin classes. regression, model optimizes robust loss function affected large model residuals. SVM model uses linear function create decision boundary regression line. different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: LiblineaR  (default) kernlab information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Linear support vector machines — svm_linear","text":"","code":"svm_linear(mode = \"unknown\", engine = \"LiblineaR\", cost = NULL, margin = NULL)"},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear support vector machines — svm_linear","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". engine single character string specifying computational engine use fitting. cost positive number cost predicting sample within wrong side margin margin positive number epsilon SVM insensitive loss function (regression )","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_linear.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear support vector machines — svm_linear","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_linear.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear support vector machines — svm_linear","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_poly.html","id":null,"dir":"Reference","previous_headings":"","what":"Polynomial support vector machines — svm_poly","title":"Polynomial support vector machines — svm_poly","text":"svm_poly() defines support vector machine model. classification, model tries maximize width margin classes. regression, model optimizes robust loss function affected large model residuals. SVM model uses nonlinear function, specifically polynomial function, create decision boundary regression line. different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: kernlab  (default) information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_poly.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Polynomial support vector machines — svm_poly","text":"","code":"svm_poly(   mode = \"unknown\",   engine = \"kernlab\",   cost = NULL,   degree = NULL,   scale_factor = NULL,   margin = NULL )"},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_poly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Polynomial support vector machines — svm_poly","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". engine single character string specifying computational engine use fitting. cost positive number cost predicting sample within wrong side margin degree positive number polynomial degree. scale_factor positive number polynomial scaling factor. margin positive number epsilon SVM insensitive loss function (regression )","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_poly.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Polynomial support vector machines — svm_poly","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_poly.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Polynomial support vector machines — svm_poly","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_rbf.html","id":null,"dir":"Reference","previous_headings":"","what":"Radial basis function support vector machines — svm_rbf","title":"Radial basis function support vector machines — svm_rbf","text":"svm_rbf() defines support vector machine model. classification, model tries maximize width margin classes. regression, model optimizes robust loss function affected large model residuals. SVM model uses nonlinear function, specifically radial basis function, create decision boundary regression line. different ways fit model. method estimation chosen setting model engine. engine-specific pages model listed  contain details: kernlab  (default) information parsnip used modeling https://www.tidymodels.org/.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_rbf.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Radial basis function support vector machines — svm_rbf","text":"","code":"svm_rbf(   mode = \"unknown\",   engine = \"kernlab\",   cost = NULL,   rbf_sigma = NULL,   margin = NULL )"},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_rbf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Radial basis function support vector machines — svm_rbf","text":"mode single character string prediction outcome mode. Possible values model \"unknown\", \"regression\", \"classification\". engine single character string specifying computational engine use fitting. Possible engines listed . default model \"kernlab\". cost positive number cost predicting sample within wrong side margin rbf_sigma positive number radial basis function. margin positive number epsilon SVM insensitive loss function (regression )","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_rbf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Radial basis function support vector machines — svm_rbf","text":"function defines type model fit. engine specified, method fit model also defined. model trained fit fit.model_spec() function used data.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/svm_rbf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Radial basis function support vector machines — svm_rbf","text":"https://www.tidymodels.org, Tidy Modeling R","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy._LiblineaR.html","id":null,"dir":"Reference","previous_headings":"","what":"tidy methods for LiblineaR models — tidy._LiblineaR","title":"tidy methods for LiblineaR models — tidy._LiblineaR","text":"tidy() methods various LiblineaR models return coefficients parsnip model fit.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy._LiblineaR.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"tidy methods for LiblineaR models — tidy._LiblineaR","text":"","code":"# S3 method for `_LiblineaR` tidy(x, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy._LiblineaR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"tidy methods for LiblineaR models — tidy._LiblineaR","text":"x fitted parsnip model used LiblineaR engine. ... used","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy._LiblineaR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"tidy methods for LiblineaR models — tidy._LiblineaR","text":"tibble columns term estimate.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy._elnet.html","id":null,"dir":"Reference","previous_headings":"","what":"tidy methods for glmnet models — tidy._elnet","title":"tidy methods for glmnet models — tidy._elnet","text":"tidy() methods various glmnet models return coefficients specific penalty value used parsnip model fit.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy._elnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"tidy methods for glmnet models — tidy._elnet","text":"","code":"# S3 method for `_elnet` tidy(x, penalty = NULL, ...)  # S3 method for `_lognet` tidy(x, penalty = NULL, ...)  # S3 method for `_multnet` tidy(x, penalty = NULL, ...)  # S3 method for `_fishnet` tidy(x, penalty = NULL, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy._elnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"tidy methods for glmnet models — tidy._elnet","text":"x fitted parsnip model used glmnet engine. penalty single numeric value. none given, value specified model specification used. ... used","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy._elnet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"tidy methods for glmnet models — tidy._elnet","text":"tibble columns term, estimate, penalty. multinomial mode used, additional class column included.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy.model_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn a parsnip model object into a tidy tibble — tidy.model_fit","title":"Turn a parsnip model object into a tidy tibble — tidy.model_fit","text":"method tidies model parsnip model object, exists.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy.model_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Turn a parsnip model object into a tidy tibble — tidy.model_fit","text":"","code":"# S3 method for model_fit tidy(x, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy.model_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn a parsnip model object into a tidy tibble — tidy.model_fit","text":"x object converted tidy tibble::tibble(). ... Additional arguments tidying method.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy.model_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn a parsnip model object into a tidy tibble — tidy.model_fit","text":"tibble","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy.nullmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy method for null models — tidy.nullmodel","title":"Tidy method for null models — tidy.nullmodel","text":"Return results nullmodel tibble","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy.nullmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy method for null models — tidy.nullmodel","text":"","code":"# S3 method for nullmodel tidy(x, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy.nullmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy method for null models — tidy.nullmodel","text":"x nullmodel object. ... used.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/tidy.nullmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy method for null models — tidy.nullmodel","text":"tibble column value.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/translate.html","id":null,"dir":"Reference","previous_headings":"","what":"Resolve a Model Specification for a Computational Engine — translate","title":"Resolve a Model Specification for a Computational Engine — translate","text":"translate() translate model specification code object specific particular engine (e.g. R package). translates generic parameters counterparts.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/translate.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Resolve a Model Specification for a Computational Engine — translate","text":"","code":"translate(x, ...)  # S3 method for default translate(x, engine = x$engine, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/translate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resolve a Model Specification for a Computational Engine — translate","text":"x model specification. ... currently used. engine computational engine model (see ?set_engine).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/translate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Resolve a Model Specification for a Computational Engine — translate","text":"translate() produces template call lacks specific argument values (data, etc). filled fit() called specifics data model. call may also include varying arguments specification. contain resolved argument names specific model fitting function/engine. function can useful need understand parsnip goes generic model specific model fitting function. Note: function used internally users use understand underlying syntax . used modify model specification.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/type_sum.model_spec.html","id":null,"dir":"Reference","previous_headings":"","what":"Succinct summary of parsnip object — type_sum.model_spec","title":"Succinct summary of parsnip object — type_sum.model_spec","text":"type_sum controls objects shown inside tibble columns.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/type_sum.model_spec.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Succinct summary of parsnip object — type_sum.model_spec","text":"","code":"# S3 method for model_spec type_sum(x)  # S3 method for model_fit type_sum(x)"},{"path":"https://parsnip.tidymodels.org/dev/reference/type_sum.model_spec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Succinct summary of parsnip object — type_sum.model_spec","text":"x model_spec model_fit object summarise.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/type_sum.model_spec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Succinct summary of parsnip object — type_sum.model_spec","text":"character value.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/type_sum.model_spec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Succinct summary of parsnip object — type_sum.model_spec","text":"model_spec objects, summary \"spec[?]\" \"spec[+]\". former indicates either model mode declared specification varying() parameters. Otherwise, latter shown. fitted models, either \"fit[x]\" \"fit[+]\" used \"x\" implies model fit failed way.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/varying.html","id":null,"dir":"Reference","previous_headings":"","what":"A placeholder function for argument values — varying","title":"A placeholder function for argument values — varying","text":"varying() used parameter specified later date.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/varying.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"A placeholder function for argument values — varying","text":"","code":"varying()"},{"path":"https://parsnip.tidymodels.org/dev/reference/varying_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine varying arguments — varying_args.model_spec","title":"Determine varying arguments — varying_args.model_spec","text":"varying_args() takes model specification recipe returns tibble information possible varying arguments whether actually varying.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/varying_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Determine varying arguments — varying_args.model_spec","text":"","code":"# S3 method for model_spec varying_args(object, full = TRUE, ...)  # S3 method for recipe varying_args(object, full = TRUE, ...)  # S3 method for step varying_args(object, full = TRUE, ...)"},{"path":"https://parsnip.tidymodels.org/dev/reference/varying_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine varying arguments — varying_args.model_spec","text":"object model_spec recipe. full single logical. possible varying parameters returned? FALSE, parameters actually varying returned. ... currently used.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/varying_args.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine varying arguments — varying_args.model_spec","text":"tibble columns parameter name (name), whether contains varying value (varying), id object (id), class used call method (type).","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/varying_args.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Determine varying arguments — varying_args.model_spec","text":"id column determined differently depending whether model_spec recipe used. model_spec, first class used. recipe, unique step id used.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/xgb_train.html","id":null,"dir":"Reference","previous_headings":"","what":"Boosted trees via xgboost — xgb_train","title":"Boosted trees via xgboost — xgb_train","text":"xgb_train wrapper xgboost tree-based models model arguments main function.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/xgb_train.html","id":null,"dir":"Reference","previous_headings":"","what":"Usage","title":"Boosted trees via xgboost — xgb_train","text":"","code":"xgb_train(   x,   y,   max_depth = 6,   nrounds = 15,   eta = 0.3,   colsample_bynode = NULL,   colsample_bytree = NULL,   min_child_weight = 1,   gamma = 0,   subsample = 1,   validation = 0,   early_stop = NULL,   objective = NULL,   counts = TRUE,   event_level = c(\"first\", \"second\"),   ... )"},{"path":"https://parsnip.tidymodels.org/dev/reference/xgb_train.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Boosted trees via xgboost — xgb_train","text":"x data frame matrix predictors y vector (factor numeric) matrix (numeric) outcome data. max_depth integer maximum depth tree. nrounds integer number boosting iterations. eta numeric value zero one control learning rate. colsample_bynode Subsampling proportion columns node within tree. See counts argument . default uses columns. colsample_bytree Subsampling proportion columns tree. See counts argument . default uses columns. min_child_weight numeric value minimum sum instance weights needed child continue split. gamma number minimum loss reduction required make partition leaf node tree subsample Subsampling proportion rows. default, training data used. validation proportion data used performance assessment potential early stopping. early_stop integer NULL. NULL, number training iterations without improvement stopping. validation used, performance base validation set; otherwise, training set used. objective single string (NULL) defines loss function xgboost uses create trees. See xgboost::xgb.train() options. left NULL, appropriate loss function chosen. counts logical. FALSE, colsample_bynode colsample_bytree assumed proportions proportion columns affects (instead counts). event_level binary classification, single string either \"first\" \"second\" pass along describing level outcome considered \"event\". ... options pass xgb.train.","code":""},{"path":"https://parsnip.tidymodels.org/dev/reference/xgb_train.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Boosted trees via xgboost — xgb_train","text":"fitted xgboost object.","code":""},{"path":[]},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"model-specification-changes-development-version","dir":"Changelog","previous_headings":"","what":"Model Specification Changes","title":"parsnip (development version)","text":"Bayesian additive regression trees (BART) added via bart() function.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"bug-fixes-development-version","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"parsnip (development version)","text":"bug class predictions two-class GAM models fixed (#541) Fixed bug logistic_reg() LiblineaR engine (#552). list column produced creating survival probability predictions now always called .pred (.pred_survival used inside list column).","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-017","dir":"Changelog","previous_headings":"","what":"parsnip 0.1.7","title":"parsnip 0.1.7","text":"CRAN release: 2021-07-21","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"model-specification-changes-0-1-7","dir":"Changelog","previous_headings":"","what":"Model Specification Changes","title":"parsnip 0.1.7","text":"model function (gen_additive_mod()) added generalized additive models. model now default engine used model defined. default model listed help documents. also adds functionality declare engine model specification function. set_engine() still required engine-specific arguments need added. (#513) parsnip now checks valid combination engine mode (#529) default engine multinom_reg() changed nnet.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"other-changes-0-1-7","dir":"Changelog","previous_headings":"","what":"Other Changes","title":"parsnip 0.1.7","text":"helper functions .convert_form_to_xy_fit(), .convert_form_to_xy_new(), .convert_xy_to_form_fit(), .convert_xy_to_form_new() converting formula matrix interface now exported developer use (#508). Fix bug augment() non-predictor, non-outcome variables included data (#510). New article “Fitting Predicting parsnip” contains examples various combinations model type engine. ( #527)","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-016","dir":"Changelog","previous_headings":"","what":"parsnip 0.1.6","title":"parsnip 0.1.6","text":"CRAN release: 2021-05-27","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"model-specification-changes-0-1-6","dir":"Changelog","previous_headings":"","what":"Model Specification Changes","title":"parsnip 0.1.6","text":"new linear SVM model svm_linear() now available LiblineaR engine (#424) kernlab engine (#438), LiblineaR engine available logistic_reg() well (#429). models can use sparse matrices via fit_xy() (#447) tidy method (#474). models glmnet engines: single value required penalty (either single numeric value value tune()) (#481). special argument called path_values can used set lambda path specific set numbers (independent value penalty). pure ridge regression models (.e., mixture = 1) generate incorrect values path include zero. See issue #431 discussion (#486). liquidSVM engine svm_rbf() deprecated due package’s removal CRAN. (#425) xgboost engine boosted trees translating mtry xgboost’s colsample_bytree. now map mtry colsample_bynode since consistent random forest works. colsample_bytree can still optimized passing engine argument. colsample_bynode added xgboost parsnip package code written. (#495) xgboost, mtry colsample_bytree can passed integer counts proportions, subsample validation always proportions. xgb_train() now new option counts (TRUE FALSE) states scale mtry colsample_bytree used. (#461)","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"other-changes-0-1-6","dir":"Changelog","previous_headings":"","what":"Other Changes","title":"parsnip 0.1.6","text":"Re-licensed package GPL-2 MIT. See consent copyright holders . set_mode() now checks mode compatible model class, similar new_model_spec() (@jtlandis, #467). set_mode() set_engine() now error NULL missing arguments (#503). Re-organized model documentation: update methods moved model help files (#479). model/engine combination help page. model help page dynamic bulleted list engines links individual help pages. generics::required_pkgs() extended parsnip objects. Prediction functions now give consistent error user uses unavailable value type (#489) augment() method changed avoid failing model enable class probabilities. method now returns tibbles despite input data class (#487) (#478) xgboost engines now respect event_level option predictions (#460).","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-015","dir":"Changelog","previous_headings":"","what":"parsnip 0.1.5","title":"parsnip 0.1.5","text":"CRAN release: 2021-01-19 RStudio add-available makes writing multiple parsnip model specifications source window. can accessed via IDE addin menus calling parsnip_addin(). xgboost models, users can now pass objective set_engine(\"xgboost\"). (#403) Changes test cases CRAN get xgboost work Solaris configuration. now augument() method fitted models. See augment.model_fit. (#401) Column names x now required fit_xy() used. (#398) now event_level argument xgboost engine. (#420) New mode “censored regression” new prediction types “linear_pred”, “time”, “survival”, “hazard”. (#396) Censored regression models use fit_xy() (use fit()). (#442)","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-014","dir":"Changelog","previous_headings":"","what":"parsnip 0.1.4","title":"parsnip 0.1.4","text":"CRAN release: 2020-10-27 show_engines() provide information current set model. three models (glmnet, xgboost, ranger), enable sparse matrix use via fit_xy() (#373). added protections added function arguments dependent data dimensions (e.g., mtry, neighbors, min_n, etc). (#184) Infrastructure improved running parsnip models parallel using PSOCK clusters Windows.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-013","dir":"Changelog","previous_headings":"","what":"parsnip 0.1.3","title":"parsnip 0.1.3","text":"CRAN release: 2020-08-04 glance() method model_fit objects added (#325) Specific tidy() methods glmnet models fit via parsnip created coefficients specific fitted parsnip model returned.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"fixes-0-1-3","dir":"Changelog","previous_headings":"","what":"Fixes","title":"parsnip 0.1.3","text":"glmnet models fitting two intercepts (#349) various update() methods now work engine-specific parameters.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-012","dir":"Changelog","previous_headings":"","what":"parsnip 0.1.2","title":"parsnip 0.1.2","text":"CRAN release: 2020-07-03","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"breaking-changes-0-1-2","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"parsnip 0.1.2","text":"parsnip now options set specific types predictor encodings different models. example, ranger models run using parsnip workflows thing creating indicator variables. encodings can overridden using blueprint options workflows. consequence, possible get different model fit previous versions parsnip. details specific encoding changes . (#326)","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"other-changes-0-1-2","dir":"Changelog","previous_headings":"","what":"Other Changes","title":"parsnip 0.1.2","text":"tidyr >= 1.0.0 now required. SVM models produced kernlab now use formula method (see breaking change notice ). change due ksvm() made indicator variables factor predictors (one-hot encodings). Since ordinary formula method , data passed -ksvm() results closer one get ksmv() called directly. MARS models produced earth now use formula method. xgboost, one-hot encoding used indicator variables created. --hood changes made non-standard data arguments modeling packages can accommodated. (#315)","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"new-features-0-1-2","dir":"Changelog","previous_headings":"","what":"New Features","title":"parsnip 0.1.2","text":"new main argument added boost_tree() called stop_iter early stopping. xgb_train() function gained arguments early stopping percentage data leave validation set. fit() used underlying model uses formula, actual formula pass model (instead placeholder). makes model call better. function named repair_call() added. can help change underlying models call object better reflect obtained model function used directly (instead via parsnip). useful user chooses formula interface model uses formula interface. also limited use recipes used construct feature set workflows tune. predict() function now checks see required modeling packages installed. packages loaded (attached). (#249) (#308) (tidymodels/workflows#45) function req_pkgs() user interface determining required packages. (#308)","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-011","dir":"Changelog","previous_headings":"","what":"parsnip 0.1.1","title":"parsnip 0.1.1","text":"CRAN release: 2020-05-06","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"new-features-0-1-1","dir":"Changelog","previous_headings":"","what":"New Features","title":"parsnip 0.1.1","text":"liquidSVM added engine svm_rbf() (#300)","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"fixes-0-1-1","dir":"Changelog","previous_headings":"","what":"Fixes","title":"parsnip 0.1.1","text":"error message missing packages fixed (#289 #292)","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"other-changes-0-1-1","dir":"Changelog","previous_headings":"","what":"Other Changes","title":"parsnip 0.1.1","text":"S3 dispatch tidy() broken R 4.0.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-005","dir":"Changelog","previous_headings":"","what":"parsnip 0.0.5","title":"parsnip 0.0.5","text":"CRAN release: 2020-01-07","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"fixes-0-0-5","dir":"Changelog","previous_headings":"","what":"Fixes","title":"parsnip 0.0.5","text":"bug (#206 #234) fixed caused error predicting multinomial glmnet model.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"other-changes-0-0-5","dir":"Changelog","previous_headings":"","what":"Other Changes","title":"parsnip 0.0.5","text":"glmnet removed dependency since new version depends 3.6.0 greater. Keeping constrain parsnip requirement. glmnet tests run locally. set internal functions now exported. helpful creating new package registers new model specifications.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"new-features-0-0-5","dir":"Changelog","previous_headings":"","what":"New Features","title":"parsnip 0.0.5","text":"nnet added engine multinom_reg() #209","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"breaking-changes-0-0-5","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"parsnip 0.0.5","text":"mis-mapped parameters (going parsnip underlying model function) spark boosted trees keras models. See 897c927.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-004","dir":"Changelog","previous_headings":"","what":"parsnip 0.0.4","title":"parsnip 0.0.4","text":"CRAN release: 2019-11-02","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"new-features-0-0-4","dir":"Changelog","previous_headings":"","what":"New Features","title":"parsnip 0.0.4","text":"time elapsed model fitting stored $elapsed slot parsnip model object, printed model object printed. default parameter ranges updated SVM, KNN, MARS models. model udpate() methods gained parameters argument cases parameters contained tibble list. fit_control() soft-deprecated favor control_parsnip().","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"fixes-0-0-4","dir":"Changelog","previous_headings":"","what":"Fixes","title":"parsnip 0.0.4","text":"bug fixed standardizing output column types multi_predict predict multinom_reg. bug fixed related using data descriptors fit_xy(). bug fixed related column names generated multi_predict(). top-level tibble always column named .pred list column contains tibbles across sub-models. column names sub-model tibbles names consistent predict() (previously incorrect). See 43c15db. bug fixed standardizing column names nnet class probability predictions.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-0031","dir":"Changelog","previous_headings":"","what":"parsnip 0.0.3.1","title":"parsnip 0.0.3.1","text":"CRAN release: 2019-08-06 Test case update due CRAN running extra tests (#202)","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-003","dir":"Changelog","previous_headings":"","what":"parsnip 0.0.3","title":"parsnip 0.0.3","text":"CRAN release: 2019-07-31 Unplanned release based CRAN requirements Solaris.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"breaking-changes-0-0-3","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"parsnip 0.0.3","text":"method parsnip stores model information changed. custom models previous versions need use new method registering models. methods detailed ?get_model_env package vignette adding models. mode needs declared models can used one mode prior fitting /translation. surv_reg(), engine uses survival package now called survival instead survreg. glmnet models, full regularization path always fit regardless value given penalty. Previously, model fit passing penalty glmnet’s lambda argument model make predictions specific values. (#195)","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"new-features-0-0-3","dir":"Changelog","previous_headings":"","what":"New Features","title":"parsnip 0.0.3","text":"add_rowindex() can create column called .row data frame. computational engine explicitly set, default used. default documented corresponding model page. warning issued fit time unless verbosity zero. nearest_neighbor() gained multi_predict method. multi_predict() documentation little better organized. suite internal functions added help upcoming model tuning features. parsnip object always saved name(s) outcome variable(s) proper naming predicted values.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-002","dir":"Changelog","previous_headings":"","what":"parsnip 0.0.2","title":"parsnip 0.0.2","text":"CRAN release: 2019-03-22 Small release driven changes sample() current r-devel.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"new-features-0-0-2","dir":"Changelog","previous_headings":"","what":"New Features","title":"parsnip 0.0.2","text":"“null model” now available fits predictor-free model (using mean outcome regression mode classification). fit_xy() can take single column data frame matrix y without error","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"other-changes-0-0-2","dir":"Changelog","previous_headings":"","what":"Other Changes","title":"parsnip 0.0.2","text":"varying_args() now full argument control whether full set possible varying arguments returned (opposed arguments actually varying). fit_control() returns S3 method. classification models, error occurs outcome data encoded factors (#115). prediction modules (e.g. predict_class, predict_numeric, etc) de-exported. internal functions used users users using . event time data set (check_times) included time (seconds) run R CMD check using \"r-devel-windows-ix86+x86_64` flavor. Packages errored censored.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"bug-fixes-0-0-2","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parsnip 0.0.2","text":"varying_args() now uses version generics package. means first argument, x, renamed object align generics. recipes step method varying_args(), now error checking catch user tries specify argument varying varying (example, id) (#132). find_varying(), internal function detecting varying arguments, now returns correct results size 0 argument provided. can also now detect varying arguments nested deeply call (#131, #134). multinomial regression, .pred_ prefix now added prediction column names (#107). multinomial regression using glmnet, multi_predict() now pulls correct default penalty (#108). Confidence prediction intervals logistic regression computed intervals single level. now computed. (#156)","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-001","dir":"Changelog","previous_headings":"","what":"parsnip 0.0.1","title":"parsnip 0.0.1","text":"CRAN release: 2018-11-12 First CRAN release","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-0009005","dir":"Changelog","previous_headings":"","what":"parsnip 0.0.0.9005","title":"parsnip 0.0.0.9005","text":"engine, associated arguments, now specified using set_engine(). engine argument","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-0009004","dir":"Changelog","previous_headings":"","what":"parsnip 0.0.0.9004","title":"parsnip 0.0.0.9004","text":"Arguments modeling functions now captured quosures. others replaced ... Data descriptor names changed now functions. descriptor definitions “cols” “preds” switched.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-0009003","dir":"Changelog","previous_headings":"","what":"parsnip 0.0.0.9003","title":"parsnip 0.0.0.9003","text":"regularization changed penalty models consistent change. mode chosen model specification, assigned time fit. 51 underlying modeling packages now loaded namespace. exceptions noted documentation model. example, predict methods, earth package need attached fully operational.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-0009002","dir":"Changelog","previous_headings":"","what":"parsnip 0.0.0.9002","title":"parsnip 0.0.0.9002","text":"consistent snake_case, newdata changed new_data. predict_raw method added.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-0009001","dir":"Changelog","previous_headings":"","what":"parsnip 0.0.0.9001","title":"parsnip 0.0.0.9001","text":"package dependency suffered new change.","code":""},{"path":"https://parsnip.tidymodels.org/dev/news/index.html","id":"parsnip-0009000","dir":"Changelog","previous_headings":"","what":"parsnip 0.0.0.9000","title":"parsnip 0.0.0.9000","text":"fit interface previously used cover x/y interface well formula interface. Now, fit() formula interface fit_xy() x/y interface. Added NEWS.md file track changes package. predict methods overhauled consistent. MARS added.","code":""}]
