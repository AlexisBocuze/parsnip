<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>General Interface for Boosted Trees — boost_tree • parsnip</title>

<!-- favicons -->
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png" />
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png" />
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png" />
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png" />

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>

<!-- Bootstrap -->
<link href="../tidyverse.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>
<link href="../tidyverse-2.css" rel="stylesheet">

<!--optional theme-->
<link href="../tidymodels.css" rel="stylesheet">




<meta property="og:title" content="General Interface for Boosted Trees — boost_tree" />
<meta property="og:description" content="boost_tree() is a way to generate a specification of a model
before fitting and allows the model to be created using
different packages in R or via Spark. The main arguments for the
model are:
mtry: The number of predictors that will be
randomly sampled at each split when creating the tree models.
trees: The number of trees contained in the ensemble.
min_n: The minimum number of data points in a node
that is required for the node to be split further.
tree_depth: The maximum depth of the tree (i.e. number of
splits).
learn_rate: The rate at which the boosting algorithm adapts
from iteration-to-iteration.
loss_reduction: The reduction in the loss function required
to split further.
sample_size: The amount of data exposed to the fitting routine.
stop_iter: The number of iterations without improvement before
stopping.
These arguments are converted to their specific names at the
time that the model is fit. Other options and arguments can be
set using the set_engine() function. If left to their defaults
here (NULL), the values are taken from the underlying model
functions. If parameters need to be modified, update() can be used
in lieu of recreating the object from scratch." />
<meta property="og:image" content="https://parsnip.tidymodels.org/logo.png" />
<meta name="twitter:card" content="summary" />


<meta name="robots" content="noindex">

<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-115082821-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-115082821-1');
</script>

  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a class="navbar-brand" href="../index.html">parsnip</a>
        <div class="info hidden-xs hidden-sm">
          <span class="partof">part of <a href="https://tidymodels.org">tidymodels</a></span>
          <span class="version version-danger" data-toggle="tooltip" data-placement="bottom" title="In-development version">0.1.6.9000</span>
        </div>
      </div>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="../articles/parsnip_Intro.html">Basic Usage</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="https://www.tidymodels.org/learn/models/parsnip-ranger-glmnet/">Regression modeling</a>
    </li>
    <li>
      <a href="https://www.tidymodels.org/learn/models/parsnip-nnet/">Classification modeling</a>
    </li>
    <li>
      <a href="https://www.tidymodels.org/learn/develop/models/">Making a parsnip model from scratch</a>
    </li>
    <li>
      <a href="../articles/articles/Submodels.html">Evaluating submodels with the same model object</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
        <li>
  <a href="https://github.com/tidymodels/parsnip/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>General Interface for Boosted Trees</h1>
    <small class="dont-index">Source: <a href='https://github.com/tidymodels/parsnip/blob/master/R/boost_tree.R'><code>R/boost_tree.R</code></a></small>
    <div class="hidden name"><code>boost_tree.Rd</code></div>
    </div>

    <div class="ref-description">
    <p><code>boost_tree()</code> is a way to generate a <em>specification</em> of a model
before fitting and allows the model to be created using
different packages in R or via Spark. The main arguments for the
model are:</p><ul>
<li><p><code>mtry</code>: The number of predictors that will be
randomly sampled at each split when creating the tree models.</p></li>
<li><p><code>trees</code>: The number of trees contained in the ensemble.</p></li>
<li><p><code>min_n</code>: The minimum number of data points in a node
that is required for the node to be split further.</p></li>
<li><p><code>tree_depth</code>: The maximum depth of the tree (i.e. number of
splits).</p></li>
<li><p><code>learn_rate</code>: The rate at which the boosting algorithm adapts
from iteration-to-iteration.</p></li>
<li><p><code>loss_reduction</code>: The reduction in the loss function required
to split further.</p></li>
<li><p><code>sample_size</code>: The amount of data exposed to the fitting routine.</p></li>
<li><p><code>stop_iter</code>: The number of iterations without improvement before
stopping.</p></li>
</ul><p>These arguments are converted to their specific names at the
time that the model is fit. Other options and arguments can be
set using the <code><a href='set_engine.html'>set_engine()</a></code> function. If left to their defaults
here (<code>NULL</code>), the values are taken from the underlying model
functions. If parameters need to be modified, <code><a href='https://rdrr.io/r/stats/update.html'>update()</a></code> can be used
in lieu of recreating the object from scratch.</p>
    </div>

    <pre class="usage"><span class='fu'>boost_tree</span><span class='op'>(</span>
  mode <span class='op'>=</span> <span class='st'>"unknown"</span>,
  engine <span class='op'>=</span> <span class='st'>"xgboost"</span>,
  mtry <span class='op'>=</span> <span class='cn'>NULL</span>,
  trees <span class='op'>=</span> <span class='cn'>NULL</span>,
  min_n <span class='op'>=</span> <span class='cn'>NULL</span>,
  tree_depth <span class='op'>=</span> <span class='cn'>NULL</span>,
  learn_rate <span class='op'>=</span> <span class='cn'>NULL</span>,
  loss_reduction <span class='op'>=</span> <span class='cn'>NULL</span>,
  sample_size <span class='op'>=</span> <span class='cn'>NULL</span>,
  stop_iter <span class='op'>=</span> <span class='cn'>NULL</span>
<span class='op'>)</span></pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>mode</th>
      <td><p>A single character string for the prediction outcome mode.
Possible values for this model are "unknown", "regression", or
"classification".</p></td>
    </tr>
    <tr>
      <th>engine</th>
      <td><p>A single character string specifying what computational engine
to use for fitting. Possible engines are listed below. The default for this
model is <code>"xgboost"</code>.</p></td>
    </tr>
    <tr>
      <th>mtry</th>
      <td><p>A number for the number (or proportion) of predictors that will
be randomly sampled at each split when creating the tree models (<code>xgboost</code>
only).</p></td>
    </tr>
    <tr>
      <th>trees</th>
      <td><p>An integer for the number of trees contained in
the ensemble.</p></td>
    </tr>
    <tr>
      <th>min_n</th>
      <td><p>An integer for the minimum number of data points
in a node that is required for the node to be split further.</p></td>
    </tr>
    <tr>
      <th>tree_depth</th>
      <td><p>An integer for the maximum depth of the tree (i.e. number
of splits) (<code>xgboost</code> only).</p></td>
    </tr>
    <tr>
      <th>learn_rate</th>
      <td><p>A number for the rate at which the boosting algorithm adapts
from iteration-to-iteration (<code>xgboost</code> only).</p></td>
    </tr>
    <tr>
      <th>loss_reduction</th>
      <td><p>A number for the reduction in the loss function required
to split further (<code>xgboost</code> only).</p></td>
    </tr>
    <tr>
      <th>sample_size</th>
      <td><p>A number for the number (or proportion) of data that is
exposed to the fitting routine. For <code>xgboost</code>, the sampling is done at
each iteration while <code>C5.0</code> samples once during training.</p></td>
    </tr>
    <tr>
      <th>stop_iter</th>
      <td><p>The number of iterations without improvement before
stopping (<code>xgboost</code> only).</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>The data given to the function are not saved and are only used
to determine the <em>mode</em> of the model. For <code>boost_tree()</code>, the
possible modes are "regression" and "classification".</p>
<p>The model can be created using the <code><a href='https://generics.r-lib.org/reference/fit.html'>fit()</a></code> function using the
following <em>engines</em>:</p><ul>
<li><p><span class="pkg">R</span>: <code>"xgboost"</code> (the default), <code>"C5.0"</code></p></li>
<li><p><span class="pkg">Spark</span>: <code>"spark"</code></p></li>
</ul>

<p>For this model, other packages may add additional engines. Use
<code><a href='show_engines.html'>show_engines()</a></code> to see the current set of engines.</p>
    <h2 class="hasAnchor" id="note"><a class="anchor" href="#note"></a>Note</h2>

    <p>For models created using the spark engine, there are
several differences to consider. First, only the formula
interface to via <code><a href='https://generics.r-lib.org/reference/fit.html'>fit()</a></code> is available; using <code><a href='https://generics.r-lib.org/reference/fit_xy.html'>fit_xy()</a></code> will
generate an error. Second, the predictions will always be in a
spark table format. The names will be the same as documented but
without the dots. Third, there is no equivalent to factor
columns in spark tables so class predictions are returned as
character columns. Fourth, to retain the model object for a new
R session (via <code><a href='https://rdrr.io/r/base/save.html'>save()</a></code>), the <code>model$fit</code> element of the <code>parsnip</code>
object should be serialized via <code>ml_save(object$fit)</code> and
separately saved to disk. In a new session, the object can be
reloaded and reattached to the <code>parsnip</code> object.</p>
    <h2 class="hasAnchor" id="engine-details"><a class="anchor" href="#engine-details"></a>Engine Details</h2>

    <p>Engines may have pre-set default arguments when executing the model fit
call. For this type of model, the template of the fit calls are below:</p><h3 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>xgboost</h3>
<p><div class="r"></p><pre><span class='fu'>boost_tree</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='set_engine.html'>set_engine</a></span><span class='op'>(</span><span class='st'>"xgboost"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='set_args.html'>set_mode</a></span><span class='op'>(</span><span class='st'>"regression"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='translate.html'>translate</a></span><span class='op'>(</span><span class='op'>)</span>
</pre><p></div></p><pre><span class='co'>## Boosted Tree Model Specification (regression)</span>
<span class='co'>## </span>
<span class='co'>## Computational engine: xgboost </span>
<span class='co'>## </span>
<span class='co'>## Model fit template:</span>
<span class='co'>## parsnip::xgb_train(x = missing_arg(), y = missing_arg(), nthread = 1, </span>
<span class='co'>##     verbose = 0)</span>
</pre><p><div class="r"></p><pre><span class='fu'>boost_tree</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='set_engine.html'>set_engine</a></span><span class='op'>(</span><span class='st'>"xgboost"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='set_args.html'>set_mode</a></span><span class='op'>(</span><span class='st'>"classification"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='translate.html'>translate</a></span><span class='op'>(</span><span class='op'>)</span>
</pre><p></div></p><pre><span class='co'>## Boosted Tree Model Specification (classification)</span>
<span class='co'>## </span>
<span class='co'>## Computational engine: xgboost </span>
<span class='co'>## </span>
<span class='co'>## Model fit template:</span>
<span class='co'>## parsnip::xgb_train(x = missing_arg(), y = missing_arg(), nthread = 1, </span>
<span class='co'>##     verbose = 0)</span>
</pre>

<p>Note that, for most engines to <code>boost_tree()</code>, the <code>sample_size</code>
argument is in terms of the <em>number</em> of training set points. The
<code>xgboost</code> package parameterizes this as the <em>proportion</em> of training set
samples instead. When using the <code>tune</code>, this <strong>occurs automatically</strong>.</p>
<p>If you would like to use a custom range when tuning <code>sample_size</code>, the
<code><a href='https://dials.tidymodels.org/reference/trees.html'>dials::sample_prop()</a></code> function can be used in that case. For example,
using a parameter set:<div class="r"></p><pre><span class='va'>mod</span> <span class='op'>&lt;-</span> 
  <span class='fu'>boost_tree</span><span class='op'>(</span>sample_size <span class='op'>=</span> <span class='fu'>tune</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='set_engine.html'>set_engine</a></span><span class='op'>(</span><span class='st'>"xgboost"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='set_args.html'>set_mode</a></span><span class='op'>(</span><span class='st'>"classification"</span><span class='op'>)</span>

<span class='co'># update the parameters using the `dials` function</span>
<span class='va'>mod_param</span> <span class='op'>&lt;-</span> 
  <span class='va'>mod</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>parameters</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='https://rdrr.io/r/stats/update.html'>update</a></span><span class='op'>(</span>sample_size <span class='op'>=</span> <span class='fu'>sample_prop</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0.4</span>, <span class='fl'>0.9</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
</pre><p></div></p>
<p>For this engine, tuning over <code>trees</code> is very efficient since the same
model object can be used to make predictions over multiple values of
<code>trees</code>.</p>
<p>Note that <code>xgboost</code> models require that non-numeric predictors (e.g.,
factors) must be converted to dummy variables or some other numeric
representation. By default, when using <code><a href='https://generics.r-lib.org/reference/fit.html'>fit()</a></code> with <code>xgboost</code>, a one-hot
encoding is used to convert factor predictors to indicator variables.</p>
<p>Finally, in the classification mode, non-numeric outcomes (i.e.,
factors) are converted to numeric. For binary classification, the
<code>event_level</code> argument of <code><a href='set_engine.html'>set_engine()</a></code> can be set to either <code>"first"</code>
or <code>"second"</code> to specify which level should be used as the event. This
can be helpful when a watchlist is used to monitor performance from with
the xgboost training process.</p>

<h3 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>C5.0</h3>
<p><div class="r"></p><pre><span class='fu'>boost_tree</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='set_engine.html'>set_engine</a></span><span class='op'>(</span><span class='st'>"C5.0"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='set_args.html'>set_mode</a></span><span class='op'>(</span><span class='st'>"classification"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='translate.html'>translate</a></span><span class='op'>(</span><span class='op'>)</span>
</pre><p></div></p><pre><span class='co'>## Boosted Tree Model Specification (classification)</span>
<span class='co'>## </span>
<span class='co'>## Computational engine: C5.0 </span>
<span class='co'>## </span>
<span class='co'>## Model fit template:</span>
<span class='co'>## parsnip::C5.0_train(x = missing_arg(), y = missing_arg(), weights = missing_arg())</span>
</pre>

<p>Note that <code><a href='https://topepo.github.io/C5.0/reference/C5.0.html'>C50::C5.0()</a></code> does not require factor
predictors to be converted to indicator variables. <code><a href='https://generics.r-lib.org/reference/fit.html'>fit()</a></code> does not
affect the encoding of the predictor values (i.e. factors stay factors)
for this model.</p>
<p>For this engine, tuning over <code>trees</code> is very efficient since the same
model object can be used to make predictions over multiple values of
<code>trees</code>.</p>

<h3 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>spark</h3>
<p><div class="r"></p><pre><span class='fu'>boost_tree</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='set_engine.html'>set_engine</a></span><span class='op'>(</span><span class='st'>"spark"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='set_args.html'>set_mode</a></span><span class='op'>(</span><span class='st'>"regression"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='translate.html'>translate</a></span><span class='op'>(</span><span class='op'>)</span>
</pre><p></div></p><pre><span class='co'>## Boosted Tree Model Specification (regression)</span>
<span class='co'>## </span>
<span class='co'>## Computational engine: spark </span>
<span class='co'>## </span>
<span class='co'>## Model fit template:</span>
<span class='co'>## sparklyr::ml_gradient_boosted_trees(x = missing_arg(), formula = missing_arg(), </span>
<span class='co'>##     type = "regression", seed = sample.int(10^5, 1))</span>
</pre><p><div class="r"></p><pre><span class='fu'>boost_tree</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='set_engine.html'>set_engine</a></span><span class='op'>(</span><span class='st'>"spark"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='set_args.html'>set_mode</a></span><span class='op'>(</span><span class='st'>"classification"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'><a href='translate.html'>translate</a></span><span class='op'>(</span><span class='op'>)</span>
</pre><p></div></p><pre><span class='co'>## Boosted Tree Model Specification (classification)</span>
<span class='co'>## </span>
<span class='co'>## Computational engine: spark </span>
<span class='co'>## </span>
<span class='co'>## Model fit template:</span>
<span class='co'>## sparklyr::ml_gradient_boosted_trees(x = missing_arg(), formula = missing_arg(), </span>
<span class='co'>##     type = "classification", seed = sample.int(10^5, 1))</span>
</pre>

<p><code><a href='https://generics.r-lib.org/reference/fit.html'>fit()</a></code> does not affect the encoding of the predictor values
(i.e. factors stay factors) for this model.</p>

<h3 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Parameter translations</h3>


<p>The standardized parameter names in parsnip can be mapped to their
original names in each engine that has main parameters. Each engine
typically has a different default value (shown in parentheses) for each
parameter.</p><table class='table'>
<tr><td><strong>parsnip</strong></td><td><strong>xgboost</strong></td><td><strong>C5.0</strong></td><td><strong>spark</strong></td></tr>
<tr><td>tree_depth</td><td>max_depth (6)</td><td>NA</td><td>max_depth (5)</td></tr>
<tr><td>trees</td><td>nrounds (15)</td><td>trials (15)</td><td>max_iter (20)</td></tr>
<tr><td>learn_rate</td><td>eta (0.3)</td><td>NA</td><td>step_size (0.1)</td></tr>
<tr><td>mtry</td><td>colsample_bynode (character(0))</td><td>NA</td><td>feature_subset_strategy (see below)</td></tr>
<tr><td>min_n</td><td>min_child_weight (1)</td><td>minCases (2)</td><td>min_instances_per_node (1)</td></tr>
<tr><td>loss_reduction</td><td>gamma (0)</td><td>NA</td><td>min_info_gain (0)</td></tr>
<tr><td>sample_size</td><td>subsample (1)</td><td>sample (0)</td><td>subsampling_rate (1)</td></tr>
<tr><td>stop_iter</td><td>early_stop (NULL)</td><td>NA</td><td>NA</td></tr>
</table>



<p>For spark, the default <code>mtry</code> is the square root of the number of
predictors for classification, and one-third of the predictors for
regression.</p>

    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p><code><a href='https://generics.r-lib.org/reference/fit.html'>fit()</a></code>, <code><a href='set_engine.html'>set_engine()</a></code>, <code><a href='https://rdrr.io/r/stats/update.html'>update()</a></code></p></div>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='fu'><a href='show_engines.html'>show_engines</a></span><span class='op'>(</span><span class='st'>"boost_tree"</span><span class='op'>)</span>
</div><div class='output co'>#&gt; <span style='color: #949494;'># A tibble: 5 x 2</span>
#&gt;   engine  mode          
#&gt;   <span style='color: #949494; font-style: italic;'>&lt;chr&gt;</span>   <span style='color: #949494; font-style: italic;'>&lt;chr&gt;</span>         
#&gt; <span style='color: #BCBCBC;'>1</span> xgboost classification
#&gt; <span style='color: #BCBCBC;'>2</span> xgboost regression    
#&gt; <span style='color: #BCBCBC;'>3</span> C5.0    classification
#&gt; <span style='color: #BCBCBC;'>4</span> spark   classification
#&gt; <span style='color: #BCBCBC;'>5</span> spark   regression    </div><div class='input'>
<span class='fu'>boost_tree</span><span class='op'>(</span>mode <span class='op'>=</span> <span class='st'>"classification"</span>, trees <span class='op'>=</span> <span class='fl'>20</span><span class='op'>)</span>
</div><div class='output co'>#&gt; Boosted Tree Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   trees = 20
#&gt; 
#&gt; Computational engine: xgboost 
#&gt; </div><div class='input'><span class='co'># Parameters can be represented by a placeholder:</span>
<span class='fu'>boost_tree</span><span class='op'>(</span>mode <span class='op'>=</span> <span class='st'>"regression"</span>, mtry <span class='op'>=</span> <span class='fu'><a href='varying.html'>varying</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt; Boosted Tree Model Specification (regression)
#&gt; 
#&gt; Main Arguments:
#&gt;   mtry = varying()
#&gt; 
#&gt; Computational engine: xgboost 
#&gt; </div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="tidyverse">
  <p>parsnip is a part of the <strong>tidymodels</strong> ecosystem, a collection of modeling packages designed with common APIs and a shared philosophy.</p>
</div>

<div class="author">
  <p>
    Developed by Max Kuhn, Davis Vaughan.
    Site built by <a href="https://pkgdown.r-lib.org">pkgdown</a>.
  </p>
</div>

      </footer>
   </div>

  


  </body>
</html>


