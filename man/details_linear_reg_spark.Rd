% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/linear_reg_doc_spark.R
\name{details_linear_reg_spark}
\alias{details_linear_reg_spark}
\title{Linear regression via spark}
\description{
\code{\link[sparklyr:ml_linear_regression]{sparklyr::ml_linear_regression()}} uses regularized least squares to fit
models with numeric outcomes.
}
\details{
For this engine, there is a single mode: regression
\subsection{Tuning Parameters}{

This model has 2 tuning parameters:
\itemize{
\item \code{penalty}: Amount of Regularization (type: double, default: 0.0)
\item \code{mixture}: Proportion of Lasso Penalty (type: double, default: 0.0)
}

For \code{penalty}, the amount of regularization includes both the L1 penalty
(i.e., lasso) and the L2 penalty (i.e., ridge or weight decay).

A value of \code{mixture = 1} corresponds to a pure lasso model, while
\code{mixture = 0} indicates ridge regression.
}

\subsection{Translation from parsnip to the original package}{\if{html}{\out{<div class="r">}}\preformatted{linear_reg(penalty = double(1), mixture = double(1)) \%>\% 
  set_engine("spark") \%>\% 
  set_mode("regression") \%>\% 
  translate()
}\if{html}{\out{</div>}}\preformatted{## Linear Regression Model Specification (regression)
## 
## Main Arguments:
##   penalty = double(1)
##   mixture = double(1)
## 
## Computational engine: spark 
## 
## Model fit template:
## sparklyr::ml_linear_regression(x = missing_arg(), formula = missing_arg(), 
##     weight_col = missing_arg(), reg_param = double(1), elastic_net_param = double(1))
}
}

\subsection{Preprocessing requirements}{

Factor/categorical predictors need to be converted to numeric values
(e.g., dummy or indicator variables) for this engine. When using the
formula method via
\code{\link[=fit.model_spec]{fit.model_spec()}}, \code{parsnip} will
convert factor columns to indicators if required.

Predictors should have the same scale. One way to achieve this is to
center and scale each so that each predictor has mean zero and a
variance of one. By default, \code{ml_linear_regression()} uses the argument
\code{standardization = TRUE} to center and scale the data.
}

\subsection{Other details}{

For models created using the spark engine, there are several differences
to consider. First, only the formula interface to via \code{fit()} is
available; using \code{fit_xy()} will generate an error. Second, the
predictions will always be in a spark table format. The names will be
the same as documented but without the dots. Third, there is no
equivalent to factor columns in spark tables so class predictions are
returned as character columns. Fourth, to retain the model object for a
new R session (via \code{save()}), the \code{model$fit} element of the \code{parsnip}
object should be serialized via \code{ml_save(object$fit)} and separately
saved to disk. In a new session, the object can be reloaded and
reattached to the \code{parsnip} object.
}

\subsection{References}{
\itemize{
\item Luraschi, J, K Kuo, and E Ruiz. 2019. \emph{Mastering Spark with R}.
Oâ€™Reilly Media
\item Hastie, T, R Tibshirani, and M Wainwright. 2015. \emph{Statistical
Learning with Sparsity}. CRC Press.
\item Kuhn, M, and K Johnson. 2013. \emph{Applied Predictive Modeling}.
Springer.
}
}
}
\keyword{internal}
