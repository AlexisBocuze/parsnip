% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/svm_linear_LiblineaR.R
\name{details_svm_linear_LiblineaR}
\alias{details_svm_linear_LiblineaR}
\title{Linear support vector machines (SVMs) via LiblineaR}
\description{
\code{\link[LiblineaR:LiblineaR]{LiblineaR::LiblineaR()}} fits a support vector machine model. For classification,
the model tries to maximize the width of the margin between classes.
For regression, the model optimizes a robust loss function that is only
affected by very large model residuals.
}
\details{
For this engine, there are multiple modes: classification and regression
\subsection{Tuning Parameters}{

This model has 2 tuning parameters:
\itemize{
\item \code{cost}: Cost (type: double, default: 1.0)
\item \code{margin}: Insensitivity Margin (type: double, default: no default)
}

This engine fits models that are L2-regularized for L2-loss. In the
\code{\link[LiblineaR:LiblineaR]{LiblineaR::LiblineaR()}} documentation, these
are types 1 (classification) and 11 (regression).
}

\subsection{Translation from parsnip to the original package (regression)}{\if{html}{\out{<div class="r">}}\preformatted{svm_linear(
  cost = double(1),
  margin = double(1)
) \%>\%  
  set_engine("LiblineaR") \%>\% 
  set_mode("regression") \%>\% 
  translate()
}\if{html}{\out{</div>}}\preformatted{## Linear Support Vector Machine Specification (regression)
## 
## Main Arguments:
##   cost = double(1)
##   margin = double(1)
## 
## Computational engine: LiblineaR 
## 
## Model fit template:
## LiblineaR::LiblineaR(x = missing_arg(), y = missing_arg(), wi = missing_arg(), 
##     C = double(1), svr_eps = double(1), type = 11)
}
}

\subsection{Translation from parsnip to the original package (classification)}{\if{html}{\out{<div class="r">}}\preformatted{svm_linear(
  cost = double(1)
) \%>\% 
  set_engine("LiblineaR") \%>\% 
  set_mode("classification") \%>\% 
  translate()
}\if{html}{\out{</div>}}\preformatted{## Linear Support Vector Machine Specification (classification)
## 
## Main Arguments:
##   cost = double(1)
## 
## Computational engine: LiblineaR 
## 
## Model fit template:
## LiblineaR::LiblineaR(x = missing_arg(), y = missing_arg(), wi = missing_arg(), 
##     C = double(1), type = 1)
}

The \code{margin} parameter does not apply to classification models.

Note that the \code{LiblineaR} engine does not produce class probabilities.
When optimizing the model using the tune package, the default metrics
require class probabilities. To use the \verb{tune_*()} functions, a metric
set must be passed as an argument that only contains metrics for hard
class predictions (e.g., accuracy).
}

\subsection{Preprocessing requirements}{

Factor/categorical predictors need to be converted to numeric values
(e.g., dummy or indicator variables) for this engine. When using the
formula method via
\code{\link[=fit.model_spec]{fit.model_spec()}}, parsnip will
convert factor columns to indicators.

Predictors should have the same scale. One way to achieve this is to
center and scale each so that each predictor has mean zero and a
variance of one.
}

\subsection{Working examples}{
\subsection{Regression Example}{

Weâ€™ll model the ridership on the Chicago elevated trains as a function
of the 14 day lagged ridership at two stations. The two predictors are
in the same units (rides per day/1000) and do not need to be normalized.

All but the last week of data are used for training. The last week will
be predicted after the model is fit.\if{html}{\out{<div class="r">}}\preformatted{library(tidymodels)
tidymodels_prefer()
data(Chicago)

n <- nrow(Chicago)
Chicago <- Chicago \%>\% select(ridership, Clark_Lake, Quincy_Wells)

Chicago_train <- Chicago[1:(n - 7), ]
Chicago_test <- Chicago[(n - 6):n, ]
}\if{html}{\out{</div>}}

We can define the model with specific parameters:\if{html}{\out{<div class="r">}}\preformatted{svm_reg_spec <- 
  svm_linear(cost = 1, margin = 0.1) \%>\% 
  # This model can be used for classification or regression, so set mode
  set_mode("regression") \%>\% 
  set_engine("LiblineaR")
svm_reg_spec
}\if{html}{\out{</div>}}\preformatted{## Linear Support Vector Machine Specification (regression)
## 
## Main Arguments:
##   cost = 1
##   margin = 0.1
## 
## Computational engine: LiblineaR
}

Now we create the model fit object:\if{html}{\out{<div class="r">}}\preformatted{set.seed(1)
svm_reg_fit <- svm_reg_spec \%>\% fit(ridership ~ ., data = Chicago_train)
svm_reg_fit
}\if{html}{\out{</div>}}\preformatted{## parsnip model object
## 
## Fit time:  0ms 
## $TypeDetail
## [1] "L2-regularized L2-loss support vector regression primal (L2R_L2LOSS_SVR)"
## 
## $Type
## [1] 11
## 
## $W
##      Clark_Lake Quincy_Wells       Bias
## [1,]  0.8277352    0.3430336 0.05042585
## 
## $Bias
## [1] 1
## 
## $NbClass
## [1] 2
## 
## attr(,"class")
## [1] "LiblineaR"
}

The holdout data can be predicted:\if{html}{\out{<div class="r">}}\preformatted{predict(svm_reg_fit, Chicago_test)
}\if{html}{\out{</div>}}\preformatted{## # A tibble: 7 x 1
##   .pred
##   <dbl>
## 1 20.6 
## 2 20.8 
## 3 21.1 
## 4 20.8 
## 5 18.9 
## 6  6.40
## 7  5.90
}
}

\subsection{Classification Example}{

The example data has two predictors and an outcome with two classes.
Both predictors are in the same units\if{html}{\out{<div class="r">}}\preformatted{library(tidymodels)
tidymodels_prefer()
data(two_class_dat)

data_train <- two_class_dat[-(1:10), ]
data_test  <- two_class_dat[  1:10 , ]
}\if{html}{\out{</div>}}

We can define the model with specific parameters:\if{html}{\out{<div class="r">}}\preformatted{svm_cls_spec <- 
  svm_linear(cost = 1) \%>\% 
  # This model can be used for classification or regression, so set mode
  set_mode("classification") \%>\% 
  set_engine("LiblineaR")
svm_cls_spec
}\if{html}{\out{</div>}}\preformatted{## Linear Support Vector Machine Specification (classification)
## 
## Main Arguments:
##   cost = 1
## 
## Computational engine: LiblineaR
}

Now we create the model fit object:\if{html}{\out{<div class="r">}}\preformatted{set.seed(1)
svm_cls_fit <- svm_cls_spec \%>\% fit(Class ~ ., data = data_train)
svm_cls_fit
}\if{html}{\out{</div>}}\preformatted{## parsnip model object
## 
## Fit time:  236ms 
## $TypeDetail
## [1] "L2-regularized L2-loss support vector classification dual (L2R_L2LOSS_SVC_DUAL)"
## 
## $Type
## [1] 1
## 
## $W
##              A         B     Bias
## [1,] 0.4067922 -1.314783 1.321851
## 
## $Bias
## [1] 1
## 
## $ClassNames
## [1] Class1 Class2
## Levels: Class1 Class2
## 
## $NbClass
## [1] 2
## 
## attr(,"class")
## [1] "LiblineaR"
}

The holdout data can be predicted for hard class predictions.\if{html}{\out{<div class="r">}}\preformatted{predict(svm_cls_fit, data_test)
}\if{html}{\out{</div>}}\preformatted{## # A tibble: 10 x 1
##    .pred_class
##    <fct>      
##  1 Class1     
##  2 Class1     
##  3 Class1     
##  4 Class1     
##  5 Class2     
##  6 Class2     
##  7 Class1     
##  8 Class1     
##  9 Class1     
## 10 Class2
}
}

}

\subsection{References}{
\itemize{
\item Kuhn, M, and K Johnson. 2013. \emph{Applied Predictive Modeling}.
Springer.
}
}
}
\keyword{internal}
