% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/glmnet_details.R
\name{glmnet-details}
\alias{glmnet-details}
\title{Technical aspects of the glmnet model}
\description{
\code{glmnet} is a package for penalized regression models that encompasses
linear, logistic, Poisson, and multinomial regression models (as well as the
Cox proportional hazards model for censored data). It is a very popular model
and there are some nuances related to how it works that are important to
discuss. This discussion will focus on linear regression but the points
generalize to the other model types.
}
\section{About the glmnet model}{
First, \code{glmnet} fits two types of penalties: the lasso (or L1) penalty
and the ridge penalty (a.k.a L2 penalty a.k.a. weight decay). The
\code{glmnet} argument \code{alpha} describes the proportion of the lasso penalty
in the overall penalty.

When \code{glmnet} fits the model, the intercept coefficient is not
penalized.

When the \code{glmnet} model is trained, it estimates a continuum of possible
penalty values. This gives a \emph{coefficient path} for each data set and a
given value of \code{alpha}. The user doesn’t need to declare the exact value
of the penalty that should be used until sample prediction (i.e., it is
not needed when the model is trained). If you specify a single value of
\code{lambda} when calling \code{\link[glmnet:glmnet]{glmnet::glmnet()}}, the
estimated coefficient path only has that value.
}

\section{Using glmnet with parsnip}{
In tidymodels, we want:
\enumerate{
\item The user to declare exactly what penalty value to use.
\item The ability to make predictions at multiple penalty values with a
single model object.
}

Point 1 is relevant for a single \code{parsnip} model while Point 2 is more
related to using the \code{tune} package. The second point greatly increases
the computation efficiency of model tuning since you only need to fit a
\code{glmnet} model for each value of alpha (see the \href{https://www.tmwr.org/grid-search.html#submodel-trick}{tidymodels book} for a
discussion).

To achieve both of these goals, \code{parsnip} does the following:
\itemize{
\item The model specification (e.g. \code{linear_reg()}) saves the value of the
penalty that the user specifies.
\item \code{parsnip} fits the \code{glmnet} model without passing the penalty value
to the \code{lambda} argument. This makes the whole coefficient path
available for prediction.
\item When \code{predict()} is used on the \code{parsnip} model fit, the saved value
of the penalty is used.
\item To make predictions at other values along the path, use the
\code{multi_predict()} function. Multiple predictions can be made
simultaneously at different penalty values.
}

For example, let’s fit a small model to the Chicago train ridership data
with a 50/50 combination of L1 and L2 penalties. The model specification
will use a total penalty of 0.01.\if{html}{\out{<div class="r">}}\preformatted{library(tidymodels)
data(Chicago, package = "modeldata")

glmnet_spec <- 
  linear_reg(penalty = 0.01, mixture = 1/2) \%>\% 
  set_engine("glmnet")
}\if{html}{\out{</div>}}

To see the function call:\if{html}{\out{<div class="r">}}\preformatted{translate(glmnet_spec)
}\if{html}{\out{</div>}}\preformatted{## Linear Regression Model Specification (regression)
## 
## Main Arguments:
##   penalty = 0.01
##   mixture = 1/2
## 
## Computational engine: glmnet 
## 
## Model fit template:
## glmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), 
##     alpha = 1/2, family = "gaussian")
}

Note that the \code{lambda} argument is not used.

After training, multiple \code{lambda} penalty values are contained in the
model object:\if{html}{\out{<div class="r">}}\preformatted{glmnet_fit <- 
  glmnet_spec \%>\% 
  fit(ridership ~ Austin + Quincy_Wells + Belmont, data = Chicago)

length(glmnet_fit$fit$lambda)
}\if{html}{\out{</div>}}\preformatted{## [1] 60
}\if{html}{\out{<div class="r">}}\preformatted{summary(glmnet_fit$fit$lambda)
}\if{html}{\out{</div>}}\preformatted{##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.0468  0.1848  0.7289  2.1171  2.8742 11.3272
}

When predictions are created with this object, the original value
requested by the user is used (i.e. 0.01):\if{html}{\out{<div class="r">}}\preformatted{predict(glmnet_fit, head(Chicago))
}\if{html}{\out{</div>}}\preformatted{## # A tibble: 6 x 1
##   .pred
##   <dbl>
## 1 16.6 
## 2 16.8 
## 3 16.8 
## 4 16.3 
## 5 16.0 
## 6  4.71
}

That value is contained in\if{html}{\out{<div class="r">}}\preformatted{glmnet_fit$spec$args$penalty
}\if{html}{\out{</div>}}\preformatted{## [1] 0.01
}

If tune is being used to find optimal values of the penalty, it uses the
\code{parsnip::multi_predict()} function to get predictions over multiple
penalty values:\if{html}{\out{<div class="r">}}\preformatted{multi_predict(glmnet_fit, head(Chicago), penalty = c(0, 0.1)) \%>\% 
  mutate(row = row_number()) \%>\% 
  unnest(cols = c(.pred))
}\if{html}{\out{</div>}}\preformatted{## # A tibble: 12 x 3
##    penalty .pred   row
##      <dbl> <dbl> <int>
##  1     0   16.6      1
##  2     0.1 16.5      1
##  3     0   16.8      2
##  4     0.1 16.8      2
##  5     0   16.8      3
##  6     0.1 16.8      3
##  7     0   16.3      4
##  8     0.1 16.3      4
##  9     0   16.0      5
## 10     0.1 16.0      5
## 11     0    4.71     6
## 12     0.1  4.77     6
}

You can modify the penalties contained in the path by using the
\code{\link[glmnet:glmnet]{glmnet::glmnet()}} arguments \code{nlambda} and
\code{lambda.min.ratio}. The latter is discussed more below. These arguments
would be passed when \code{set_engine()} is called.

Note that the value supplied by the user in the model specification
(\verb{penalty = 0.1)} may not be on the coefficient path. In that case,
\code{glmnet} interpolates coefficients values between the two values on the
path that bracket the value. Use the \code{tidy()} method in the \code{parsnip}
package to get those values:\if{html}{\out{<div class="r">}}\preformatted{tidy(glmnet_fit)
}\if{html}{\out{</div>}}\preformatted{## # A tibble: 4 x 3
##   term         estimate penalty
##   <chr>           <dbl>   <dbl>
## 1 (Intercept)    -0.318    0.01
## 2 Austin          3.46     0.01
## 3 Quincy_Wells    0.997    0.01
## 4 Belmont         0.756    0.01
}

Note that there is a \code{tidy()} method for \code{glmnet} objects in the \code{broom}
package. If this is used directly on the underlying \code{glmnet} object, it
returns all of coefficients on the path:\if{html}{\out{<div class="r">}}\preformatted{broom:::tidy.glmnet(glmnet_fit$fit)
}\if{html}{\out{</div>}}\preformatted{## # A tibble: 237 x 5
##    term         step estimate lambda dev.ratio
##    <chr>       <dbl>    <dbl>  <dbl>     <dbl>
##  1 (Intercept)     1    13.6   11.3     0     
##  2 (Intercept)     2    12.7   10.3     0.0961
##  3 (Intercept)     3    11.7    9.40    0.188 
##  4 (Intercept)     4    10.7    8.57    0.268 
##  5 (Intercept)     5     9.84   7.81    0.338 
##  6 (Intercept)     6     9.00   7.11    0.400 
##  7 (Intercept)     7     8.21   6.48    0.453 
##  8 (Intercept)     8     7.47   5.91    0.499 
##  9 (Intercept)     9     6.79   5.38    0.538 
## 10 (Intercept)    10     6.15   4.90    0.572 
## # … with 227 more rows
}
}

\section{Fitting a pure ridge regression model}{
One oddity is related to models with \code{alpha = 0} (i.e., a pure L2
penalty). As shown in issue
\href{https://github.com/tidymodels/parsnip/issues/431}{#431}, the parameter
values obtained may not be close to the true values when the other
arguments contain their default values.

However, we have noticed that using the argument value
\code{lambda.min.ratio = 0} in these fits might help achieve the correct
results. However, consult the \code{\link[glmnet:glmnet]{glmnet::glmnet()}}
function documentation to read about the potential effects of using this
value.

Here’s an example of how the coefficient path is changed by this option:\if{html}{\out{<div class="r">}}\preformatted{default_value <- 
  linear_reg(penalty = 0.01, mixture = 0) \%>\% 
  set_engine("glmnet") \%>\% 
  fit(ridership ~ Austin + Quincy_Wells + Belmont, data = Chicago)

zero_value <- 
  linear_reg(penalty = 0.01, mixture = 0) \%>\% 
  set_engine("glmnet", lambda.min.ratio = 0) \%>\% 
  fit(ridership ~ Austin + Quincy_Wells + Belmont, data = Chicago)

summary(default_value$fit$lambda)
}\if{html}{\out{</div>}}\preformatted{##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
##    0.566    5.668   56.697  637.468  566.827 5663.606
}\if{html}{\out{<div class="r">}}\preformatted{summary(zero_value$fit$lambda)
}\if{html}{\out{</div>}}\preformatted{##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
##    0.035    0.700   14.029  499.793  282.565 5663.606
}
}

\keyword{internal}
