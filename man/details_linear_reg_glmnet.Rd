% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/linear_reg_doc_glmnet.R
\name{details_linear_reg_glmnet}
\alias{details_linear_reg_glmnet}
\title{Linear regression via glmnet}
\description{
\code{\link[glmnet:glmnet]{glmnet::glmnet()}} uses regularized least squares to fit models with numeric outcomes.
}
\details{
For this engine, there is a single mode: regression
\subsection{Tuning Parameters}{

This model has 2 tuning parameters:
\itemize{
\item \code{penalty}: Amount of Regularization (type: double, default: see
below)
\item \code{mixture}: Proportion of lasso Penalty (type: double, default: 1.0)
}

A value of \code{mixture = 1} corresponds to a pure lasso model, while
\code{mixture = 0} indicates ridge regression.

The \code{penalty} parameter has no default. For more details about this, and
the \code{glmnet} model in general, see \link{glmnet-details}.
}

\subsection{Translation from parsnip to the original package}{\if{html}{\out{<div class="r">}}\preformatted{linear_reg(penalty = double(1), mixture = double(1)) \%>\% 
  set_engine("glmnet") \%>\% 
  set_mode("regression") \%>\% 
  translate()
}\if{html}{\out{</div>}}\preformatted{## Linear Regression Model Specification (regression)
## 
## Main Arguments:
##   penalty = 0
##   mixture = double(1)
## 
## Computational engine: glmnet 
## 
## Model fit template:
## glmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), 
##     alpha = double(1), family = "gaussian")
}
}

\subsection{Preprocessing requirements}{

Factor/categorical predictors need to be converted to numeric values
(e.g., dummy or indicators variables). When using the formula method via
\code{\link[=fit.model_spec]{fit.model_spec()}}, \code{parsnip} will convert these
data if required.

Also, predictors should have the same scale. One way to achieve this is
to center and scale each so that each predictors have mean zero and a
variance of one. By default, \code{glmnet()} uses the argument
\code{standardize = TRUE} to center and scale the data.
}

\subsection{References}{
\itemize{
\item Hastie, T, R Tibshirani, and M Wainwright. 2015. \emph{Statistical
Learning with Sparsity}. CRC Press.
\item Kuhn, M, and K Johnson. 2013. \emph{Applied Predictive Modeling}.
Springer.
}
}
}
\keyword{internal}
